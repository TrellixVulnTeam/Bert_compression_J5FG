训练 full, COLA:

tot time 416.2169461250305 =========

测试：

23:49:06-INFO: ***** Running evaluation *****
23:49:06-INFO:   Num examples = 1043
23:49:06-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
23:49:16-INFO: ***** Eval results *****
23:49:16-INFO:   Matthew's correlation = 0.5650871771295588
23:49:16-INFO:   eval_accuracy = 0.8235858101629914
23:49:16-INFO:   eval_loss = 0.47330745422478876
23:49:16-INFO:   global_step = 804
23:49:16-INFO:   inference_time = 9.288876295089722
23:49:16-INFO:   loss = 0.34617523727150845


测试head剪枝：

Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
00:48:36-INFO: device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
00:48:37-INFO: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
00:48:37-INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
00:48:37-INFO: extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpdvkgoaj7
00:48:42-INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

00:48:45-INFO: Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
00:48:45-INFO: Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
00:48:50-INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
00:48:50-INFO: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_uanh5ix
00:48:54-INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

attention_head_mask ['1:1']
['1', '1']
00:48:57-INFO: ***** Running evaluation *****
00:48:57-INFO:   Num examples = 1043
00:48:57-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:49:06-INFO: ***** Eval results *****
00:49:06-INFO:   Matthew's correlation = 0.5600900419522739
00:49:06-INFO:   eval_accuracy = 0.8216682646212847
00:49:06-INFO:   eval_loss = 0.47696786464163754
00:49:06-INFO:   global_step = 0
00:49:06-INFO:   inference_time = 9.284069538116455
00:49:06-INFO:   loss = None
attention_head_mask ['1:2']
['1', '2']
00:49:06-INFO: ***** Running evaluation *****
00:49:06-INFO:   Num examples = 1043
00:49:06-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:49:15-INFO: ***** Eval results *****
00:49:15-INFO:   Matthew's correlation = 0.5677348492150284
00:49:15-INFO:   eval_accuracy = 0.8245445829338447
00:49:15-INFO:   eval_loss = 0.46955891303492314
00:49:15-INFO:   global_step = 0
00:49:15-INFO:   inference_time = 9.267088174819946
00:49:15-INFO:   loss = None
attention_head_mask ['1:3']
['1', '3']
00:49:15-INFO: ***** Running evaluation *****
00:49:15-INFO:   Num examples = 1043
00:49:15-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:49:25-INFO: ***** Eval results *****
00:49:25-INFO:   Matthew's correlation = 0.5599999927061219
00:49:25-INFO:   eval_accuracy = 0.8216682646212847
00:49:25-INFO:   eval_loss = 0.4741994274610823
00:49:25-INFO:   global_step = 0
00:49:25-INFO:   inference_time = 9.266046285629272
00:49:25-INFO:   loss = None
attention_head_mask ['1:4']
['1', '4']
00:49:25-INFO: ***** Running evaluation *****
00:49:25-INFO:   Num examples = 1043
00:49:25-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:49:34-INFO: ***** Eval results *****
00:49:34-INFO:   Matthew's correlation = 0.5599999927061219
00:49:34-INFO:   eval_accuracy = 0.8216682646212847
00:49:34-INFO:   eval_loss = 0.4777992327104915
00:49:34-INFO:   global_step = 0
00:49:34-INFO:   inference_time = 9.265694856643677
00:49:34-INFO:   loss = None
attention_head_mask ['1:5']
['1', '5']
00:49:34-INFO: ***** Running evaluation *****
00:49:34-INFO:   Num examples = 1043
00:49:34-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:49:43-INFO: ***** Eval results *****
00:49:43-INFO:   Matthew's correlation = 0.5652516382961122
00:49:43-INFO:   eval_accuracy = 0.8235858101629914
00:49:43-INFO:   eval_loss = 0.4750595096160065
00:49:43-INFO:   global_step = 0
00:49:43-INFO:   inference_time = 9.26728868484497
00:49:43-INFO:   loss = None
attention_head_mask ['1:6']
['1', '6']
00:49:43-INFO: ***** Running evaluation *****
00:49:43-INFO:   Num examples = 1043
00:49:43-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:49:53-INFO: ***** Eval results *****
00:49:53-INFO:   Matthew's correlation = 0.5522294868395369
00:49:53-INFO:   eval_accuracy = 0.8187919463087249
00:49:53-INFO:   eval_loss = 0.4701304952755119
00:49:53-INFO:   global_step = 0
00:49:53-INFO:   inference_time = 9.2660231590271
00:49:53-INFO:   loss = None
attention_head_mask ['1:7']
['1', '7']
00:49:53-INFO: ***** Running evaluation *****
00:49:53-INFO:   Num examples = 1043
00:49:53-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:02-INFO: ***** Eval results *****
00:50:02-INFO:   Matthew's correlation = 0.5678267214677118
00:50:02-INFO:   eval_accuracy = 0.8245445829338447
00:50:02-INFO:   eval_loss = 0.4720307963364052
00:50:02-INFO:   global_step = 0
00:50:02-INFO:   inference_time = 9.26471471786499
00:50:02-INFO:   loss = None
attention_head_mask ['1:8']
['1', '8']
00:50:02-INFO: ***** Running evaluation *****
00:50:02-INFO:   Num examples = 1043
00:50:02-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:11-INFO: ***** Eval results *****
00:50:11-INFO:   Matthew's correlation = 0.5650871771295588
00:50:11-INFO:   eval_accuracy = 0.8235858101629914
00:50:11-INFO:   eval_loss = 0.4715666782223817
00:50:11-INFO:   global_step = 0
00:50:11-INFO:   inference_time = 9.263779163360596
00:50:11-INFO:   loss = None
attention_head_mask ['1:9']
['1', '9']
00:50:11-INFO: ***** Running evaluation *****
00:50:11-INFO:   Num examples = 1043
00:50:11-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:21-INFO: ***** Eval results *****
00:50:21-INFO:   Matthew's correlation = 0.5727969336224868
00:50:21-INFO:   eval_accuracy = 0.8264621284755513
00:50:21-INFO:   eval_loss = 0.4714218413062168
00:50:21-INFO:   global_step = 0
00:50:21-INFO:   inference_time = 9.265116214752197
00:50:21-INFO:   loss = None
attention_head_mask ['1:10']
['1', '10']
00:50:21-INFO: ***** Running evaluation *****
00:50:21-INFO:   Num examples = 1043
00:50:21-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:30-INFO: ***** Eval results *****
00:50:30-INFO:   Matthew's correlation = 0.5599999927061219
00:50:30-INFO:   eval_accuracy = 0.8216682646212847
00:50:30-INFO:   eval_loss = 0.47344467664758366
00:50:30-INFO:   global_step = 0
00:50:30-INFO:   inference_time = 9.263720273971558
00:50:30-INFO:   loss = None
attention_head_mask ['1:11']
['1', '11']
00:50:30-INFO: ***** Running evaluation *****
00:50:30-INFO:   Num examples = 1043
00:50:30-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:39-INFO: ***** Eval results *****
00:50:39-INFO:   Matthew's correlation = 0.547116568580723
00:50:39-INFO:   eval_accuracy = 0.8168744007670182
00:50:39-INFO:   eval_loss = 0.47418073000329913
00:50:39-INFO:   global_step = 0
00:50:39-INFO:   inference_time = 9.263415098190308
00:50:39-INFO:   loss = None
attention_head_mask ['1:12']
['1', '12']
00:50:39-INFO: ***** Running evaluation *****
00:50:39-INFO:   Num examples = 1043
00:50:39-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.55it/s]
00:50:48-INFO: ***** Eval results *****
00:50:48-INFO:   Matthew's correlation = 0.5625821583056989
00:50:48-INFO:   eval_accuracy = 0.822627037392138
00:50:48-INFO:   eval_loss = 0.47272331233729015
00:50:48-INFO:   global_step = 0
00:50:48-INFO:   inference_time = 9.266280174255371
00:50:48-INFO:   loss = None
attention_head_mask ['2:1']
['2', '1']
00:50:48-INFO: ***** Running evaluation *****
00:50:48-INFO:   Num examples = 1043
00:50:48-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:50:58-INFO: ***** Eval results *****
00:50:58-INFO:   Matthew's correlation = 0.5547527490659778
00:50:58-INFO:   eval_accuracy = 0.8197507190795782
00:50:58-INFO:   eval_loss = 0.47840019552545116
00:50:58-INFO:   global_step = 0
00:50:58-INFO:   inference_time = 9.280606269836426
00:50:58-INFO:   loss = None
attention_head_mask ['2:2']
['2', '2']
00:50:58-INFO: ***** Running evaluation *****
00:50:58-INFO:   Num examples = 1043
00:50:58-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:07-INFO: ***** Eval results *****
00:51:07-INFO:   Matthew's correlation = 0.5625821583056989
00:51:07-INFO:   eval_accuracy = 0.822627037392138
00:51:07-INFO:   eval_loss = 0.47241969948465173
00:51:07-INFO:   global_step = 0
00:51:07-INFO:   inference_time = 9.27966570854187
00:51:07-INFO:   loss = None
attention_head_mask ['2:3']
['2', '3']
00:51:07-INFO: ***** Running evaluation *****
00:51:07-INFO:   Num examples = 1043
00:51:07-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:16-INFO: ***** Eval results *****
00:51:16-INFO:   Matthew's correlation = 0.549825623859248
00:51:16-INFO:   eval_accuracy = 0.8178331735378715
00:51:16-INFO:   eval_loss = 0.4747003832775535
00:51:16-INFO:   global_step = 0
00:51:16-INFO:   inference_time = 9.279754877090454
00:51:16-INFO:   loss = None
attention_head_mask ['2:4']
['2', '4']
00:51:16-INFO: ***** Running evaluation *****
00:51:16-INFO:   Num examples = 1043
00:51:16-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:26-INFO: ***** Eval results *****
00:51:26-INFO:   Matthew's correlation = 0.5523181756655187
00:51:26-INFO:   eval_accuracy = 0.8187919463087249
00:51:26-INFO:   eval_loss = 0.47304465316913347
00:51:26-INFO:   global_step = 0
00:51:26-INFO:   inference_time = 9.279034852981567
00:51:26-INFO:   loss = None
attention_head_mask ['2:5']
['2', '5']
00:51:26-INFO: ***** Running evaluation *****
00:51:26-INFO:   Num examples = 1043
00:51:26-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:35-INFO: ***** Eval results *****
00:51:35-INFO:   Matthew's correlation = 0.5470285194988502
00:51:35-INFO:   eval_accuracy = 0.8168744007670182
00:51:35-INFO:   eval_loss = 0.47723764643976185
00:51:35-INFO:   global_step = 0
00:51:35-INFO:   inference_time = 9.279616355895996
00:51:35-INFO:   loss = None
attention_head_mask ['2:6']
['2', '6']
00:51:35-INFO: ***** Running evaluation *****
00:51:35-INFO:   Num examples = 1043
00:51:35-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:44-INFO: ***** Eval results *****
00:51:44-INFO:   Matthew's correlation = 0.5599999927061219
00:51:44-INFO:   eval_accuracy = 0.8216682646212847
00:51:44-INFO:   eval_loss = 0.474221965467388
00:51:44-INFO:   global_step = 0
00:51:44-INFO:   inference_time = 9.279916524887085
00:51:44-INFO:   loss = None
attention_head_mask ['2:7']
['2', '7']
00:51:44-INFO: ***** Running evaluation *****
00:51:44-INFO:   Num examples = 1043
00:51:44-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:51:54-INFO: ***** Eval results *****
00:51:54-INFO:   Matthew's correlation = 0.5574138665741355
00:51:54-INFO:   eval_accuracy = 0.8207094918504314
00:51:54-INFO:   eval_loss = 0.47112064266746695
00:51:54-INFO:   global_step = 0
00:51:54-INFO:   inference_time = 9.278940439224243
00:51:54-INFO:   loss = None
attention_head_mask ['2:8']
['2', '8']
00:51:54-INFO: ***** Running evaluation *****
00:51:54-INFO:   Num examples = 1043
00:51:54-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:03-INFO: ***** Eval results *****
00:52:03-INFO:   Matthew's correlation = 0.5575034099514093
00:52:03-INFO:   eval_accuracy = 0.8207094918504314
00:52:03-INFO:   eval_loss = 0.47217925355741475
00:52:03-INFO:   global_step = 0
00:52:03-INFO:   inference_time = 9.27982783317566
00:52:03-INFO:   loss = None
attention_head_mask ['2:9']
['2', '9']
00:52:03-INFO: ***** Running evaluation *****
00:52:03-INFO:   Num examples = 1043
00:52:03-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:12-INFO: ***** Eval results *****
00:52:12-INFO:   Matthew's correlation = 0.5625095574827523
00:52:12-INFO:   eval_accuracy = 0.822627037392138
00:52:12-INFO:   eval_loss = 0.4722703240360274
00:52:12-INFO:   global_step = 0
00:52:12-INFO:   inference_time = 9.28007698059082
00:52:12-INFO:   loss = None
attention_head_mask ['2:10']
['2', '10']
00:52:12-INFO: ***** Running evaluation *****
00:52:12-INFO:   Num examples = 1043
00:52:12-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:22-INFO: ***** Eval results *****
00:52:22-INFO:   Matthew's correlation = 0.5625095574827523
00:52:22-INFO:   eval_accuracy = 0.822627037392138
00:52:22-INFO:   eval_loss = 0.4728835020778757
00:52:22-INFO:   global_step = 0
00:52:22-INFO:   inference_time = 9.28262209892273
00:52:22-INFO:   loss = None
attention_head_mask ['2:11']
['2', '11']
00:52:22-INFO: ***** Running evaluation *****
00:52:22-INFO:   Num examples = 1043
00:52:22-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:31-INFO: ***** Eval results *****
00:52:31-INFO:   Matthew's correlation = 0.5499492780843731
00:52:31-INFO:   eval_accuracy = 0.8178331735378715
00:52:31-INFO:   eval_loss = 0.47651446452646545
00:52:31-INFO:   global_step = 0
00:52:31-INFO:   inference_time = 9.278846025466919
00:52:31-INFO:   loss = None
attention_head_mask ['2:12']
['2', '12']
00:52:31-INFO: ***** Running evaluation *****
00:52:31-INFO:   Num examples = 1043
00:52:31-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:40-INFO: ***** Eval results *****
00:52:40-INFO:   Matthew's correlation = 0.5573424050983508
00:52:40-INFO:   eval_accuracy = 0.8207094918504314
00:52:40-INFO:   eval_loss = 0.47776087587981514
00:52:40-INFO:   global_step = 0
00:52:40-INFO:   inference_time = 9.280330657958984
00:52:40-INFO:   loss = None
attention_head_mask ['3:1']
['3', '1']
00:52:40-INFO: ***** Running evaluation *****
00:52:40-INFO:   Num examples = 1043
00:52:40-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:52:50-INFO: ***** Eval results *****
00:52:50-INFO:   Matthew's correlation = 0.5624553233571645
00:52:50-INFO:   eval_accuracy = 0.822627037392138
00:52:50-INFO:   eval_loss = 0.4787204217052821
00:52:50-INFO:   global_step = 0
00:52:50-INFO:   inference_time = 9.301774501800537
00:52:50-INFO:   loss = None
attention_head_mask ['3:2']
['3', '2']
00:52:50-INFO: ***** Running evaluation *****
00:52:50-INFO:   Num examples = 1043
00:52:50-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:52:59-INFO: ***** Eval results *****
00:52:59-INFO:   Matthew's correlation = 0.5572552114140278
00:52:59-INFO:   eval_accuracy = 0.8207094918504314
00:52:59-INFO:   eval_loss = 0.47982861530600174
00:52:59-INFO:   global_step = 0
00:52:59-INFO:   inference_time = 9.295001029968262
00:52:59-INFO:   loss = None
attention_head_mask ['3:3']
['3', '3']
00:52:59-INFO: ***** Running evaluation *****
00:52:59-INFO:   Num examples = 1043
00:52:59-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:53:08-INFO: ***** Eval results *****
00:53:08-INFO:   Matthew's correlation = 0.5495609631481372
00:53:08-INFO:   eval_accuracy = 0.8178331735378715
00:53:08-INFO:   eval_loss = 0.4779816994612867
00:53:08-INFO:   global_step = 0
00:53:08-INFO:   inference_time = 9.295716762542725
00:53:08-INFO:   loss = None
attention_head_mask ['3:4']
['3', '4']
00:53:08-INFO: ***** Running evaluation *****
00:53:08-INFO:   Num examples = 1043
00:53:08-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:53:18-INFO: ***** Eval results *****
00:53:18-INFO:   Matthew's correlation = 0.5599279872250126
00:53:18-INFO:   eval_accuracy = 0.8216682646212847
00:53:18-INFO:   eval_loss = 0.47693670868422045
00:53:18-INFO:   global_step = 0
00:53:18-INFO:   inference_time = 9.296664714813232
00:53:18-INFO:   loss = None
attention_head_mask ['3:5']
['3', '5']
00:53:18-INFO: ***** Running evaluation *****
00:53:18-INFO:   Num examples = 1043
00:53:18-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:53:27-INFO: ***** Eval results *****
00:53:27-INFO:   Matthew's correlation = 0.557289393094284
00:53:27-INFO:   eval_accuracy = 0.8207094918504314
00:53:27-INFO:   eval_loss = 0.47750147477243887
00:53:27-INFO:   global_step = 0
00:53:27-INFO:   inference_time = 9.294256925582886
00:53:27-INFO:   loss = None
attention_head_mask ['3:6']
['3', '6']
00:53:27-INFO: ***** Running evaluation *****
00:53:27-INFO:   Num examples = 1043
00:53:27-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:53:36-INFO: ***** Eval results *****
00:53:36-INFO:   Matthew's correlation = 0.5547527490659778
00:53:36-INFO:   eval_accuracy = 0.8197507190795782
00:53:36-INFO:   eval_loss = 0.4785567754597375
00:53:36-INFO:   global_step = 0
00:53:36-INFO:   inference_time = 9.29455041885376
00:53:36-INFO:   loss = None
attention_head_mask ['3:7']
['3', '7']
00:53:36-INFO: ***** Running evaluation *****
00:53:36-INFO:   Num examples = 1043
00:53:36-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:53:46-INFO: ***** Eval results *****
00:53:46-INFO:   Matthew's correlation = 0.562419829892001
00:53:46-INFO:   eval_accuracy = 0.822627037392138
00:53:46-INFO:   eval_loss = 0.48382836106148636
00:53:46-INFO:   global_step = 0
00:53:46-INFO:   inference_time = 9.29625916481018
00:53:46-INFO:   loss = None
attention_head_mask ['3:8']
['3', '8']
00:53:46-INFO: ***** Running evaluation *****
00:53:46-INFO:   Num examples = 1043
00:53:46-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:53:55-INFO: ***** Eval results *****
00:53:55-INFO:   Matthew's correlation = 0.5496311083440725
00:53:55-INFO:   eval_accuracy = 0.8178331735378715
00:53:55-INFO:   eval_loss = 0.47644412393371266
00:53:55-INFO:   global_step = 0
00:53:55-INFO:   inference_time = 9.294726371765137
00:53:55-INFO:   loss = None
attention_head_mask ['3:9']
['3', '9']
00:53:55-INFO: ***** Running evaluation *****
00:53:55-INFO:   Num examples = 1043
00:53:55-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:54:05-INFO: ***** Eval results *****
00:54:05-INFO:   Matthew's correlation = 0.5547527490659778
00:54:05-INFO:   eval_accuracy = 0.8197507190795782
00:54:05-INFO:   eval_loss = 0.4759133078835227
00:54:05-INFO:   global_step = 0
00:54:05-INFO:   inference_time = 9.294750690460205
00:54:05-INFO:   loss = None
attention_head_mask ['3:10']
['3', '10']
00:54:05-INFO: ***** Running evaluation *****
00:54:05-INFO:   Num examples = 1043
00:54:05-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:54:14-INFO: ***** Eval results *****
00:54:14-INFO:   Matthew's correlation = 0.5522294868395369
00:54:14-INFO:   eval_accuracy = 0.8187919463087249
00:54:14-INFO:   eval_loss = 0.47781217843294144
00:54:14-INFO:   global_step = 0
00:54:14-INFO:   inference_time = 9.29515552520752
00:54:14-INFO:   loss = None
attention_head_mask ['3:11']
['3', '11']
00:54:14-INFO: ***** Running evaluation *****
00:54:14-INFO:   Num examples = 1043
00:54:14-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:54:23-INFO: ***** Eval results *****
00:54:23-INFO:   Matthew's correlation = 0.5573424050983508
00:54:23-INFO:   eval_accuracy = 0.8207094918504314
00:54:23-INFO:   eval_loss = 0.48028849765206827
00:54:23-INFO:   global_step = 0
00:54:23-INFO:   inference_time = 9.295867681503296
00:54:23-INFO:   loss = None
attention_head_mask ['3:12']
['3', '12']
00:54:23-INFO: ***** Running evaluation *****
00:54:23-INFO:   Num examples = 1043
00:54:23-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.54it/s]
00:54:33-INFO: ***** Eval results *****
00:54:33-INFO:   Matthew's correlation = 0.5573424050983508
00:54:33-INFO:   eval_accuracy = 0.8207094918504314
00:54:33-INFO:   eval_loss = 0.47414583498329826
00:54:33-INFO:   global_step = 0
00:54:33-INFO:   inference_time = 9.295321702957153
00:54:33-INFO:   loss = None
attention_head_mask ['4:1']
['4', '1']
00:54:33-INFO: ***** Running evaluation *****
00:54:33-INFO:   Num examples = 1043
00:54:33-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:54:42-INFO: ***** Eval results *****
00:54:42-INFO:   Matthew's correlation = 0.5575034099514093
00:54:42-INFO:   eval_accuracy = 0.8207094918504314
00:54:42-INFO:   eval_loss = 0.4731985688435309
00:54:42-INFO:   global_step = 0
00:54:42-INFO:   inference_time = 9.310878038406372
00:54:42-INFO:   loss = None
attention_head_mask ['4:2']
['4', '2']
00:54:42-INFO: ***** Running evaluation *****
00:54:42-INFO:   Num examples = 1043
00:54:42-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:54:51-INFO: ***** Eval results *****
00:54:51-INFO:   Matthew's correlation = 0.5495609631481372
00:54:51-INFO:   eval_accuracy = 0.8178331735378715
00:54:51-INFO:   eval_loss = 0.4763359148619753
00:54:51-INFO:   global_step = 0
00:54:51-INFO:   inference_time = 9.312210321426392
00:54:51-INFO:   loss = None
attention_head_mask ['4:3']
['4', '3']
00:54:51-INFO: ***** Running evaluation *****
00:54:51-INFO:   Num examples = 1043
00:54:51-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:01-INFO: ***** Eval results *****
00:55:01-INFO:   Matthew's correlation = 0.5650322558145829
00:55:01-INFO:   eval_accuracy = 0.8235858101629914
00:55:01-INFO:   eval_loss = 0.47432655400850554
00:55:01-INFO:   global_step = 0
00:55:01-INFO:   inference_time = 9.312789678573608
00:55:01-INFO:   loss = None
attention_head_mask ['4:4']
['4', '4']
00:55:01-INFO: ***** Running evaluation *****
00:55:01-INFO:   Num examples = 1043
00:55:01-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:10-INFO: ***** Eval results *****
00:55:10-INFO:   Matthew's correlation = 0.5495093920893817
00:55:10-INFO:   eval_accuracy = 0.8178331735378715
00:55:10-INFO:   eval_loss = 0.47681269162532053
00:55:10-INFO:   global_step = 0
00:55:10-INFO:   inference_time = 9.312660932540894
00:55:10-INFO:   loss = None
attention_head_mask ['4:5']
['4', '5']
00:55:10-INFO: ***** Running evaluation *****
00:55:10-INFO:   Num examples = 1043
00:55:10-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:19-INFO: ***** Eval results *****
00:55:19-INFO:   Matthew's correlation = 0.5599279872250126
00:55:19-INFO:   eval_accuracy = 0.8216682646212847
00:55:19-INFO:   eval_loss = 0.4727128412235867
00:55:19-INFO:   global_step = 0
00:55:19-INFO:   inference_time = 9.312277793884277
00:55:19-INFO:   loss = None
attention_head_mask ['4:6']
['4', '6']
00:55:19-INFO: ***** Running evaluation *****
00:55:19-INFO:   Num examples = 1043
00:55:19-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:29-INFO: ***** Eval results *****
00:55:29-INFO:   Matthew's correlation = 0.5524246615971198
00:55:29-INFO:   eval_accuracy = 0.8187919463087249
00:55:29-INFO:   eval_loss = 0.4680485256919355
00:55:29-INFO:   global_step = 0
00:55:29-INFO:   inference_time = 9.311280488967896
00:55:29-INFO:   loss = None
attention_head_mask ['4:7']
['4', '7']
00:55:29-INFO: ***** Running evaluation *****
00:55:29-INFO:   Num examples = 1043
00:55:29-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:38-INFO: ***** Eval results *****
00:55:38-INFO:   Matthew's correlation = 0.5522294868395369
00:55:38-INFO:   eval_accuracy = 0.8187919463087249
00:55:38-INFO:   eval_loss = 0.47646584937518294
00:55:38-INFO:   global_step = 0
00:55:38-INFO:   inference_time = 9.311633825302124
00:55:38-INFO:   loss = None
attention_head_mask ['4:8']
['4', '8']
00:55:38-INFO: ***** Running evaluation *****
00:55:38-INFO:   Num examples = 1043
00:55:38-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:47-INFO: ***** Eval results *****
00:55:47-INFO:   Matthew's correlation = 0.5520738806744706
00:55:47-INFO:   eval_accuracy = 0.8187919463087249
00:55:47-INFO:   eval_loss = 0.47473173396605434
00:55:47-INFO:   global_step = 0
00:55:47-INFO:   inference_time = 9.312056064605713
00:55:47-INFO:   loss = None
attention_head_mask ['4:9']
['4', '9']
00:55:47-INFO: ***** Running evaluation *****
00:55:47-INFO:   Num examples = 1043
00:55:47-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:55:57-INFO: ***** Eval results *****
00:55:57-INFO:   Matthew's correlation = 0.5524246615971198
00:55:57-INFO:   eval_accuracy = 0.8187919463087249
00:55:57-INFO:   eval_loss = 0.4739953384480693
00:55:57-INFO:   global_step = 0
00:55:57-INFO:   inference_time = 9.311550855636597
00:55:57-INFO:   loss = None
attention_head_mask ['4:10']
['4', '10']
00:55:57-INFO: ***** Running evaluation *****
00:55:57-INFO:   Num examples = 1043
00:55:57-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:56:06-INFO: ***** Eval results *****
00:56:06-INFO:   Matthew's correlation = 0.5470285194988502
00:56:06-INFO:   eval_accuracy = 0.8168744007670182
00:56:06-INFO:   eval_loss = 0.47571678233869147
00:56:06-INFO:   global_step = 0
00:56:06-INFO:   inference_time = 9.311639785766602
00:56:06-INFO:   loss = None
attention_head_mask ['4:11']
['4', '11']
00:56:06-INFO: ***** Running evaluation *****
00:56:06-INFO:   Num examples = 1043
00:56:06-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:56:15-INFO: ***** Eval results *****
00:56:15-INFO:   Matthew's correlation = 0.554912808282685
00:56:15-INFO:   eval_accuracy = 0.8197507190795782
00:56:15-INFO:   eval_loss = 0.469186622988094
00:56:15-INFO:   global_step = 0
00:56:15-INFO:   inference_time = 9.311448574066162
00:56:15-INFO:   loss = None
attention_head_mask ['4:12']
['4', '12']
00:56:15-INFO: ***** Running evaluation *****
00:56:15-INFO:   Num examples = 1043
00:56:16-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.53it/s]
00:56:25-INFO: ***** Eval results *****
00:56:25-INFO:   Matthew's correlation = 0.5547002704668513
00:56:25-INFO:   eval_accuracy = 0.8197507190795782
00:56:25-INFO:   eval_loss = 0.4740852093832059
00:56:25-INFO:   global_step = 0
00:56:25-INFO:   inference_time = 9.310914516448975
00:56:25-INFO:   loss = None
attention_head_mask ['5:1']
['5', '1']
00:56:25-INFO: ***** Running evaluation *****
00:56:25-INFO:   Num examples = 1043
00:56:25-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:56:34-INFO: ***** Eval results *****
00:56:34-INFO:   Matthew's correlation = 0.5676609066599885
00:56:34-INFO:   eval_accuracy = 0.8245445829338447
00:56:34-INFO:   eval_loss = 0.4690391981240475
00:56:34-INFO:   global_step = 0
00:56:34-INFO:   inference_time = 9.32649564743042
00:56:34-INFO:   loss = None
attention_head_mask ['5:2']
['5', '2']
00:56:34-INFO: ***** Running evaluation *****
00:56:34-INFO:   Num examples = 1043
00:56:34-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:56:44-INFO: ***** Eval results *****
00:56:44-INFO:   Matthew's correlation = 0.5521069582827846
00:56:44-INFO:   eval_accuracy = 0.8187919463087249
00:56:44-INFO:   eval_loss = 0.4762230005228158
00:56:44-INFO:   global_step = 0
00:56:44-INFO:   inference_time = 9.32913088798523
00:56:44-INFO:   loss = None
attention_head_mask ['5:3']
['5', '3']
00:56:44-INFO: ***** Running evaluation *****
00:56:44-INFO:   Num examples = 1043
00:56:44-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:56:53-INFO: ***** Eval results *****
00:56:53-INFO:   Matthew's correlation = 0.5494767866076017
00:56:53-INFO:   eval_accuracy = 0.8178331735378715
00:56:53-INFO:   eval_loss = 0.4796259631261681
00:56:53-INFO:   global_step = 0
00:56:53-INFO:   inference_time = 9.327343225479126
00:56:53-INFO:   loss = None
attention_head_mask ['5:4']
['5', '4']
00:56:53-INFO: ***** Running evaluation *****
00:56:53-INFO:   Num examples = 1043
00:56:53-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:02-INFO: ***** Eval results *****
00:57:02-INFO:   Matthew's correlation = 0.5626727648075698
00:57:02-INFO:   eval_accuracy = 0.822627037392138
00:57:02-INFO:   eval_loss = 0.4689981086236058
00:57:02-INFO:   global_step = 0
00:57:02-INFO:   inference_time = 9.326430559158325
00:57:02-INFO:   loss = None
attention_head_mask ['5:5']
['5', '5']
00:57:02-INFO: ***** Running evaluation *****
00:57:02-INFO:   Num examples = 1043
00:57:02-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:12-INFO: ***** Eval results *****
00:57:12-INFO:   Matthew's correlation = 0.5650322558145829
00:57:12-INFO:   eval_accuracy = 0.8235858101629914
00:57:12-INFO:   eval_loss = 0.46787215103254176
00:57:12-INFO:   global_step = 0
00:57:12-INFO:   inference_time = 9.327109813690186
00:57:12-INFO:   loss = None
attention_head_mask ['5:6']
['5', '6']
00:57:12-INFO: ***** Running evaluation *****
00:57:12-INFO:   Num examples = 1043
00:57:12-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:21-INFO: ***** Eval results *****
00:57:21-INFO:   Matthew's correlation = 0.5495093920893817
00:57:21-INFO:   eval_accuracy = 0.8178331735378715
00:57:21-INFO:   eval_loss = 0.4731600491160696
00:57:21-INFO:   global_step = 0
00:57:21-INFO:   inference_time = 9.327624320983887
00:57:21-INFO:   loss = None
attention_head_mask ['5:7']
['5', '7']
00:57:21-INFO: ***** Running evaluation *****
00:57:21-INFO:   Num examples = 1043
00:57:21-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:30-INFO: ***** Eval results *****
00:57:30-INFO:   Matthew's correlation = 0.5650871771295588
00:57:30-INFO:   eval_accuracy = 0.8235858101629914
00:57:30-INFO:   eval_loss = 0.47106813594247354
00:57:30-INFO:   global_step = 0
00:57:30-INFO:   inference_time = 9.326860666275024
00:57:30-INFO:   loss = None
attention_head_mask ['5:8']
['5', '8']
00:57:30-INFO: ***** Running evaluation *****
00:57:30-INFO:   Num examples = 1043
00:57:30-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:40-INFO: ***** Eval results *****
00:57:40-INFO:   Matthew's correlation = 0.5624034645452709
00:57:40-INFO:   eval_accuracy = 0.822627037392138
00:57:40-INFO:   eval_loss = 0.47055713696913287
00:57:40-INFO:   global_step = 0
00:57:40-INFO:   inference_time = 9.327354192733765
00:57:40-INFO:   loss = None
attention_head_mask ['5:9']
['5', '9']
00:57:40-INFO: ***** Running evaluation *****
00:57:40-INFO:   Num examples = 1043
00:57:40-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:49-INFO: ***** Eval results *****
00:57:49-INFO:   Matthew's correlation = 0.5521069582827846
00:57:49-INFO:   eval_accuracy = 0.8187919463087249
00:57:49-INFO:   eval_loss = 0.4782902629989566
00:57:49-INFO:   global_step = 0
00:57:49-INFO:   inference_time = 9.326338052749634
00:57:49-INFO:   loss = None
attention_head_mask ['5:10']
['5', '10']
00:57:49-INFO: ***** Running evaluation *****
00:57:49-INFO:   Num examples = 1043
00:57:49-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:57:59-INFO: ***** Eval results *****
00:57:59-INFO:   Matthew's correlation = 0.5468969938757886
00:57:59-INFO:   eval_accuracy = 0.8168744007670182
00:57:59-INFO:   eval_loss = 0.4786550310073477
00:57:59-INFO:   global_step = 0
00:57:59-INFO:   inference_time = 9.326334714889526
00:57:59-INFO:   loss = None
attention_head_mask ['5:11']
['5', '11']
00:57:59-INFO: ***** Running evaluation *****
00:57:59-INFO:   Num examples = 1043
00:57:59-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:08-INFO: ***** Eval results *****
00:58:08-INFO:   Matthew's correlation = 0.5547002704668513
00:58:08-INFO:   eval_accuracy = 0.8197507190795782
00:58:08-INFO:   eval_loss = 0.4773919182744893
00:58:08-INFO:   global_step = 0
00:58:08-INFO:   inference_time = 9.328102588653564
00:58:08-INFO:   loss = None
attention_head_mask ['5:12']
['5', '12']
00:58:08-INFO: ***** Running evaluation *****
00:58:08-INFO:   Num examples = 1043
00:58:08-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:17-INFO: ***** Eval results *****
00:58:17-INFO:   Matthew's correlation = 0.5390322970786539
00:58:17-INFO:   eval_accuracy = 0.8139980824544583
00:58:17-INFO:   eval_loss = 0.4776813948922085
00:58:17-INFO:   global_step = 0
00:58:17-INFO:   inference_time = 9.327512979507446
00:58:17-INFO:   loss = None
attention_head_mask ['6:1']
['6', '1']
00:58:17-INFO: ***** Running evaluation *****
00:58:17-INFO:   Num examples = 1043
00:58:17-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:27-INFO: ***** Eval results *****
00:58:27-INFO:   Matthew's correlation = 0.5338269593815457
00:58:27-INFO:   eval_accuracy = 0.8120805369127517
00:58:27-INFO:   eval_loss = 0.47943786260756577
00:58:27-INFO:   global_step = 0
00:58:27-INFO:   inference_time = 9.341979026794434
00:58:27-INFO:   loss = None
attention_head_mask ['6:2']
['6', '2']
00:58:27-INFO: ***** Running evaluation *****
00:58:27-INFO:   Num examples = 1043
00:58:27-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:36-INFO: ***** Eval results *****
00:58:36-INFO:   Matthew's correlation = 0.5494968980251971
00:58:36-INFO:   eval_accuracy = 0.8178331735378715
00:58:36-INFO:   eval_loss = 0.47874281657013024
00:58:36-INFO:   global_step = 0
00:58:36-INFO:   inference_time = 9.342124938964844
00:58:36-INFO:   loss = None
attention_head_mask ['6:3']
['6', '3']
00:58:36-INFO: ***** Running evaluation *****
00:58:36-INFO:   Num examples = 1043
00:58:36-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:46-INFO: ***** Eval results *****
00:58:46-INFO:   Matthew's correlation = 0.5416549448511832
00:58:46-INFO:   eval_accuracy = 0.8149568552253116
00:58:46-INFO:   eval_loss = 0.4761358432923303
00:58:46-INFO:   global_step = 0
00:58:46-INFO:   inference_time = 9.342246770858765
00:58:46-INFO:   loss = None
attention_head_mask ['6:4']
['6', '4']
00:58:46-INFO: ***** Running evaluation *****
00:58:46-INFO:   Num examples = 1043
00:58:46-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:58:55-INFO: ***** Eval results *****
00:58:55-INFO:   Matthew's correlation = 0.557240254761928
00:58:55-INFO:   eval_accuracy = 0.8207094918504314
00:58:55-INFO:   eval_loss = 0.47491042361114966
00:58:55-INFO:   global_step = 0
00:58:55-INFO:   inference_time = 9.341984510421753
00:58:55-INFO:   loss = None
attention_head_mask ['6:5']
['6', '5']
00:58:55-INFO: ***** Running evaluation *****
00:58:55-INFO:   Num examples = 1043
00:58:55-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:04-INFO: ***** Eval results *****
00:59:04-INFO:   Matthew's correlation = 0.5496129885311101
00:59:04-INFO:   eval_accuracy = 0.8178331735378715
00:59:04-INFO:   eval_loss = 0.48312259397723456
00:59:04-INFO:   global_step = 0
00:59:04-INFO:   inference_time = 9.342288255691528
00:59:04-INFO:   loss = None
attention_head_mask ['6:6']
['6', '6']
00:59:04-INFO: ***** Running evaluation *****
00:59:04-INFO:   Num examples = 1043
00:59:04-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:14-INFO: ***** Eval results *****
00:59:14-INFO:   Matthew's correlation = 0.5416905121171213
00:59:14-INFO:   eval_accuracy = 0.8149568552253116
00:59:14-INFO:   eval_loss = 0.47157171379887697
00:59:14-INFO:   global_step = 0
00:59:14-INFO:   inference_time = 9.342885732650757
00:59:14-INFO:   loss = None
attention_head_mask ['6:7']
['6', '7']
00:59:14-INFO: ***** Running evaluation *****
00:59:14-INFO:   Num examples = 1043
00:59:14-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:23-INFO: ***** Eval results *****
00:59:23-INFO:   Matthew's correlation = 0.5494968980251971
00:59:23-INFO:   eval_accuracy = 0.8178331735378715
00:59:23-INFO:   eval_loss = 0.4694494910989747
00:59:23-INFO:   global_step = 0
00:59:23-INFO:   inference_time = 9.343420505523682
00:59:23-INFO:   loss = None
attention_head_mask ['6:8']
['6', '8']
00:59:23-INFO: ***** Running evaluation *****
00:59:23-INFO:   Num examples = 1043
00:59:23-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:33-INFO: ***** Eval results *****
00:59:33-INFO:   Matthew's correlation = 0.5390322970786539
00:59:33-INFO:   eval_accuracy = 0.8139980824544583
00:59:33-INFO:   eval_loss = 0.4751184858155973
00:59:33-INFO:   global_step = 0
00:59:33-INFO:   inference_time = 9.343841075897217
00:59:33-INFO:   loss = None
attention_head_mask ['6:9']
['6', '9']
00:59:33-INFO: ***** Running evaluation *****
00:59:33-INFO:   Num examples = 1043
00:59:33-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:42-INFO: ***** Eval results *****
00:59:42-INFO:   Matthew's correlation = 0.5495443671948597
00:59:42-INFO:   eval_accuracy = 0.8178331735378715
00:59:42-INFO:   eval_loss = 0.47659161709474795
00:59:42-INFO:   global_step = 0
00:59:42-INFO:   inference_time = 9.34230899810791
00:59:42-INFO:   loss = None
attention_head_mask ['6:10']
['6', '10']
00:59:42-INFO: ***** Running evaluation *****
00:59:42-INFO:   Num examples = 1043
00:59:42-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
00:59:51-INFO: ***** Eval results *****
00:59:51-INFO:   Matthew's correlation = 0.5443411760365089
00:59:51-INFO:   eval_accuracy = 0.8159156279961649
00:59:51-INFO:   eval_loss = 0.47859794612635265
00:59:51-INFO:   global_step = 0
00:59:51-INFO:   inference_time = 9.34401798248291
00:59:51-INFO:   loss = None
attention_head_mask ['6:11']
['6', '11']
00:59:51-INFO: ***** Running evaluation *****
00:59:51-INFO:   Num examples = 1043
00:59:51-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
01:00:01-INFO: ***** Eval results *****
01:00:01-INFO:   Matthew's correlation = 0.5390322970786539
01:00:01-INFO:   eval_accuracy = 0.8139980824544583
01:00:01-INFO:   eval_loss = 0.47199433105009975
01:00:01-INFO:   global_step = 0
01:00:01-INFO:   inference_time = 9.342901706695557
01:00:01-INFO:   loss = None
attention_head_mask ['6:12']
['6', '12']
01:00:01-INFO: ***** Running evaluation *****
01:00:01-INFO:   Num examples = 1043
01:00:01-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.52it/s]
01:00:10-INFO: ***** Eval results *****
01:00:10-INFO:   Matthew's correlation = 0.5390439985632989
01:00:10-INFO:   eval_accuracy = 0.8139980824544583
01:00:10-INFO:   eval_loss = 0.47475969272129465
01:00:10-INFO:   global_step = 0
01:00:10-INFO:   inference_time = 9.342817544937134
01:00:10-INFO:   loss = None
attention_head_mask ['7:1']
['7', '1']
01:00:10-INFO: ***** Running evaluation *****
01:00:10-INFO:   Num examples = 1043
01:00:10-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:00:19-INFO: ***** Eval results *****
01:00:19-INFO:   Matthew's correlation = 0.5446151814563016
01:00:19-INFO:   eval_accuracy = 0.8159156279961649
01:00:19-INFO:   eval_loss = 0.4622621361279126
01:00:19-INFO:   global_step = 0
01:00:19-INFO:   inference_time = 9.359782934188843
01:00:19-INFO:   loss = None
attention_head_mask ['7:2']
['7', '2']
01:00:19-INFO: ***** Running evaluation *****
01:00:19-INFO:   Num examples = 1043
01:00:19-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:00:29-INFO: ***** Eval results *****
01:00:29-INFO:   Matthew's correlation = 0.5442570546927161
01:00:29-INFO:   eval_accuracy = 0.8159156279961649
01:00:29-INFO:   eval_loss = 0.46986243399706756
01:00:29-INFO:   global_step = 0
01:00:29-INFO:   inference_time = 9.358438730239868
01:00:29-INFO:   loss = None
attention_head_mask ['7:3']
['7', '3']
01:00:29-INFO: ***** Running evaluation *****
01:00:29-INFO:   Num examples = 1043
01:00:29-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:00:38-INFO: ***** Eval results *****
01:00:38-INFO:   Matthew's correlation = 0.5259790835948196
01:00:38-INFO:   eval_accuracy = 0.8092042186001918
01:00:38-INFO:   eval_loss = 0.48845657886880817
01:00:38-INFO:   global_step = 0
01:00:38-INFO:   inference_time = 9.358073711395264
01:00:38-INFO:   loss = None
attention_head_mask ['7:4']
['7', '4']
01:00:38-INFO: ***** Running evaluation *****
01:00:38-INFO:   Num examples = 1043
01:00:38-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:00:48-INFO: ***** Eval results *****
01:00:48-INFO:   Matthew's correlation = 0.5232427655095763
01:00:48-INFO:   eval_accuracy = 0.8082454458293384
01:00:48-INFO:   eval_loss = 0.484262166827014
01:00:48-INFO:   global_step = 0
01:00:48-INFO:   inference_time = 9.358025312423706
01:00:48-INFO:   loss = None
attention_head_mask ['7:5']
['7', '5']
01:00:48-INFO: ***** Running evaluation *****
01:00:48-INFO:   Num examples = 1043
01:00:48-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:00:57-INFO: ***** Eval results *****
01:00:57-INFO:   Matthew's correlation = 0.5339501336198276
01:00:57-INFO:   eval_accuracy = 0.8120805369127517
01:00:57-INFO:   eval_loss = 0.4693735597485846
01:00:57-INFO:   global_step = 0
01:00:57-INFO:   inference_time = 9.3584566116333
01:00:57-INFO:   loss = None
attention_head_mask ['7:6']
['7', '6']
01:00:57-INFO: ***** Running evaluation *****
01:00:57-INFO:   Num examples = 1043
01:00:57-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:07-INFO: ***** Eval results *****
01:01:07-INFO:   Matthew's correlation = 0.5495093920893817
01:01:07-INFO:   eval_accuracy = 0.8178331735378715
01:01:07-INFO:   eval_loss = 0.4650129184804179
01:01:07-INFO:   global_step = 0
01:01:07-INFO:   inference_time = 9.35904312133789
01:01:07-INFO:   loss = None
attention_head_mask ['7:7']
['7', '7']
01:01:07-INFO: ***** Running evaluation *****
01:01:07-INFO:   Num examples = 1043
01:01:07-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:16-INFO: ***** Eval results *****
01:01:16-INFO:   Matthew's correlation = 0.5311596898053897
01:01:16-INFO:   eval_accuracy = 0.8111217641418984
01:01:16-INFO:   eval_loss = 0.4772116146755941
01:01:16-INFO:   global_step = 0
01:01:16-INFO:   inference_time = 9.35805058479309
01:01:16-INFO:   loss = None
attention_head_mask ['7:8']
['7', '8']
01:01:16-INFO: ***** Running evaluation *****
01:01:16-INFO:   Num examples = 1043
01:01:16-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:25-INFO: ***** Eval results *****
01:01:25-INFO:   Matthew's correlation = 0.5390439985632989
01:01:25-INFO:   eval_accuracy = 0.8139980824544583
01:01:25-INFO:   eval_loss = 0.4762849236528079
01:01:25-INFO:   global_step = 0
01:01:25-INFO:   inference_time = 9.357786417007446
01:01:25-INFO:   loss = None
attention_head_mask ['7:9']
['7', '9']
01:01:25-INFO: ***** Running evaluation *****
01:01:25-INFO:   Num examples = 1043
01:01:25-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:35-INFO: ***** Eval results *****
01:01:35-INFO:   Matthew's correlation = 0.5442645975519255
01:01:35-INFO:   eval_accuracy = 0.8159156279961649
01:01:35-INFO:   eval_loss = 0.4756120531396432
01:01:35-INFO:   global_step = 0
01:01:35-INFO:   inference_time = 9.358856916427612
01:01:35-INFO:   loss = None
attention_head_mask ['7:10']
['7', '10']
01:01:35-INFO: ***** Running evaluation *****
01:01:35-INFO:   Num examples = 1043
01:01:35-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:44-INFO: ***** Eval results *****
01:01:44-INFO:   Matthew's correlation = 0.544269410354875
01:01:44-INFO:   eval_accuracy = 0.8159156279961649
01:01:44-INFO:   eval_loss = 0.4762825378865907
01:01:44-INFO:   global_step = 0
01:01:44-INFO:   inference_time = 9.357325553894043
01:01:44-INFO:   loss = None
attention_head_mask ['7:11']
['7', '11']
01:01:44-INFO: ***** Running evaluation *****
01:01:44-INFO:   Num examples = 1043
01:01:44-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:01:54-INFO: ***** Eval results *****
01:01:54-INFO:   Matthew's correlation = 0.5521390429003941
01:01:54-INFO:   eval_accuracy = 0.8187919463087249
01:01:54-INFO:   eval_loss = 0.47438350714968913
01:01:54-INFO:   global_step = 0
01:01:54-INFO:   inference_time = 9.357919692993164
01:01:54-INFO:   loss = None
attention_head_mask ['7:12']
['7', '12']
01:01:54-INFO: ***** Running evaluation *****
01:01:54-INFO:   Num examples = 1043
01:01:54-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:02:03-INFO: ***** Eval results *****
01:02:03-INFO:   Matthew's correlation = 0.5416469931221344
01:02:03-INFO:   eval_accuracy = 0.8149568552253116
01:02:03-INFO:   eval_loss = 0.47441629523580725
01:02:03-INFO:   global_step = 0
01:02:03-INFO:   inference_time = 9.358158826828003
01:02:03-INFO:   loss = None
attention_head_mask ['8:1']
['8', '1']
01:02:03-INFO: ***** Running evaluation *****
01:02:03-INFO:   Num examples = 1043
01:02:03-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:02:12-INFO: ***** Eval results *****
01:02:12-INFO:   Matthew's correlation = 0.5442645975519255
01:02:12-INFO:   eval_accuracy = 0.8159156279961649
01:02:12-INFO:   eval_loss = 0.47456338888767996
01:02:12-INFO:   global_step = 0
01:02:12-INFO:   inference_time = 9.374941110610962
01:02:12-INFO:   loss = None
attention_head_mask ['8:2']
['8', '2']
01:02:12-INFO: ***** Running evaluation *****
01:02:12-INFO:   Num examples = 1043
01:02:12-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:02:22-INFO: ***** Eval results *****
01:02:22-INFO:   Matthew's correlation = 0.5390752681565225
01:02:22-INFO:   eval_accuracy = 0.8139980824544583
01:02:22-INFO:   eval_loss = 0.4662459126927636
01:02:22-INFO:   global_step = 0
01:02:22-INFO:   inference_time = 9.373532772064209
01:02:22-INFO:   loss = None
attention_head_mask ['8:3']
['8', '3']
01:02:22-INFO: ***** Running evaluation *****
01:02:22-INFO:   Num examples = 1043
01:02:22-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:02:31-INFO: ***** Eval results *****
01:02:31-INFO:   Matthew's correlation = 0.533788717644728
01:02:31-INFO:   eval_accuracy = 0.8120805369127517
01:02:31-INFO:   eval_loss = 0.479510685711196
01:02:31-INFO:   global_step = 0
01:02:31-INFO:   inference_time = 9.375208139419556
01:02:31-INFO:   loss = None
attention_head_mask ['8:4']
['8', '4']
01:02:31-INFO: ***** Running evaluation *****
01:02:31-INFO:   Num examples = 1043
01:02:31-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:02:41-INFO: ***** Eval results *****
01:02:41-INFO:   Matthew's correlation = 0.5390752681565225
01:02:41-INFO:   eval_accuracy = 0.8139980824544583
01:02:41-INFO:   eval_loss = 0.47381315143270925
01:02:41-INFO:   global_step = 0
01:02:41-INFO:   inference_time = 9.374256372451782
01:02:41-INFO:   loss = None
attention_head_mask ['8:5']
['8', '5']
01:02:41-INFO: ***** Running evaluation *****
01:02:41-INFO:   Num examples = 1043
01:02:41-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:02:50-INFO: ***** Eval results *****
01:02:50-INFO:   Matthew's correlation = 0.5285348624455609
01:02:50-INFO:   eval_accuracy = 0.8101629913710451
01:02:50-INFO:   eval_loss = 0.47998439543174976
01:02:50-INFO:   global_step = 0
01:02:50-INFO:   inference_time = 9.37573790550232
01:02:50-INFO:   loss = None
attention_head_mask ['8:6']
['8', '6']
01:02:50-INFO: ***** Running evaluation *****
01:02:50-INFO:   Num examples = 1043
01:02:50-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:03:00-INFO: ***** Eval results *****
01:03:00-INFO:   Matthew's correlation = 0.5390439985632989
01:03:00-INFO:   eval_accuracy = 0.8139980824544583
01:03:00-INFO:   eval_loss = 0.470043215787772
01:03:00-INFO:   global_step = 0
01:03:00-INFO:   inference_time = 9.373662948608398
01:03:00-INFO:   loss = None
attention_head_mask ['8:7']
['8', '7']
01:03:00-INFO: ***** Running evaluation *****
01:03:00-INFO:   Num examples = 1043
01:03:00-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:03:09-INFO: ***** Eval results *****
01:03:09-INFO:   Matthew's correlation = 0.5390439985632989
01:03:09-INFO:   eval_accuracy = 0.8139980824544583
01:03:09-INFO:   eval_loss = 0.47448211253592465
01:03:09-INFO:   global_step = 0
01:03:09-INFO:   inference_time = 9.373716354370117
01:03:09-INFO:   loss = None
attention_head_mask ['8:8']
['8', '8']
01:03:09-INFO: ***** Running evaluation *****
01:03:09-INFO:   Num examples = 1043
01:03:09-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:03:18-INFO: ***** Eval results *****
01:03:18-INFO:   Matthew's correlation = 0.5285257385527052
01:03:18-INFO:   eval_accuracy = 0.8101629913710451
01:03:18-INFO:   eval_loss = 0.47912710160017014
01:03:18-INFO:   global_step = 0
01:03:18-INFO:   inference_time = 9.374076843261719
01:03:18-INFO:   loss = None
attention_head_mask ['8:9']
['8', '9']
01:03:18-INFO: ***** Running evaluation *****
01:03:18-INFO:   Num examples = 1043
01:03:18-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:03:28-INFO: ***** Eval results *****
01:03:28-INFO:   Matthew's correlation = 0.5364243566130295
01:03:28-INFO:   eval_accuracy = 0.8130393096836049
01:03:28-INFO:   eval_loss = 0.46666905441970535
01:03:28-INFO:   global_step = 0
01:03:28-INFO:   inference_time = 9.375623226165771
01:03:28-INFO:   loss = None
attention_head_mask ['8:10']
['8', '10']
01:03:28-INFO: ***** Running evaluation *****
01:03:28-INFO:   Num examples = 1043
01:03:28-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:03:37-INFO: ***** Eval results *****
01:03:37-INFO:   Matthew's correlation = 0.5286178863044644
01:03:37-INFO:   eval_accuracy = 0.8101629913710451
01:03:37-INFO:   eval_loss = 0.4716909770486933
01:03:37-INFO:   global_step = 0
01:03:37-INFO:   inference_time = 9.374173879623413
01:03:37-INFO:   loss = None
attention_head_mask ['8:11']
['8', '11']
01:03:37-INFO: ***** Running evaluation *****
01:03:37-INFO:   Num examples = 1043
01:03:37-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:03:47-INFO: ***** Eval results *****
01:03:47-INFO:   Matthew's correlation = 0.533788717644728
01:03:47-INFO:   eval_accuracy = 0.8120805369127517
01:03:47-INFO:   eval_loss = 0.47447407855228946
01:03:47-INFO:   global_step = 0
01:03:47-INFO:   inference_time = 9.376528978347778
01:03:47-INFO:   loss = None
attention_head_mask ['8:12']
['8', '12']
01:03:47-INFO: ***** Running evaluation *****
01:03:47-INFO:   Num examples = 1043
01:03:47-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.51it/s]
01:03:56-INFO: ***** Eval results *****
01:03:56-INFO:   Matthew's correlation = 0.5311983410233877
01:03:56-INFO:   eval_accuracy = 0.8111217641418984
01:03:56-INFO:   eval_loss = 0.4817817053108504
01:03:56-INFO:   global_step = 0
01:03:56-INFO:   inference_time = 9.37357759475708
01:03:56-INFO:   loss = None
attention_head_mask ['9:1']
['9', '1']
01:03:56-INFO: ***** Running evaluation *****
01:03:56-INFO:   Num examples = 1043
01:03:56-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:06-INFO: ***** Eval results *****
01:04:06-INFO:   Matthew's correlation = 0.5311983410233877
01:04:06-INFO:   eval_accuracy = 0.8111217641418984
01:04:06-INFO:   eval_loss = 0.4785136061184334
01:04:06-INFO:   global_step = 0
01:04:06-INFO:   inference_time = 9.389691591262817
01:04:06-INFO:   loss = None
attention_head_mask ['9:2']
['9', '2']
01:04:06-INFO: ***** Running evaluation *****
01:04:06-INFO:   Num examples = 1043
01:04:06-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:15-INFO: ***** Eval results *****
01:04:15-INFO:   Matthew's correlation = 0.5338269593815457
01:04:15-INFO:   eval_accuracy = 0.8120805369127517
01:04:15-INFO:   eval_loss = 0.4754013830062115
01:04:15-INFO:   global_step = 0
01:04:15-INFO:   inference_time = 9.388617992401123
01:04:15-INFO:   loss = None
attention_head_mask ['9:3']
['9', '3']
01:04:15-INFO: ***** Running evaluation *****
01:04:15-INFO:   Num examples = 1043
01:04:15-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:24-INFO: ***** Eval results *****
01:04:24-INFO:   Matthew's correlation = 0.5339494412838712
01:04:24-INFO:   eval_accuracy = 0.8120805369127517
01:04:24-INFO:   eval_loss = 0.4839713381546916
01:04:24-INFO:   global_step = 0
01:04:24-INFO:   inference_time = 9.390625953674316
01:04:24-INFO:   loss = None
attention_head_mask ['9:4']
['9', '4']
01:04:24-INFO: ***** Running evaluation *****
01:04:24-INFO:   Num examples = 1043
01:04:24-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:34-INFO: ***** Eval results *****
01:04:34-INFO:   Matthew's correlation = 0.5311983410233877
01:04:34-INFO:   eval_accuracy = 0.8111217641418984
01:04:34-INFO:   eval_loss = 0.4844336146206567
01:04:34-INFO:   global_step = 0
01:04:34-INFO:   inference_time = 9.390755891799927
01:04:34-INFO:   loss = None
attention_head_mask ['9:5']
['9', '5']
01:04:34-INFO: ***** Running evaluation *****
01:04:34-INFO:   Num examples = 1043
01:04:34-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:43-INFO: ***** Eval results *****
01:04:43-INFO:   Matthew's correlation = 0.5340435327165364
01:04:43-INFO:   eval_accuracy = 0.8120805369127517
01:04:43-INFO:   eval_loss = 0.4901116698077231
01:04:43-INFO:   global_step = 0
01:04:43-INFO:   inference_time = 9.390704870223999
01:04:43-INFO:   loss = None
attention_head_mask ['9:6']
['9', '6']
01:04:43-INFO: ***** Running evaluation *****
01:04:43-INFO:   Num examples = 1043
01:04:43-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:04:53-INFO: ***** Eval results *****
01:04:53-INFO:   Matthew's correlation = 0.5341602366353293
01:04:53-INFO:   eval_accuracy = 0.8120805369127517
01:04:53-INFO:   eval_loss = 0.49140300646875845
01:04:53-INFO:   global_step = 0
01:04:53-INFO:   inference_time = 9.390690565109253
01:04:53-INFO:   loss = None
attention_head_mask ['9:7']
['9', '7']
01:04:53-INFO: ***** Running evaluation *****
01:04:53-INFO:   Num examples = 1043
01:04:53-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:02-INFO: ***** Eval results *****
01:05:02-INFO:   Matthew's correlation = 0.5340435327165364
01:05:02-INFO:   eval_accuracy = 0.8120805369127517
01:05:02-INFO:   eval_loss = 0.48222095541881793
01:05:02-INFO:   global_step = 0
01:05:02-INFO:   inference_time = 9.391326189041138
01:05:02-INFO:   loss = None
attention_head_mask ['9:8']
['9', '8']
01:05:02-INFO: ***** Running evaluation *****
01:05:02-INFO:   Num examples = 1043
01:05:02-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:12-INFO: ***** Eval results *****
01:05:12-INFO:   Matthew's correlation = 0.5285646777370838
01:05:12-INFO:   eval_accuracy = 0.8101629913710451
01:05:12-INFO:   eval_loss = 0.47680605428688455
01:05:12-INFO:   global_step = 0
01:05:12-INFO:   inference_time = 9.388962507247925
01:05:12-INFO:   loss = None
attention_head_mask ['9:9']
['9', '9']
01:05:12-INFO: ***** Running evaluation *****
01:05:12-INFO:   Num examples = 1043
01:05:12-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:21-INFO: ***** Eval results *****
01:05:21-INFO:   Matthew's correlation = 0.5161596159953151
01:05:21-INFO:   eval_accuracy = 0.8053691275167785
01:05:21-INFO:   eval_loss = 0.48434272882613266
01:05:21-INFO:   global_step = 0
01:05:21-INFO:   inference_time = 9.393851518630981
01:05:21-INFO:   loss = None
attention_head_mask ['9:10']
['9', '10']
01:05:21-INFO: ***** Running evaluation *****
01:05:21-INFO:   Num examples = 1043
01:05:21-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:30-INFO: ***** Eval results *****
01:05:30-INFO:   Matthew's correlation = 0.5364128958265776
01:05:30-INFO:   eval_accuracy = 0.8130393096836049
01:05:30-INFO:   eval_loss = 0.47521789496143657
01:05:30-INFO:   global_step = 0
01:05:30-INFO:   inference_time = 9.392579317092896
01:05:30-INFO:   loss = None
attention_head_mask ['9:11']
['9', '11']
01:05:30-INFO: ***** Running evaluation *****
01:05:30-INFO:   Num examples = 1043
01:05:30-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:40-INFO: ***** Eval results *****
01:05:40-INFO:   Matthew's correlation = 0.5338309424338816
01:05:40-INFO:   eval_accuracy = 0.8120805369127517
01:05:40-INFO:   eval_loss = 0.47071177512407303
01:05:40-INFO:   global_step = 0
01:05:40-INFO:   inference_time = 9.392451047897339
01:05:40-INFO:   loss = None
attention_head_mask ['9:12']
['9', '12']
01:05:40-INFO: ***** Running evaluation *****
01:05:40-INFO:   Num examples = 1043
01:05:40-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.50it/s]
01:05:49-INFO: ***** Eval results *****
01:05:49-INFO:   Matthew's correlation = 0.5364506086387147
01:05:49-INFO:   eval_accuracy = 0.8130393096836049
01:05:49-INFO:   eval_loss = 0.48098872331055725
01:05:49-INFO:   global_step = 0
01:05:49-INFO:   inference_time = 9.390446901321411
01:05:49-INFO:   loss = None
attention_head_mask ['10:1']
['10', '1']
01:05:49-INFO: ***** Running evaluation *****
01:05:49-INFO:   Num examples = 1043
01:05:49-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:05:59-INFO: ***** Eval results *****
01:05:59-INFO:   Matthew's correlation = 0.5364214937932232
01:05:59-INFO:   eval_accuracy = 0.8130393096836049
01:05:59-INFO:   eval_loss = 0.4785963213353446
01:05:59-INFO:   global_step = 0
01:05:59-INFO:   inference_time = 9.406681060791016
01:05:59-INFO:   loss = None
attention_head_mask ['10:2']
['10', '2']
01:05:59-INFO: ***** Running evaluation *****
01:05:59-INFO:   Num examples = 1043
01:05:59-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:08-INFO: ***** Eval results *****
01:06:08-INFO:   Matthew's correlation = 0.5338269593815457
01:06:08-INFO:   eval_accuracy = 0.8120805369127517
01:06:08-INFO:   eval_loss = 0.4807305040233063
01:06:08-INFO:   global_step = 0
01:06:08-INFO:   inference_time = 9.406357049942017
01:06:08-INFO:   loss = None
attention_head_mask ['10:3']
['10', '3']
01:06:08-INFO: ***** Running evaluation *****
01:06:08-INFO:   Num examples = 1043
01:06:08-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:18-INFO: ***** Eval results *****
01:06:18-INFO:   Matthew's correlation = 0.5259770638545269
01:06:18-INFO:   eval_accuracy = 0.8092042186001918
01:06:18-INFO:   eval_loss = 0.47851742420232657
01:06:18-INFO:   global_step = 0
01:06:18-INFO:   inference_time = 9.405070304870605
01:06:18-INFO:   loss = None
attention_head_mask ['10:4']
['10', '4']
01:06:18-INFO: ***** Running evaluation *****
01:06:18-INFO:   Num examples = 1043
01:06:18-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:27-INFO: ***** Eval results *****
01:06:27-INFO:   Matthew's correlation = 0.5261452181661114
01:06:27-INFO:   eval_accuracy = 0.8092042186001918
01:06:27-INFO:   eval_loss = 0.48646487656867865
01:06:27-INFO:   global_step = 0
01:06:27-INFO:   inference_time = 9.406810998916626
01:06:27-INFO:   loss = None
attention_head_mask ['10:5']
['10', '5']
01:06:27-INFO: ***** Running evaluation *****
01:06:27-INFO:   Num examples = 1043
01:06:27-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:37-INFO: ***** Eval results *****
01:06:37-INFO:   Matthew's correlation = 0.5338269593815457
01:06:37-INFO:   eval_accuracy = 0.8120805369127517
01:06:37-INFO:   eval_loss = 0.4789293577725237
01:06:37-INFO:   global_step = 0
01:06:37-INFO:   inference_time = 9.406052350997925
01:06:37-INFO:   loss = None
attention_head_mask ['10:6']
['10', '6']
01:06:37-INFO: ***** Running evaluation *****
01:06:37-INFO:   Num examples = 1043
01:06:37-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:46-INFO: ***** Eval results *****
01:06:46-INFO:   Matthew's correlation = 0.5364506086387147
01:06:46-INFO:   eval_accuracy = 0.8130393096836049
01:06:46-INFO:   eval_loss = 0.4797292306567683
01:06:46-INFO:   global_step = 0
01:06:46-INFO:   inference_time = 9.40573239326477
01:06:46-INFO:   loss = None
attention_head_mask ['10:7']
['10', '7']
01:06:46-INFO: ***** Running evaluation *****
01:06:46-INFO:   Num examples = 1043
01:06:46-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:06:56-INFO: ***** Eval results *****
01:06:56-INFO:   Matthew's correlation = 0.5311596898053897
01:06:56-INFO:   eval_accuracy = 0.8111217641418984
01:06:56-INFO:   eval_loss = 0.477650396751635
01:06:56-INFO:   global_step = 0
01:06:56-INFO:   inference_time = 9.408859491348267
01:06:56-INFO:   loss = None
attention_head_mask ['10:8']
['10', '8']
01:06:56-INFO: ***** Running evaluation *****
01:06:56-INFO:   Num examples = 1043
01:06:56-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:05-INFO: ***** Eval results *****
01:07:05-INFO:   Matthew's correlation = 0.533788717644728
01:07:05-INFO:   eval_accuracy = 0.8120805369127517
01:07:05-INFO:   eval_loss = 0.4798900986259634
01:07:05-INFO:   global_step = 0
01:07:05-INFO:   inference_time = 9.406654119491577
01:07:05-INFO:   loss = None
attention_head_mask ['10:9']
['10', '9']
01:07:05-INFO: ***** Running evaluation *****
01:07:05-INFO:   Num examples = 1043
01:07:05-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:14-INFO: ***** Eval results *****
01:07:14-INFO:   Matthew's correlation = 0.5286156744059349
01:07:14-INFO:   eval_accuracy = 0.8101629913710451
01:07:14-INFO:   eval_loss = 0.4805967861955816
01:07:14-INFO:   global_step = 0
01:07:14-INFO:   inference_time = 9.405142307281494
01:07:14-INFO:   loss = None
attention_head_mask ['10:10']
['10', '10']
01:07:14-INFO: ***** Running evaluation *****
01:07:14-INFO:   Num examples = 1043
01:07:14-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:24-INFO: ***** Eval results *****
01:07:24-INFO:   Matthew's correlation = 0.5311983410233877
01:07:24-INFO:   eval_accuracy = 0.8111217641418984
01:07:24-INFO:   eval_loss = 0.480125318422462
01:07:24-INFO:   global_step = 0
01:07:24-INFO:   inference_time = 9.405853509902954
01:07:24-INFO:   loss = None
attention_head_mask ['10:11']
['10', '11']
01:07:24-INFO: ***** Running evaluation *****
01:07:24-INFO:   Num examples = 1043
01:07:24-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:33-INFO: ***** Eval results *****
01:07:33-INFO:   Matthew's correlation = 0.5296111755015093
01:07:33-INFO:   eval_accuracy = 0.8101629913710451
01:07:33-INFO:   eval_loss = 0.4900043202620564
01:07:33-INFO:   global_step = 0
01:07:33-INFO:   inference_time = 9.405085325241089
01:07:33-INFO:   loss = None
attention_head_mask ['10:12']
['10', '12']
01:07:33-INFO: ***** Running evaluation *****
01:07:33-INFO:   Num examples = 1043
01:07:33-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:43-INFO: ***** Eval results *****
01:07:43-INFO:   Matthew's correlation = 0.5337975510473064
01:07:43-INFO:   eval_accuracy = 0.8120805369127517
01:07:43-INFO:   eval_loss = 0.47655083668051346
01:07:43-INFO:   global_step = 0
01:07:43-INFO:   inference_time = 9.408188104629517
01:07:43-INFO:   loss = None
attention_head_mask ['11:1']
['11', '1']
01:07:43-INFO: ***** Running evaluation *****
01:07:43-INFO:   Num examples = 1043
01:07:43-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:07:52-INFO: ***** Eval results *****
01:07:52-INFO:   Matthew's correlation = 0.5285348624455609
01:07:52-INFO:   eval_accuracy = 0.8101629913710451
01:07:52-INFO:   eval_loss = 0.47034493720892706
01:07:52-INFO:   global_step = 0
01:07:52-INFO:   inference_time = 9.425285577774048
01:07:52-INFO:   loss = None
attention_head_mask ['11:2']
['11', '2']
01:07:52-INFO: ***** Running evaluation *****
01:07:52-INFO:   Num examples = 1043
01:07:52-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:02-INFO: ***** Eval results *****
01:08:02-INFO:   Matthew's correlation = 0.5285368344613508
01:08:02-INFO:   eval_accuracy = 0.8101629913710451
01:08:02-INFO:   eval_loss = 0.47324275067358307
01:08:02-INFO:   global_step = 0
01:08:02-INFO:   inference_time = 9.423563003540039
01:08:02-INFO:   loss = None
attention_head_mask ['11:3']
['11', '3']
01:08:02-INFO: ***** Running evaluation *****
01:08:02-INFO:   Num examples = 1043
01:08:02-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:11-INFO: ***** Eval results *****
01:08:11-INFO:   Matthew's correlation = 0.5258867890805083
01:08:11-INFO:   eval_accuracy = 0.8092042186001918
01:08:11-INFO:   eval_loss = 0.47723384991739737
01:08:11-INFO:   global_step = 0
01:08:11-INFO:   inference_time = 9.420794010162354
01:08:11-INFO:   loss = None
attention_head_mask ['11:4']
['11', '4']
01:08:11-INFO: ***** Running evaluation *****
01:08:11-INFO:   Num examples = 1043
01:08:11-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:21-INFO: ***** Eval results *****
01:08:21-INFO:   Matthew's correlation = 0.5337975510473064
01:08:21-INFO:   eval_accuracy = 0.8120805369127517
01:08:21-INFO:   eval_loss = 0.47592531912254565
01:08:21-INFO:   global_step = 0
01:08:21-INFO:   inference_time = 9.424343347549438
01:08:21-INFO:   loss = None
attention_head_mask ['11:5']
['11', '5']
01:08:21-INFO: ***** Running evaluation *****
01:08:21-INFO:   Num examples = 1043
01:08:21-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:30-INFO: ***** Eval results *****
01:08:30-INFO:   Matthew's correlation = 0.5338269593815457
01:08:30-INFO:   eval_accuracy = 0.8120805369127517
01:08:30-INFO:   eval_loss = 0.4747259020805359
01:08:30-INFO:   global_step = 0
01:08:30-INFO:   inference_time = 9.421490669250488
01:08:30-INFO:   loss = None
attention_head_mask ['11:6']
['11', '6']
01:08:30-INFO: ***** Running evaluation *****
01:08:30-INFO:   Num examples = 1043
01:08:30-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:40-INFO: ***** Eval results *****
01:08:40-INFO:   Matthew's correlation = 0.5285646777370838
01:08:40-INFO:   eval_accuracy = 0.8101629913710451
01:08:40-INFO:   eval_loss = 0.47603088414127176
01:08:40-INFO:   global_step = 0
01:08:40-INFO:   inference_time = 9.422346830368042
01:08:40-INFO:   loss = None
attention_head_mask ['11:7']
['11', '7']
01:08:40-INFO: ***** Running evaluation *****
01:08:40-INFO:   Num examples = 1043
01:08:40-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:49-INFO: ***** Eval results *****
01:08:49-INFO:   Matthew's correlation = 0.5311686988596115
01:08:49-INFO:   eval_accuracy = 0.8111217641418984
01:08:49-INFO:   eval_loss = 0.47614031555977737
01:08:49-INFO:   global_step = 0
01:08:49-INFO:   inference_time = 9.421569108963013
01:08:49-INFO:   loss = None
attention_head_mask ['11:8']
['11', '8']
01:08:49-INFO: ***** Running evaluation *****
01:08:49-INFO:   Num examples = 1043
01:08:49-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:08:59-INFO: ***** Eval results *****
01:08:59-INFO:   Matthew's correlation = 0.5311983410233877
01:08:59-INFO:   eval_accuracy = 0.8111217641418984
01:08:59-INFO:   eval_loss = 0.47823391312902624
01:08:59-INFO:   global_step = 0
01:08:59-INFO:   inference_time = 9.423207998275757
01:08:59-INFO:   loss = None
attention_head_mask ['11:9']
['11', '9']
01:08:59-INFO: ***** Running evaluation *****
01:08:59-INFO:   Num examples = 1043
01:08:59-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:09:08-INFO: ***** Eval results *****
01:09:08-INFO:   Matthew's correlation = 0.5311686988596115
01:09:08-INFO:   eval_accuracy = 0.8111217641418984
01:09:08-INFO:   eval_loss = 0.47470297686981433
01:09:08-INFO:   global_step = 0
01:09:08-INFO:   inference_time = 9.42038869857788
01:09:08-INFO:   loss = None
attention_head_mask ['11:10']
['11', '10']
01:09:08-INFO: ***** Running evaluation *****
01:09:08-INFO:   Num examples = 1043
01:09:08-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:09:18-INFO: ***** Eval results *****
01:09:18-INFO:   Matthew's correlation = 0.5311708468019721
01:09:18-INFO:   eval_accuracy = 0.8111217641418984
01:09:18-INFO:   eval_loss = 0.47092741908449115
01:09:18-INFO:   global_step = 0
01:09:18-INFO:   inference_time = 9.422948837280273
01:09:18-INFO:   loss = None
attention_head_mask ['11:11']
['11', '11']
01:09:18-INFO: ***** Running evaluation *****
01:09:18-INFO:   Num examples = 1043
01:09:18-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:09:27-INFO: ***** Eval results *****
01:09:27-INFO:   Matthew's correlation = 0.5337975510473064
01:09:27-INFO:   eval_accuracy = 0.8120805369127517
01:09:27-INFO:   eval_loss = 0.4723887919928088
01:09:27-INFO:   global_step = 0
01:09:27-INFO:   inference_time = 9.421997547149658
01:09:27-INFO:   loss = None
attention_head_mask ['11:12']
['11', '12']
01:09:27-INFO: ***** Running evaluation *****
01:09:27-INFO:   Num examples = 1043
01:09:27-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.49it/s]
01:09:36-INFO: ***** Eval results *****
01:09:36-INFO:   Matthew's correlation = 0.523253926058104
01:09:36-INFO:   eval_accuracy = 0.8082454458293384
01:09:36-INFO:   eval_loss = 0.47662894066536066
01:09:36-INFO:   global_step = 0
01:09:36-INFO:   inference_time = 9.419411182403564
01:09:36-INFO:   loss = None
attention_head_mask ['12:1']
['12', '1']
01:09:36-INFO: ***** Running evaluation *****
01:09:36-INFO:   Num examples = 1043
01:09:36-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:09:46-INFO: ***** Eval results *****
01:09:46-INFO:   Matthew's correlation = 0.5258867890805083
01:09:46-INFO:   eval_accuracy = 0.8092042186001918
01:09:46-INFO:   eval_loss = 0.4757802667039813
01:09:46-INFO:   global_step = 0
01:09:46-INFO:   inference_time = 9.439796209335327
01:09:46-INFO:   loss = None
attention_head_mask ['12:2']
['12', '2']
01:09:46-INFO: ***** Running evaluation *****
01:09:46-INFO:   Num examples = 1043
01:09:46-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:09:55-INFO: ***** Eval results *****
01:09:55-INFO:   Matthew's correlation = 0.5205935908642821
01:09:55-INFO:   eval_accuracy = 0.8072866730584851
01:09:55-INFO:   eval_loss = 0.4724173110091325
01:09:55-INFO:   global_step = 0
01:09:55-INFO:   inference_time = 9.436969757080078
01:09:55-INFO:   loss = None
attention_head_mask ['12:3']
['12', '3']
01:09:55-INFO: ***** Running evaluation *****
01:09:55-INFO:   Num examples = 1043
01:09:55-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:05-INFO: ***** Eval results *****
01:10:05-INFO:   Matthew's correlation = 0.5259258925916567
01:10:05-INFO:   eval_accuracy = 0.8092042186001918
01:10:05-INFO:   eval_loss = 0.4834391668890462
01:10:05-INFO:   global_step = 0
01:10:05-INFO:   inference_time = 9.438762187957764
01:10:05-INFO:   loss = None
attention_head_mask ['12:4']
['12', '4']
01:10:05-INFO: ***** Running evaluation *****
01:10:05-INFO:   Num examples = 1043
01:10:05-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:14-INFO: ***** Eval results *****
01:10:14-INFO:   Matthew's correlation = 0.5341602366353293
01:10:14-INFO:   eval_accuracy = 0.8120805369127517
01:10:14-INFO:   eval_loss = 0.4827989057609529
01:10:14-INFO:   global_step = 0
01:10:14-INFO:   inference_time = 9.43798279762268
01:10:14-INFO:   loss = None
attention_head_mask ['12:5']
['12', '5']
01:10:14-INFO: ***** Running evaluation *****
01:10:14-INFO:   Num examples = 1043
01:10:14-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:24-INFO: ***** Eval results *****
01:10:24-INFO:   Matthew's correlation = 0.5259258925916567
01:10:24-INFO:   eval_accuracy = 0.8092042186001918
01:10:24-INFO:   eval_loss = 0.47764619304375217
01:10:24-INFO:   global_step = 0
01:10:24-INFO:   inference_time = 9.438262462615967
01:10:24-INFO:   loss = None
attention_head_mask ['12:6']
['12', '6']
01:10:24-INFO: ***** Running evaluation *****
01:10:24-INFO:   Num examples = 1043
01:10:24-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:33-INFO: ***** Eval results *****
01:10:33-INFO:   Matthew's correlation = 0.5285348624455609
01:10:33-INFO:   eval_accuracy = 0.8101629913710451
01:10:33-INFO:   eval_loss = 0.4745342650196769
01:10:33-INFO:   global_step = 0
01:10:33-INFO:   inference_time = 9.436221361160278
01:10:33-INFO:   loss = None
attention_head_mask ['12:7']
['12', '7']
01:10:33-INFO: ***** Running evaluation *****
01:10:33-INFO:   Num examples = 1043
01:10:33-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:43-INFO: ***** Eval results *****
01:10:43-INFO:   Matthew's correlation = 0.5206326433339101
01:10:43-INFO:   eval_accuracy = 0.8072866730584851
01:10:43-INFO:   eval_loss = 0.4762365260359013
01:10:43-INFO:   global_step = 0
01:10:43-INFO:   inference_time = 9.438116312026978
01:10:43-INFO:   loss = None
attention_head_mask ['12:8']
['12', '8']
01:10:43-INFO: ***** Running evaluation *****
01:10:43-INFO:   Num examples = 1043
01:10:43-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:10:52-INFO: ***** Eval results *****
01:10:52-INFO:   Matthew's correlation = 0.5258867890805083
01:10:52-INFO:   eval_accuracy = 0.8092042186001918
01:10:52-INFO:   eval_loss = 0.47685071126078116
01:10:52-INFO:   global_step = 0
01:10:52-INFO:   inference_time = 9.437542915344238
01:10:52-INFO:   loss = None
attention_head_mask ['12:9']
['12', '9']
01:10:52-INFO: ***** Running evaluation *****
01:10:52-INFO:   Num examples = 1043
01:10:52-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:11:02-INFO: ***** Eval results *****
01:11:02-INFO:   Matthew's correlation = 0.5232819075279987
01:11:02-INFO:   eval_accuracy = 0.8082454458293384
01:11:02-INFO:   eval_loss = 0.48187459260225296
01:11:02-INFO:   global_step = 0
01:11:02-INFO:   inference_time = 9.437889814376831
01:11:02-INFO:   loss = None
attention_head_mask ['12:10']
['12', '10']
01:11:02-INFO: ***** Running evaluation *****
01:11:02-INFO:   Num examples = 1043
01:11:02-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:11:11-INFO: ***** Eval results *****
01:11:11-INFO:   Matthew's correlation = 0.5152912157847293
01:11:11-INFO:   eval_accuracy = 0.8053691275167785
01:11:11-INFO:   eval_loss = 0.4746720531221592
01:11:11-INFO:   global_step = 0
01:11:11-INFO:   inference_time = 9.440897941589355
01:11:11-INFO:   loss = None
attention_head_mask ['12:11']
['12', '11']
01:11:11-INFO: ***** Running evaluation *****
01:11:11-INFO:   Num examples = 1043
01:11:11-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:11:21-INFO: ***** Eval results *****
01:11:21-INFO:   Matthew's correlation = 0.5232819075279987
01:11:21-INFO:   eval_accuracy = 0.8082454458293384
01:11:21-INFO:   eval_loss = 0.47665066226865305
01:11:21-INFO:   global_step = 0
01:11:21-INFO:   inference_time = 9.436286687850952
01:11:21-INFO:   loss = None
attention_head_mask ['12:12']
['12', '12']
01:11:21-INFO: ***** Running evaluation *****
01:11:21-INFO:   Num examples = 1043
01:11:21-INFO:   Batch size = 32
Evaluating: 100% 33/33 [00:09<00:00,  3.48it/s]
01:11:30-INFO: ***** Eval results *****
01:11:30-INFO:   Matthew's correlation = 0.5232519323928566
01:11:30-INFO:   eval_accuracy = 0.8082454458293384
01:11:30-INFO:   eval_loss = 0.47653821923516015
01:11:30-INFO:   global_step = 0
01:11:30-INFO:   inference_time = 9.440559148788452
01:11:30-INFO:   loss = None