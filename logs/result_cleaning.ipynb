{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf60530-145c-40d1-8f76-1c544f27700f",
   "metadata": {},
   "source": [
    "# Result logs cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a8937c61-373b-4eb6-ab03-c7b57725644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276e620-3772-4c70-9afb-0f34f128afc5",
   "metadata": {},
   "source": [
    "## Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6818e9e3-1ef7-4f73-a146-e3f16a892e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_idx(lines, substring):\n",
    "    '''\n",
    "    Obtain the beginning of the cleaning\n",
    "    '''\n",
    "    return [line_idx for line_idx, line in enumerate(lines) if substring in line]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e73f1b-8a00-4110-adab-1248e19e8f33",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean logs of attention head mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "0b16a2a6-fe52-48c0-8711-2bc96d668364",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = './logs'\n",
    "\n",
    "def get_sliced_logs(lines):\n",
    "    '''\n",
    "    Slice the entire logs of multiple experiemnts into seperate experiements.\n",
    "    '''\n",
    "    \n",
    "    # Step 1: Find the starting point.\n",
    "    starter_ides = get_start_idx(lines, 'attention_head_mask')\n",
    "    res = pd.DataFrame({'starter_ides': starter_ides})\n",
    "    \n",
    "    # Step 2: Base on all the start point, find the range\n",
    "    res['ender_ides'] = res.apply(lambda x: x.shift(-1))\n",
    "    res.iloc[-1, -1] = len(lines) # Upper bound of last row is the length!\n",
    "    res['ender_ides'] = res['ender_ides'].astype('int')\n",
    "\n",
    "    # Step 3: Obtain the corresponding lines base on the ranges\n",
    "    sliced_lines = []\n",
    "    for index, row in res.iterrows():\n",
    "        starter_idx = row['starter_ides']\n",
    "        ender_idx = row['ender_ides']\n",
    "        sliced_lines.append(lines[starter_idx:ender_idx])\n",
    "    return sliced_lines\n",
    "        \n",
    "def clean_log(logs):\n",
    "    '''\n",
    "    Clean the log of 1 experiment\n",
    "    '''\n",
    "    def clean_one_line(log_line):\n",
    "        '''\n",
    "        Clean 1 line of 1 log\n",
    "        Examples\n",
    "        --------\n",
    "        >>> clean_one_line(\"00:31:00-INFO:   Batch size = 8\")\n",
    "        ('Batch size', '8')\n",
    "        '''\n",
    "        if '-INFO:   ' in log_line:\n",
    "            result = log_line.split('-INFO:   ')\n",
    "\n",
    "            if result:\n",
    "                variable, value = result[1].split(' = ')\n",
    "                value = re.findall(r'[-+]?(?:\\d*\\.\\d+|\\d+)', value)\n",
    "                if value:\n",
    "                    value = value[0]\n",
    "                else:\n",
    "                    value = None\n",
    "                return variable, value\n",
    "    variables = []\n",
    "    values = []\n",
    "    for log_line in logs:\n",
    "        result = clean_one_line(log_line)\n",
    "        if result:\n",
    "            variable, value = result\n",
    "            variables.append(variable)\n",
    "            values.append(value)\n",
    "    return variables, values\n",
    "\n",
    "def get_experiment_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_sliced_logs(lines):\n",
    "        experiment = log[0].split(' ')[0]\n",
    "        parameters = eval(log[1].replace('\\n', ''))\n",
    "        variables, values = clean_log(log[2:])\n",
    "        # if task == 'rte':\n",
    "        #     print(task, parameters, variables, values)\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'drop_head_at_layer': int(parameters[0]),\n",
    "                           'drop_head': int(parameters[1]),\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    result.loc[result['variables'].isin(['acc', 'eval_accuracy']), 'variables'] = 'accuracy'\n",
    "    return result\n",
    "\n",
    "def get_baseline_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    header_start = min(get_start_idx(lines, 'Running evaluation'))\n",
    "    header_end = min(get_start_idx(lines, 'attention_head_mask'))\n",
    "    variables, values = clean_log(lines[header_start:header_end])\n",
    "\n",
    "    df = pd.DataFrame({'task': task,\n",
    "                       'variables': variables,\n",
    "                       'values': values})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d07a131b-8d4d-446c-95c5-68fcd7f5abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = []\n",
    "baseline_results = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/head_pruning') if '.ipynb_checkpoints' not in task]:\n",
    "    experiment_results.append(get_experiment_result(task))\n",
    "    baseline_results.append(get_baseline_result(task))\n",
    "    \n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/head_pruning_experiment_results.csv', index=False)\n",
    "pd.concat(experiment_results, axis=0).to_pickle('logs_cleaned/head_pruning_experiment_results.pickle')\n",
    "pd.concat(baseline_results, axis=0).to_csv('logs_cleaned/baseline_results.csv', index=False)\n",
    "pd.concat(baseline_results, axis=0).to_pickle('logs_cleaned/baseline_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499be002-6929-4af4-a819-c195a7cd4816",
   "metadata": {},
   "source": [
    "### Clean logs of layer pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "70ad81de-c908-4050-a4cd-fc3ae61b947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs_2(lines):\n",
    "    logs = []\n",
    "    start_ides = get_start_idx(lines, 'EXPERIMENT')\n",
    "    for log_idx, strat_idx in enumerate(start_ides):\n",
    "        if log_idx != len(start_ides) - 1:\n",
    "            end_idx = start_ides[log_idx+1]\n",
    "            log = lines[strat_idx:end_idx]\n",
    "            logs.append(log)\n",
    "    return logs\n",
    "\n",
    "def get_experiment_result_2(task):\n",
    "    with open(f'{LOGS_PATH}/layer_drop/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs_2(lines):\n",
    "        experiment = 'Remove Layers'\n",
    "        parameter = log[0].split(' remove layers ')[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    return result\n",
    "\n",
    "experiment_results_2 = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/layer_drop') if '.ipynb_checkpoints' not in task]:\n",
    "    experiment_results_2.append(get_experiment_result_2(task))\n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/layer_drop_results.csv', index=False)\n",
    "pd.concat(experiment_results, axis=0).to_pickle('logs_cleaned/layer_drop_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d82e1-23b4-4cc5-a6d9-f8c5f468a749",
   "metadata": {},
   "source": [
    "## Result re-formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bfd8c-0465-4405-9c7d-93ad0f949fa6",
   "metadata": {},
   "source": [
    "[GLUE](https://openreview.net/pdf?id=rJ4km2R5t7https://openreview.net/pdf?id=rJ4km2R5t7)\n",
    "\n",
    "<img width = \"50%\" src=\"https://cdn.mathpix.com/snip/images/pS3Kb2-_3rym-Zd4LhhdPZkqIs7-K1cMmMekf7QQ2HE.original.fullsize.png\" />\n",
    "\n",
    "- Note that at [BERT](https://arxiv.org/abs/1810.04805https://arxiv.org/abs/1810.04805), F1 scores are reported for QQP and MRPC.\n",
    "\n",
    "    <img width = \"50%\" src=\"https://cdn.mathpix.com/snip/images/TyBsRFSkPxAnklR4GijMblC8w8kcwXuTcAIVCqfaPdA.original.fullsize.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "88c3eb83-19b0-46b3-9e3f-5fe34486fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_mapper = pd.DataFrame(\n",
    "    {'task': ['sst-2', 'rte', 'mrpc', 'wnli', 'sts-b', 'cola'],\n",
    "     'benchmark': ['accuracy', 'accuracy', 'F-1 score', 'accuracy', 'spearmanr', \"Matthew's correlation\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "2cf7a627-2740-44a1-83b7-f5f71e62bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_prune = pd.read_pickle('logs_cleaned/head_pruning_experiment_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "24d3dc8a-0efb-4cf5-9278-46bb2dbfbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_prune.merge(benchmark_mapper, how='inner', on='task') \\\n",
    "    .query('variables == benchmark') \\\n",
    "    .drop(columns=['experiments', 'variables']).to_csv('logs_cleaned/head_prune_core_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f87bad-8b68-4633-b809-4157b2cd179b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
