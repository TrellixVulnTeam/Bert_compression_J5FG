{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf60530-145c-40d1-8f76-1c544f27700f",
   "metadata": {},
   "source": [
    "# Result logs cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8937c61-373b-4eb6-ab03-c7b57725644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49389816-7370-49d7-878b-68aba6dfc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)  # or 1000\n",
    "pd.set_option('display.max_rows', 50)  # or 1000\n",
    "pd.set_option('display.max_colwidth', 300)  # or 199"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276e620-3772-4c70-9afb-0f34f128afc5",
   "metadata": {},
   "source": [
    "## Initial Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6818e9e3-1ef7-4f73-a146-e3f16a892e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_idx(lines, substring):\n",
    "    '''\n",
    "    Obtain the beginning of the cleaning\n",
    "    '''\n",
    "    return [line_idx for line_idx, line in enumerate(lines) if substring in line]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e73f1b-8a00-4110-adab-1248e19e8f33",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Clean logs of attention head mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b16a2a6-fe52-48c0-8711-2bc96d668364",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = './logs'\n",
    "\n",
    "def get_sliced_logs(lines):\n",
    "    '''\n",
    "    Slice the entire logs of multiple experiemnts into seperate experiements.\n",
    "    '''\n",
    "    \n",
    "    # Step 1: Find the starting point.\n",
    "    starter_ides = get_start_idx(lines, 'attention_head_mask')\n",
    "    res = pd.DataFrame({'starter_ides': starter_ides})\n",
    "    \n",
    "    # Step 2: Base on all the start point, find the range\n",
    "    res['ender_ides'] = res.apply(lambda x: x.shift(-1))\n",
    "    res.iloc[-1, -1] = len(lines) # Upper bound of last row is the length!\n",
    "    res['ender_ides'] = res['ender_ides'].astype('int')\n",
    "\n",
    "    # Step 3: Obtain the corresponding lines base on the ranges\n",
    "    sliced_lines = []\n",
    "    for index, row in res.iterrows():\n",
    "        starter_idx = row['starter_ides']\n",
    "        ender_idx = row['ender_ides']\n",
    "        sliced_lines.append(lines[starter_idx:ender_idx])\n",
    "    return sliced_lines\n",
    "        \n",
    "def clean_log(logs):\n",
    "    '''\n",
    "    Clean the log of 1 experiment\n",
    "    '''\n",
    "    def clean_one_line(log_line):\n",
    "        '''\n",
    "        Clean 1 line of 1 log\n",
    "        Examples\n",
    "        --------\n",
    "        >>> clean_one_line(\"00:31:00-INFO:   Batch size = 8\")\n",
    "        ('Batch size', '8')\n",
    "        '''\n",
    "        if '-INFO:   ' in log_line:\n",
    "            result = log_line.split('-INFO:   ')\n",
    "            if result:\n",
    "                variable, value = result[1].split(' = ')\n",
    "                value = re.findall(r'[-+]?(?:\\d*\\.\\d+|\\d+)', value)\n",
    "                if value:\n",
    "                    value = value[0]\n",
    "                else:\n",
    "                    value = None\n",
    "                return variable, value\n",
    "        \n",
    "    variables = []\n",
    "    values = []\n",
    "    for log_line in logs:\n",
    "        result = clean_one_line(log_line)\n",
    "        if result:\n",
    "            variable, value = result\n",
    "            variables.append(variable)\n",
    "            values.append(value)\n",
    "    return variables, values\n",
    "\n",
    "def get_train_time(header_logs):\n",
    "    '''\n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_train_time(\"tot time 416.2169461250305 =========\")\n",
    "    416.2169461250305\n",
    "    '''\n",
    "    for header_log in header_logs:\n",
    "        #print(header_log)\n",
    "        if 'training time======' in header_log or (' =========' in header_log and 'tot ' in header_log) or ' training time======' in header_log:\n",
    "            train_time = re.search(r'[-+]?(?:\\d*\\.\\d+|\\d+)', header_log).group()\n",
    "            return train_time\n",
    "    return None\n",
    "\n",
    "def get_inference_time(header_logs):\n",
    "    '''\n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_inference_time(\"evaluation time 0.7100062370300293\")\n",
    "    0.7100062370300293\n",
    "    '''\n",
    "    for header_log in header_logs:\n",
    "        #print(header_log)\n",
    "        if 'evaluation time' in header_log:\n",
    "            train_time = re.search(r'[-+]?(?:\\d*\\.\\d+|\\d+)', header_log).group()\n",
    "            return train_time\n",
    "    return None\n",
    "        \n",
    "def get_experiment_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_sliced_logs(lines):\n",
    "        experiment = log[0].split(' ')[0]\n",
    "        parameters = eval(log[1].replace('\\n', ''))\n",
    "        variables, values = clean_log(log[2:])\n",
    "        # if task == 'rte':\n",
    "        #     print(task, parameters, variables, values)\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'drop_head_at_layer': int(parameters[0]),\n",
    "                           'drop_head': int(parameters[1]),\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    result.loc[result['variables'].isin(['acc', 'eval_accuracy']), 'variables'] = 'accuracy'\n",
    "    return result\n",
    "\n",
    "def get_baseline_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    header_start = min(get_start_idx(lines, 'Running evaluation'))\n",
    "    header_end = min(get_start_idx(lines, 'attention_head_mask'))\n",
    "    variables, values = clean_log(lines[header_start:header_end])\n",
    "    train_time = get_train_time(lines[:header_start])\n",
    "    if train_time:\n",
    "        variables.append('train_time')\n",
    "        values.append(train_time)\n",
    "    inference_time = get_inference_time(lines)\n",
    "    if inference_time:\n",
    "        variables.append('inference_time')\n",
    "        values.append(inference_time)\n",
    "            \n",
    "    result = pd.DataFrame({'task': task,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "    result.loc[result['variables'].isin(['acc', 'eval_accuracy']), 'variables'] = 'accuracy'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07a131b-8d4d-446c-95c5-68fcd7f5abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = []\n",
    "baseline_results = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/head_pruning') if '.ipynb_checkpoints' not in task]:\n",
    "    baseline_results.append(get_baseline_result(task))\n",
    "    experiment_results.append(get_experiment_result(task))\n",
    "    \n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/head_pruning_experiment_results.csv', index=False)\n",
    "pd.concat(experiment_results, axis=0).to_pickle('logs_cleaned/head_pruning_experiment_results.pickle')\n",
    "pd.concat(baseline_results, axis=0).to_csv('logs_cleaned/baseline_results.csv', index=False)\n",
    "pd.concat(baseline_results, axis=0).to_pickle('logs_cleaned/baseline_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499be002-6929-4af4-a819-c195a7cd4816",
   "metadata": {},
   "source": [
    "### Clean logs of layer pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ad81de-c908-4050-a4cd-fc3ae61b947e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_logs_2(lines):\n",
    "    logs = []\n",
    "    start_ides = get_start_idx(lines, 'EXPERIMENT')\n",
    "    for log_idx, strat_idx in enumerate(start_ides):\n",
    "        if log_idx != len(start_ides) - 1:\n",
    "            end_idx = start_ides[log_idx+1]\n",
    "            log = lines[strat_idx:end_idx]\n",
    "        else:\n",
    "            log = lines[strat_idx:]\n",
    "        logs.append(log)\n",
    "    return logs\n",
    "\n",
    "def get_experiment_result_2(task):\n",
    "    with open(f'{LOGS_PATH}/layer_drop/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs_2(lines):\n",
    "        experiment = 'Remove Layers'\n",
    "        parameter = log[0].split(' remove layers ')[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        train_time = get_train_time(log)\n",
    "        if train_time:\n",
    "            variables.append('train_time')\n",
    "            values.append(train_time)\n",
    "        inference_time = get_inference_time(log)\n",
    "        if inference_time:\n",
    "            variables.append('inference_time')\n",
    "            values.append(inference_time)\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    result.loc[result['variables'].isin(['acc', 'eval_accuracy']), 'variables'] = 'accuracy'\n",
    "    return result\n",
    "\n",
    "experiment_results_2 = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/layer_drop') if '.ipynb_checkpoints' not in task]:\n",
    "    experiment_results_2.append(get_experiment_result_2(task))\n",
    "pd.concat(experiment_results_2, axis=0).to_csv('logs_cleaned/layer_drop_results.csv', index=False)\n",
    "pd.concat(experiment_results_2, axis=0).to_pickle('logs_cleaned/layer_drop_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d82e1-23b4-4cc5-a6d9-f8c5f468a749",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Result re-formatting for heads pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bfd8c-0465-4405-9c7d-93ad0f949fa6",
   "metadata": {},
   "source": [
    "[GLUE](https://openreview.net/pdf?id=rJ4km2R5t7https://openreview.net/pdf?id=rJ4km2R5t7)\n",
    "\n",
    "<img width = \"50%\" src=\"https://cdn.mathpix.com/snip/images/pS3Kb2-_3rym-Zd4LhhdPZkqIs7-K1cMmMekf7QQ2HE.original.fullsize.png\" />\n",
    "\n",
    "- Note that at [BERT](https://arxiv.org/abs/1810.04805https://arxiv.org/abs/1810.04805), F1 scores are reported for QQP and MRPC.\n",
    "\n",
    "    <img width = \"50%\" src=\"https://cdn.mathpix.com/snip/images/TyBsRFSkPxAnklR4GijMblC8w8kcwXuTcAIVCqfaPdA.original.fullsize.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf7a627-2740-44a1-83b7-f5f71e62bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_prune = pd.read_pickle('logs_cleaned/head_pruning_experiment_results.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6071419-83bb-4663-b516-40a3f8b6c537",
   "metadata": {},
   "source": [
    "### Core scores of every experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88c3eb83-19b0-46b3-9e3f-5fe34486fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_mapper = pd.DataFrame(\n",
    "    {'task': ['sst-2', 'rte', 'mrpc', 'wnli', 'sts-b', 'cola'],\n",
    "     'benchmark': ['accuracy', 'accuracy', 'F-1 score', 'accuracy', 'spearmanr', \"Matthew's correlation\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24d3dc8a-0efb-4cf5-9278-46bb2dbfbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_prune_core_benchmark = head_prune.merge(benchmark_mapper, how='inner', on='task') \\\n",
    "    .query('variables == benchmark') \\\n",
    "    .drop(columns=['experiments', 'variables'])\n",
    "head_prune_core_benchmark.to_csv('logs_cleaned/head_prune_core_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f1f855-67fd-460e-8394-e951af22d887",
   "metadata": {},
   "source": [
    "### GLUE scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c2885b-e298-42cf-909d-4d32889ada96",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f76ec5a-d22a-4a05-8db6-56e2dc508140",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = pd.read_pickle('logs_cleaned/baseline_results.pickle')\n",
    "baseline_core_benchmark = baseline.merge(benchmark_mapper, how='inner', \n",
    "               left_on=['task', 'variables'],\n",
    "               right_on=['task', 'benchmark']) \\\n",
    "    .drop(columns=['variables']) \\\n",
    "    .rename(columns={'values': 'baseline'})\n",
    "baseline_core_benchmark['baseline'] = baseline_core_benchmark['baseline'].astype('double')\n",
    "baseline_core_benchmark.to_csv('logs_cleaned/baseline_core_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ac828-236f-4ce0-93bc-7e7017b11a87",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c8a78d-832b-4f60-a599-da6c0b5d47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_prune_core_benchmark['values'] = head_prune_core_benchmark['values'].astype('double')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b851d3ff-234e-4f6d-922b-8c9b1dccd225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005379</td>\n",
       "      <td>-0.006500</td>\n",
       "      <td>-0.005898</td>\n",
       "      <td>-0.009108</td>\n",
       "      <td>-0.008952</td>\n",
       "      <td>-0.014626</td>\n",
       "      <td>-0.009983</td>\n",
       "      <td>-0.007087</td>\n",
       "      <td>-0.008186</td>\n",
       "      <td>-0.009156</td>\n",
       "      <td>-0.009768</td>\n",
       "      <td>-0.002781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005869</td>\n",
       "      <td>-0.002797</td>\n",
       "      <td>-0.007298</td>\n",
       "      <td>-0.007884</td>\n",
       "      <td>-0.005798</td>\n",
       "      <td>-0.004140</td>\n",
       "      <td>-0.009235</td>\n",
       "      <td>-0.015561</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.014159</td>\n",
       "      <td>-0.012032</td>\n",
       "      <td>-0.018996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>-0.021481</td>\n",
       "      <td>-0.023172</td>\n",
       "      <td>-0.024453</td>\n",
       "      <td>-0.025173</td>\n",
       "      <td>-0.029516</td>\n",
       "      <td>-0.062614</td>\n",
       "      <td>-0.062530</td>\n",
       "      <td>-0.057031</td>\n",
       "      <td>-0.053495</td>\n",
       "      <td>-0.077953</td>\n",
       "      <td>-0.070548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.096419</td>\n",
       "      <td>-0.098221</td>\n",
       "      <td>-0.093843</td>\n",
       "      <td>-0.100176</td>\n",
       "      <td>-0.100281</td>\n",
       "      <td>-0.102900</td>\n",
       "      <td>-0.099230</td>\n",
       "      <td>-0.098148</td>\n",
       "      <td>-0.092852</td>\n",
       "      <td>-0.082303</td>\n",
       "      <td>-0.092527</td>\n",
       "      <td>-0.091420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.086843</td>\n",
       "      <td>-0.093080</td>\n",
       "      <td>-0.098205</td>\n",
       "      <td>-0.151903</td>\n",
       "      <td>-0.145662</td>\n",
       "      <td>-0.151990</td>\n",
       "      <td>-0.151336</td>\n",
       "      <td>-0.153239</td>\n",
       "      <td>-0.156442</td>\n",
       "      <td>-0.173080</td>\n",
       "      <td>-0.170316</td>\n",
       "      <td>-0.175261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.186006</td>\n",
       "      <td>-0.179811</td>\n",
       "      <td>-0.185567</td>\n",
       "      <td>-0.182454</td>\n",
       "      <td>-0.187551</td>\n",
       "      <td>-0.184524</td>\n",
       "      <td>-0.184981</td>\n",
       "      <td>-0.186574</td>\n",
       "      <td>-0.189523</td>\n",
       "      <td>-0.187186</td>\n",
       "      <td>-0.184743</td>\n",
       "      <td>-0.180867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.175022</td>\n",
       "      <td>-0.175160</td>\n",
       "      <td>-0.182925</td>\n",
       "      <td>-0.182463</td>\n",
       "      <td>-0.178944</td>\n",
       "      <td>-0.176547</td>\n",
       "      <td>-0.181029</td>\n",
       "      <td>-0.179775</td>\n",
       "      <td>-0.168324</td>\n",
       "      <td>-0.170164</td>\n",
       "      <td>-0.169337</td>\n",
       "      <td>-0.171992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.179130</td>\n",
       "      <td>-0.177025</td>\n",
       "      <td>-0.181518</td>\n",
       "      <td>-0.182744</td>\n",
       "      <td>-0.186339</td>\n",
       "      <td>-0.179484</td>\n",
       "      <td>-0.178311</td>\n",
       "      <td>-0.182333</td>\n",
       "      <td>-0.170191</td>\n",
       "      <td>-0.175672</td>\n",
       "      <td>-0.172345</td>\n",
       "      <td>-0.169897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.169829</td>\n",
       "      <td>-0.166242</td>\n",
       "      <td>-0.172903</td>\n",
       "      <td>-0.172677</td>\n",
       "      <td>-0.175056</td>\n",
       "      <td>-0.178014</td>\n",
       "      <td>-0.174588</td>\n",
       "      <td>-0.167839</td>\n",
       "      <td>-0.142535</td>\n",
       "      <td>-0.136854</td>\n",
       "      <td>-0.140835</td>\n",
       "      <td>-0.137587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.135881</td>\n",
       "      <td>-0.142173</td>\n",
       "      <td>-0.137087</td>\n",
       "      <td>-0.134012</td>\n",
       "      <td>-0.129973</td>\n",
       "      <td>-0.121409</td>\n",
       "      <td>-0.129586</td>\n",
       "      <td>-0.129693</td>\n",
       "      <td>-0.163039</td>\n",
       "      <td>-0.159994</td>\n",
       "      <td>-0.149896</td>\n",
       "      <td>-0.153944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.151567</td>\n",
       "      <td>-0.151779</td>\n",
       "      <td>-0.154988</td>\n",
       "      <td>-0.146411</td>\n",
       "      <td>-0.143277</td>\n",
       "      <td>-0.141961</td>\n",
       "      <td>-0.138327</td>\n",
       "      <td>-0.142914</td>\n",
       "      <td>-0.146178</td>\n",
       "      <td>-0.145589</td>\n",
       "      <td>-0.189876</td>\n",
       "      <td>-0.208343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.200801</td>\n",
       "      <td>-0.196476</td>\n",
       "      <td>-0.191010</td>\n",
       "      <td>-0.196897</td>\n",
       "      <td>-0.200754</td>\n",
       "      <td>-0.202763</td>\n",
       "      <td>-0.231964</td>\n",
       "      <td>-0.227201</td>\n",
       "      <td>-0.212137</td>\n",
       "      <td>-0.246741</td>\n",
       "      <td>-0.247641</td>\n",
       "      <td>-0.246770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.005379 -0.006500 -0.005898 -0.009108 -0.008952   \n",
       "2                  -0.005869 -0.002797 -0.007298 -0.007884 -0.005798   \n",
       "3                  -0.020481 -0.021481 -0.023172 -0.024453 -0.025173   \n",
       "4                  -0.096419 -0.098221 -0.093843 -0.100176 -0.100281   \n",
       "5                  -0.086843 -0.093080 -0.098205 -0.151903 -0.145662   \n",
       "6                  -0.186006 -0.179811 -0.185567 -0.182454 -0.187551   \n",
       "7                  -0.175022 -0.175160 -0.182925 -0.182463 -0.178944   \n",
       "8                  -0.179130 -0.177025 -0.181518 -0.182744 -0.186339   \n",
       "9                  -0.169829 -0.166242 -0.172903 -0.172677 -0.175056   \n",
       "10                 -0.135881 -0.142173 -0.137087 -0.134012 -0.129973   \n",
       "11                 -0.151567 -0.151779 -0.154988 -0.146411 -0.143277   \n",
       "12                 -0.200801 -0.196476 -0.191010 -0.196897 -0.200754   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.014626 -0.009983 -0.007087 -0.008186 -0.009156   \n",
       "2                  -0.004140 -0.009235 -0.015561 -0.014483 -0.014159   \n",
       "3                  -0.029516 -0.062614 -0.062530 -0.057031 -0.053495   \n",
       "4                  -0.102900 -0.099230 -0.098148 -0.092852 -0.082303   \n",
       "5                  -0.151990 -0.151336 -0.153239 -0.156442 -0.173080   \n",
       "6                  -0.184524 -0.184981 -0.186574 -0.189523 -0.187186   \n",
       "7                  -0.176547 -0.181029 -0.179775 -0.168324 -0.170164   \n",
       "8                  -0.179484 -0.178311 -0.182333 -0.170191 -0.175672   \n",
       "9                  -0.178014 -0.174588 -0.167839 -0.142535 -0.136854   \n",
       "10                 -0.121409 -0.129586 -0.129693 -0.163039 -0.159994   \n",
       "11                 -0.141961 -0.138327 -0.142914 -0.146178 -0.145589   \n",
       "12                 -0.202763 -0.231964 -0.227201 -0.212137 -0.246741   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                  -0.009768 -0.002781  \n",
       "2                  -0.012032 -0.018996  \n",
       "3                  -0.077953 -0.070548  \n",
       "4                  -0.092527 -0.091420  \n",
       "5                  -0.170316 -0.175261  \n",
       "6                  -0.184743 -0.180867  \n",
       "7                  -0.169337 -0.171992  \n",
       "8                  -0.172345 -0.169897  \n",
       "9                  -0.140835 -0.137587  \n",
       "10                 -0.149896 -0.153944  \n",
       "11                 -0.189876 -0.208343  \n",
       "12                 -0.247641 -0.246770  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average\n",
    "res = head_prune_core_benchmark \\\n",
    "    .merge(baseline_core_benchmark, how='left', on=['task', 'benchmark']) \\\n",
    "    .rename(columns={'values':'scores'}) \\\n",
    "    .assign(score_diff = lambda df: (df.scores - df.baseline) / df.baseline) \\\n",
    "    .groupby([\"drop_head_at_layer\", \"drop_head\"], as_index=False) \\\n",
    "    .agg(avg_glue = ('score_diff', 'mean')) \n",
    "\n",
    "res = res.pivot_table(index=['drop_head_at_layer'],\n",
    "                values=['avg_glue'],\n",
    "                columns=['drop_head'])\n",
    "\n",
    "#res.applymap(lambda row: str(round(row* 100, 2)) + '%')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbc5643c-3847-4c2b-a7e1-342366173e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By task\n",
    "def get_task_result(task, df = head_prune_core_benchmark):\n",
    "    \n",
    "    task_df = df.copy()[df['task'] == task]\n",
    "    res = task_df \\\n",
    "        .merge(baseline_core_benchmark, how='left', on=['task', 'benchmark']) \\\n",
    "        .rename(columns={'values':'scores'}) \\\n",
    "        .assign(score_diff = lambda df: (df.scores - df.baseline) / df.baseline) \\\n",
    "        .groupby([\"drop_head_at_layer\", \"drop_head\"], as_index=False) \\\n",
    "        .agg(avg_glue = ('score_diff', 'mean')) \n",
    "\n",
    "    res = res.pivot_table(index=['drop_head_at_layer'],\n",
    "                    values=['avg_glue'],\n",
    "                    columns=['drop_head'])\n",
    "\n",
    "    #res = res.applymap(lambda row: str(round(row* 100, 2)) + '%')\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebab9e76-0c71-4117-b1bf-8211291c471b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th>drop_head</th>\n",
       "      <th>values</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930046</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928899</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.930046</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927752</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.930046</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>cola</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>0.525887</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>cola</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.523282</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>cola</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>0.515291</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5026</th>\n",
       "      <td>cola</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.523282</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>cola</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.523252</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       task  drop_head_at_layer  drop_head    values              benchmark\n",
       "3     sst-2                   1          1  0.930046               accuracy\n",
       "11    sst-2                   1          2  0.928899               accuracy\n",
       "19    sst-2                   1          3  0.930046               accuracy\n",
       "27    sst-2                   1          4  0.927752               accuracy\n",
       "35    sst-2                   1          5  0.930046               accuracy\n",
       "...     ...                 ...        ...       ...                    ...\n",
       "5002   cola                  12          8  0.525887  Matthew's correlation\n",
       "5010   cola                  12          9  0.523282  Matthew's correlation\n",
       "5018   cola                  12         10  0.515291  Matthew's correlation\n",
       "5026   cola                  12         11  0.523282  Matthew's correlation\n",
       "5034   cola                  12         12  0.523252  Matthew's correlation\n",
       "\n",
       "[864 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_prune_core_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79e7918a-faf8-4e22-9106-7a8f22e0c908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th>drop_head</th>\n",
       "      <th>values</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.930046</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>rte</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689531</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>mrpc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895575</td>\n",
       "      <td>F-1 score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>wnli</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.563380</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>sts-b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882948</td>\n",
       "      <td>spearmanr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>cola</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560090</td>\n",
       "      <td>Matthew's correlation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       task  drop_head_at_layer  drop_head    values              benchmark\n",
       "3     sst-2                   1          1  0.930046               accuracy\n",
       "1154    rte                   1          1  0.689531               accuracy\n",
       "1586   mrpc                   1          1  0.895575              F-1 score\n",
       "2738   wnli                   1          1  0.563380               accuracy\n",
       "3172  sts-b                   1          1  0.882948              spearmanr\n",
       "3890   cola                   1          1  0.560090  Matthew's correlation"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_prune_core_benchmark.drop_duplicates(subset='task')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de3bef91-006d-4a9d-82da-8a09b3bfb7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.003937</td>\n",
       "      <td>-0.002171</td>\n",
       "      <td>-0.001767</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>-0.004765</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>-0.005697</td>\n",
       "      <td>-0.003121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>-0.002022</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.002163</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.002655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.004332</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>-0.035154</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.007936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017121</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.007638</td>\n",
       "      <td>0.008296</td>\n",
       "      <td>-0.010038</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002713</td>\n",
       "      <td>-0.001917</td>\n",
       "      <td>-0.001673</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002315</td>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>-0.011804</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>-0.003249</td>\n",
       "      <td>-0.019612</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.002851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.002851</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>-0.006686</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.007512</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>-0.006686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.013523</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.003249</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>-0.008812</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.002851</td>\n",
       "      <td>-0.008812</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.003249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.003249</td>\n",
       "      <td>-0.008812</td>\n",
       "      <td>-0.003249</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>-0.004971</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.017947</td>\n",
       "      <td>-0.004167</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>-0.005377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.005786</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.007098</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>-0.005377</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>-0.002456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.002456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.002456</td>\n",
       "      <td>-0.002456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.003937 -0.002171 -0.001767  0.001773  0.005338   \n",
       "2                   0.001380  0.000789  0.002551  0.000396  0.002551   \n",
       "3                   0.002288  0.003020  0.004332  0.002655  0.002655   \n",
       "4                  -0.017121  0.002551  0.004448 -0.000571 -0.000178   \n",
       "5                   0.002713 -0.001917 -0.001673 -0.015748  0.003464   \n",
       "6                  -0.005377 -0.004971  0.002123 -0.011804 -0.000351   \n",
       "7                  -0.002851 -0.003650 -0.006686 -0.001129 -0.008396   \n",
       "8                  -0.013523 -0.005377 -0.003249 -0.004567 -0.008396   \n",
       "9                  -0.003249 -0.008812 -0.003249 -0.004971 -0.004971   \n",
       "10                 -0.005377 -0.007098 -0.005786 -0.005377 -0.007098   \n",
       "11                 -0.002456 -0.000351 -0.000351 -0.002456  0.003836   \n",
       "12                 -0.004567 -0.002456 -0.002456 -0.002456 -0.002456   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.004765  0.000789  0.002163  0.004833  0.000396   \n",
       "2                   0.000000  0.006467 -0.002022  0.002382  0.002163   \n",
       "3                   0.001354 -0.035154  0.003606  0.002655  0.005657   \n",
       "4                   0.001951  0.006189  0.007995  0.007638  0.008296   \n",
       "5                   0.001951  0.002334  0.005555 -0.000178 -0.002456   \n",
       "6                   0.001366  0.000599 -0.003249 -0.019612 -0.004167   \n",
       "7                  -0.004567 -0.001522 -0.002063 -0.005377 -0.007512   \n",
       "8                  -0.000178 -0.008812 -0.004567 -0.002851 -0.008812   \n",
       "9                  -0.005377 -0.007098 -0.017947 -0.004167 -0.004567   \n",
       "10                 -0.004567 -0.005377 -0.007098 -0.003650 -0.005377   \n",
       "11                 -0.002456 -0.002456 -0.000351 -0.004567 -0.000351   \n",
       "12                 -0.002456 -0.002456 -0.002456 -0.002456 -0.000351   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                  -0.005697 -0.003121  \n",
       "2                   0.005075  0.002655  \n",
       "3                   0.002655  0.007936  \n",
       "4                  -0.010038  0.002334  \n",
       "5                  -0.002315 -0.000739  \n",
       "6                  -0.007098 -0.002851  \n",
       "7                  -0.001129 -0.006686  \n",
       "8                  -0.004567 -0.003249  \n",
       "9                   0.001746 -0.005377  \n",
       "10                 -0.001522 -0.002456  \n",
       "11                 -0.000351 -0.002456  \n",
       "12                 -0.002456 -0.002456  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('mrpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8869e45d-00ef-4f96-8c73-b4e2a95480dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006173</td>\n",
       "      <td>-0.004938</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.002469</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.004938</td>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.004938</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                   0.001235  0.000000  0.001235 -0.001235  0.001235   \n",
       "2                   0.002469  0.002469  0.001235  0.001235  0.000000   \n",
       "3                  -0.003704  0.000000  0.000000  0.000000  0.000000   \n",
       "4                   0.002469  0.001235  0.001235  0.002469  0.001235   \n",
       "5                   0.002469  0.001235  0.000000  0.001235  0.000000   \n",
       "6                  -0.002469  0.000000  0.000000 -0.003704 -0.003704   \n",
       "7                  -0.001235  0.001235  0.000000  0.001235  0.000000   \n",
       "8                  -0.002469 -0.003704  0.000000 -0.001235  0.001235   \n",
       "9                   0.000000 -0.003704  0.000000  0.000000  0.001235   \n",
       "10                  0.000000  0.000000  0.001235  0.001235  0.002469   \n",
       "11                 -0.002469  0.001235  0.000000  0.002469 -0.004938   \n",
       "12                 -0.003704 -0.003704  0.001235 -0.001235  0.000000   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                   0.000000 -0.001235 -0.001235 -0.002469 -0.001235   \n",
       "2                   0.000000  0.002469  0.001235  0.000000  0.001235   \n",
       "3                  -0.001235  0.001235  0.000000  0.000000  0.001235   \n",
       "4                   0.001235  0.002469  0.002469  0.001235 -0.002469   \n",
       "5                   0.001235  0.002469  0.003704  0.000000  0.001235   \n",
       "6                  -0.002469 -0.003704 -0.001235  0.000000 -0.006173   \n",
       "7                  -0.001235  0.002469  0.002469  0.000000  0.000000   \n",
       "8                   0.000000  0.000000  0.002469  0.001235  0.002469   \n",
       "9                   0.001235  0.002469  0.000000 -0.001235 -0.004938   \n",
       "10                 -0.001235  0.001235  0.000000  0.001235  0.001235   \n",
       "11                  0.002469 -0.001235 -0.001235  0.001235  0.002469   \n",
       "12                  0.000000  0.000000  0.000000  0.003704  0.000000   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                   0.003704  0.001235  \n",
       "2                   0.002469  0.000000  \n",
       "3                   0.000000  0.001235  \n",
       "4                   0.002469  0.002469  \n",
       "5                   0.001235  0.000000  \n",
       "6                  -0.004938  0.001235  \n",
       "7                   0.001235  0.002469  \n",
       "8                   0.000000  0.001235  \n",
       "9                  -0.002469  0.001235  \n",
       "10                 -0.001235  0.001235  \n",
       "11                  0.001235  0.000000  \n",
       "12                 -0.001235 -0.001235  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('sst-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c96a7d9-0d6d-4434-b22a-5a4243ebc539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008843</td>\n",
       "      <td>0.004685</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>-0.022753</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013643</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.031801</td>\n",
       "      <td>-0.004433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.018288</td>\n",
       "      <td>-0.004433</td>\n",
       "      <td>-0.027007</td>\n",
       "      <td>-0.022597</td>\n",
       "      <td>-0.031957</td>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.013579</td>\n",
       "      <td>-0.013421</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.026789</td>\n",
       "      <td>-0.013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.004657</td>\n",
       "      <td>-0.013860</td>\n",
       "      <td>-0.027476</td>\n",
       "      <td>-0.009130</td>\n",
       "      <td>-0.013799</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>-0.027352</td>\n",
       "      <td>-0.018288</td>\n",
       "      <td>-0.022753</td>\n",
       "      <td>-0.013705</td>\n",
       "      <td>-0.013705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.013421</td>\n",
       "      <td>-0.027476</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.027567</td>\n",
       "      <td>-0.009130</td>\n",
       "      <td>-0.022408</td>\n",
       "      <td>-0.022753</td>\n",
       "      <td>-0.023029</td>\n",
       "      <td>-0.022408</td>\n",
       "      <td>-0.031957</td>\n",
       "      <td>-0.018005</td>\n",
       "      <td>-0.018381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004555</td>\n",
       "      <td>-0.022970</td>\n",
       "      <td>-0.027625</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.027567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>-0.022970</td>\n",
       "      <td>-0.032190</td>\n",
       "      <td>-0.018381</td>\n",
       "      <td>-0.046108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.027589</td>\n",
       "      <td>-0.041467</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.027384</td>\n",
       "      <td>-0.041404</td>\n",
       "      <td>-0.027589</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>-0.027505</td>\n",
       "      <td>-0.036713</td>\n",
       "      <td>-0.046108</td>\n",
       "      <td>-0.046087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.036228</td>\n",
       "      <td>-0.036862</td>\n",
       "      <td>-0.069207</td>\n",
       "      <td>-0.074049</td>\n",
       "      <td>-0.055101</td>\n",
       "      <td>-0.027567</td>\n",
       "      <td>-0.060039</td>\n",
       "      <td>-0.046087</td>\n",
       "      <td>-0.036848</td>\n",
       "      <td>-0.036840</td>\n",
       "      <td>-0.022914</td>\n",
       "      <td>-0.041481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.036848</td>\n",
       "      <td>-0.046032</td>\n",
       "      <td>-0.055387</td>\n",
       "      <td>-0.046032</td>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.046087</td>\n",
       "      <td>-0.046087</td>\n",
       "      <td>-0.064701</td>\n",
       "      <td>-0.050723</td>\n",
       "      <td>-0.064537</td>\n",
       "      <td>-0.055387</td>\n",
       "      <td>-0.059971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.059971</td>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.055103</td>\n",
       "      <td>-0.059971</td>\n",
       "      <td>-0.054936</td>\n",
       "      <td>-0.054730</td>\n",
       "      <td>-0.054936</td>\n",
       "      <td>-0.064632</td>\n",
       "      <td>-0.086584</td>\n",
       "      <td>-0.050743</td>\n",
       "      <td>-0.055312</td>\n",
       "      <td>-0.050676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.050728</td>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.069211</td>\n",
       "      <td>-0.068913</td>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.050676</td>\n",
       "      <td>-0.060039</td>\n",
       "      <td>-0.055387</td>\n",
       "      <td>-0.064541</td>\n",
       "      <td>-0.059971</td>\n",
       "      <td>-0.062780</td>\n",
       "      <td>-0.055371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.064681</td>\n",
       "      <td>-0.069371</td>\n",
       "      <td>-0.055371</td>\n",
       "      <td>-0.055319</td>\n",
       "      <td>-0.064632</td>\n",
       "      <td>-0.060023</td>\n",
       "      <td>-0.059971</td>\n",
       "      <td>-0.060023</td>\n",
       "      <td>-0.060020</td>\n",
       "      <td>-0.055371</td>\n",
       "      <td>-0.074030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.069371</td>\n",
       "      <td>-0.078738</td>\n",
       "      <td>-0.069301</td>\n",
       "      <td>-0.054730</td>\n",
       "      <td>-0.069301</td>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.078668</td>\n",
       "      <td>-0.069371</td>\n",
       "      <td>-0.073980</td>\n",
       "      <td>-0.088121</td>\n",
       "      <td>-0.073980</td>\n",
       "      <td>-0.074033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.008843  0.004685 -0.009002 -0.009002  0.000291   \n",
       "2                  -0.018288 -0.004433 -0.027007 -0.022597 -0.031957   \n",
       "3                  -0.004657 -0.013860 -0.027476 -0.009130 -0.013799   \n",
       "4                  -0.013421 -0.027476 -0.000097 -0.027567 -0.009130   \n",
       "5                   0.004555 -0.022970 -0.027625 -0.004273 -0.000097   \n",
       "6                  -0.055319 -0.027589 -0.041467 -0.013886 -0.027384   \n",
       "7                  -0.036228 -0.036862 -0.069207 -0.074049 -0.055101   \n",
       "8                  -0.036848 -0.046032 -0.055387 -0.046032 -0.064684   \n",
       "9                  -0.059971 -0.055319 -0.055103 -0.059971 -0.054936   \n",
       "10                 -0.050728 -0.055319 -0.069211 -0.068913 -0.055319   \n",
       "11                 -0.064684 -0.064681 -0.069371 -0.055371 -0.055319   \n",
       "12                 -0.069371 -0.078738 -0.069301 -0.054730 -0.069301   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.022753  0.004848  0.000000  0.013643 -0.009002   \n",
       "2                  -0.009002 -0.013579 -0.013421 -0.004561 -0.004561   \n",
       "3                  -0.018288 -0.004720 -0.027352 -0.018288 -0.022753   \n",
       "4                  -0.022408 -0.022753 -0.023029 -0.022408 -0.031957   \n",
       "5                  -0.027567  0.000000 -0.004749 -0.022970 -0.032190   \n",
       "6                  -0.041404 -0.027589 -0.046108 -0.027505 -0.036713   \n",
       "7                  -0.027567 -0.060039 -0.046087 -0.036848 -0.036840   \n",
       "8                  -0.046087 -0.046087 -0.064701 -0.050723 -0.064537   \n",
       "9                  -0.054730 -0.054936 -0.064632 -0.086584 -0.050743   \n",
       "10                 -0.050676 -0.060039 -0.055387 -0.064541 -0.059971   \n",
       "11                 -0.064632 -0.060023 -0.059971 -0.060023 -0.060020   \n",
       "12                 -0.064684 -0.078668 -0.069371 -0.073980 -0.088121   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                  -0.031801 -0.004433  \n",
       "2                  -0.026789 -0.013705  \n",
       "3                  -0.013705 -0.013705  \n",
       "4                  -0.018005 -0.018381  \n",
       "5                  -0.018381 -0.046108  \n",
       "6                  -0.046108 -0.046087  \n",
       "7                  -0.022914 -0.041481  \n",
       "8                  -0.055387 -0.059971  \n",
       "9                  -0.055312 -0.050676  \n",
       "10                 -0.062780 -0.055371  \n",
       "11                 -0.055371 -0.074030  \n",
       "12                 -0.073980 -0.074033  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99ed4b39-af7c-4cd5-b796-e757cfb2c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   avg_glue                                                  \\\n",
       "drop_head                1      2      3      4      5      6     7      8    \n",
       "drop_head_at_layer                                                            \n",
       "1                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "2                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "3                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "4                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "5                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "6                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "7                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "8                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "9                     0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "10                    0.000  0.000  0.000  0.000  0.000  0.000  0.00  0.000   \n",
       "11                    0.025  0.025  0.025  0.000  0.000  0.000  0.00  0.000   \n",
       "12                    0.025  0.050  0.025  0.025  0.025  0.025 -0.15 -0.125   \n",
       "\n",
       "                                                \n",
       "drop_head              9      10     11     12  \n",
       "drop_head_at_layer                              \n",
       "1                   0.000  0.000  0.000  0.000  \n",
       "2                   0.000  0.000  0.000  0.000  \n",
       "3                   0.000  0.000  0.000  0.000  \n",
       "4                   0.000  0.000  0.000  0.000  \n",
       "5                   0.000  0.000  0.000  0.000  \n",
       "6                   0.000  0.000  0.000  0.000  \n",
       "7                   0.000  0.000  0.000  0.000  \n",
       "8                   0.000  0.000  0.000  0.000  \n",
       "9                   0.000  0.000  0.000  0.000  \n",
       "10                  0.000  0.000  0.000  0.000  \n",
       "11                  0.000  0.000  0.025  0.025  \n",
       "12                 -0.075 -0.225 -0.225 -0.225  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('wnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e293558f-e95e-43df-95ce-c3073e7b6398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000216</td>\n",
       "      <td>-0.000490</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.004166</td>\n",
       "      <td>-0.003828</td>\n",
       "      <td>-0.002761</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>-0.003583</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>-0.004303</td>\n",
       "      <td>-0.005239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.005390</td>\n",
       "      <td>-0.005349</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>-0.005827</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>-0.005582</td>\n",
       "      <td>-0.009744</td>\n",
       "      <td>-0.012493</td>\n",
       "      <td>-0.012927</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>-0.022177</td>\n",
       "      <td>-0.020872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.019377</td>\n",
       "      <td>-0.020613</td>\n",
       "      <td>-0.033839</td>\n",
       "      <td>-0.047937</td>\n",
       "      <td>-0.052715</td>\n",
       "      <td>-0.061494</td>\n",
       "      <td>-0.244739</td>\n",
       "      <td>-0.228354</td>\n",
       "      <td>-0.234247</td>\n",
       "      <td>-0.217931</td>\n",
       "      <td>-0.348976</td>\n",
       "      <td>-0.326445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.458135</td>\n",
       "      <td>-0.473326</td>\n",
       "      <td>-0.466077</td>\n",
       "      <td>-0.483080</td>\n",
       "      <td>-0.491051</td>\n",
       "      <td>-0.500744</td>\n",
       "      <td>-0.488975</td>\n",
       "      <td>-0.484016</td>\n",
       "      <td>-0.456396</td>\n",
       "      <td>-0.431789</td>\n",
       "      <td>-0.447538</td>\n",
       "      <td>-0.473404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.464128</td>\n",
       "      <td>-0.452775</td>\n",
       "      <td>-0.472755</td>\n",
       "      <td>-0.800327</td>\n",
       "      <td>-0.790162</td>\n",
       "      <td>-0.790125</td>\n",
       "      <td>-0.799996</td>\n",
       "      <td>-0.800866</td>\n",
       "      <td>-0.797552</td>\n",
       "      <td>-0.825582</td>\n",
       "      <td>-0.828074</td>\n",
       "      <td>-0.814976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.822104</td>\n",
       "      <td>-0.825796</td>\n",
       "      <td>-0.858675</td>\n",
       "      <td>-0.865329</td>\n",
       "      <td>-0.873357</td>\n",
       "      <td>-0.880021</td>\n",
       "      <td>-0.884321</td>\n",
       "      <td>-0.899620</td>\n",
       "      <td>-0.905403</td>\n",
       "      <td>-0.891448</td>\n",
       "      <td>-0.865699</td>\n",
       "      <td>-0.852882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.845716</td>\n",
       "      <td>-0.852710</td>\n",
       "      <td>-0.857552</td>\n",
       "      <td>-0.856732</td>\n",
       "      <td>-0.856320</td>\n",
       "      <td>-0.851557</td>\n",
       "      <td>-0.852722</td>\n",
       "      <td>-0.832970</td>\n",
       "      <td>-0.788229</td>\n",
       "      <td>-0.786889</td>\n",
       "      <td>-0.782960</td>\n",
       "      <td>-0.770872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.760404</td>\n",
       "      <td>-0.760883</td>\n",
       "      <td>-0.779187</td>\n",
       "      <td>-0.793349</td>\n",
       "      <td>-0.789779</td>\n",
       "      <td>-0.763974</td>\n",
       "      <td>-0.753429</td>\n",
       "      <td>-0.760534</td>\n",
       "      <td>-0.732909</td>\n",
       "      <td>-0.721611</td>\n",
       "      <td>-0.702320</td>\n",
       "      <td>-0.680476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.678829</td>\n",
       "      <td>-0.693722</td>\n",
       "      <td>-0.727782</td>\n",
       "      <td>-0.714708</td>\n",
       "      <td>-0.735256</td>\n",
       "      <td>-0.747672</td>\n",
       "      <td>-0.762320</td>\n",
       "      <td>-0.719328</td>\n",
       "      <td>-0.486303</td>\n",
       "      <td>-0.468565</td>\n",
       "      <td>-0.481284</td>\n",
       "      <td>-0.468137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.466875</td>\n",
       "      <td>-0.477804</td>\n",
       "      <td>-0.446199</td>\n",
       "      <td>-0.459225</td>\n",
       "      <td>-0.453223</td>\n",
       "      <td>-0.405312</td>\n",
       "      <td>-0.410771</td>\n",
       "      <td>-0.418238</td>\n",
       "      <td>-0.557432</td>\n",
       "      <td>-0.557392</td>\n",
       "      <td>-0.526150</td>\n",
       "      <td>-0.543993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.562232</td>\n",
       "      <td>-0.559059</td>\n",
       "      <td>-0.572388</td>\n",
       "      <td>-0.587213</td>\n",
       "      <td>-0.572471</td>\n",
       "      <td>-0.566632</td>\n",
       "      <td>-0.555992</td>\n",
       "      <td>-0.549776</td>\n",
       "      <td>-0.577813</td>\n",
       "      <td>-0.574609</td>\n",
       "      <td>-0.889255</td>\n",
       "      <td>-0.890877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.895752</td>\n",
       "      <td>-0.897807</td>\n",
       "      <td>-0.895408</td>\n",
       "      <td>-0.886426</td>\n",
       "      <td>-0.896231</td>\n",
       "      <td>-0.897514</td>\n",
       "      <td>-0.909378</td>\n",
       "      <td>-0.915099</td>\n",
       "      <td>-0.873807</td>\n",
       "      <td>-0.915692</td>\n",
       "      <td>-0.931894</td>\n",
       "      <td>-0.926613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.000216 -0.000490 -0.000215 -0.000031 -0.004166   \n",
       "2                  -0.005390 -0.005349 -0.005183 -0.005827 -0.005381   \n",
       "3                  -0.019377 -0.020613 -0.033839 -0.047937 -0.052715   \n",
       "4                  -0.458135 -0.473326 -0.466077 -0.483080 -0.491051   \n",
       "5                  -0.464128 -0.452775 -0.472755 -0.800327 -0.790162   \n",
       "6                  -0.822104 -0.825796 -0.858675 -0.865329 -0.873357   \n",
       "7                  -0.845716 -0.852710 -0.857552 -0.856732 -0.856320   \n",
       "8                  -0.760404 -0.760883 -0.779187 -0.793349 -0.789779   \n",
       "9                  -0.678829 -0.693722 -0.727782 -0.714708 -0.735256   \n",
       "10                 -0.466875 -0.477804 -0.446199 -0.459225 -0.453223   \n",
       "11                 -0.562232 -0.559059 -0.572388 -0.587213 -0.572471   \n",
       "12                 -0.895752 -0.897807 -0.895408 -0.886426 -0.896231   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.003828 -0.002761 -0.002426 -0.003583 -0.004070   \n",
       "2                  -0.005582 -0.009744 -0.012493 -0.012927 -0.017127   \n",
       "3                  -0.061494 -0.244739 -0.228354 -0.234247 -0.217931   \n",
       "4                  -0.500744 -0.488975 -0.484016 -0.456396 -0.431789   \n",
       "5                  -0.790125 -0.799996 -0.800866 -0.797552 -0.825582   \n",
       "6                  -0.880021 -0.884321 -0.899620 -0.905403 -0.891448   \n",
       "7                  -0.851557 -0.852722 -0.832970 -0.788229 -0.786889   \n",
       "8                  -0.763974 -0.753429 -0.760534 -0.732909 -0.721611   \n",
       "9                  -0.747672 -0.762320 -0.719328 -0.486303 -0.468565   \n",
       "10                 -0.405312 -0.410771 -0.418238 -0.557432 -0.557392   \n",
       "11                 -0.566632 -0.555992 -0.549776 -0.577813 -0.574609   \n",
       "12                 -0.897514 -0.909378 -0.915099 -0.873807 -0.915692   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                  -0.004303 -0.005239  \n",
       "2                  -0.022177 -0.020872  \n",
       "3                  -0.348976 -0.326445  \n",
       "4                  -0.447538 -0.473404  \n",
       "5                  -0.828074 -0.814976  \n",
       "6                  -0.865699 -0.852882  \n",
       "7                  -0.782960 -0.770872  \n",
       "8                  -0.702320 -0.680476  \n",
       "9                  -0.481284 -0.468137  \n",
       "10                 -0.526150 -0.543993  \n",
       "11                 -0.889255 -0.890877  \n",
       "12                 -0.931894 -0.926613  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('sts-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80fb060a-81f6-441a-b1cb-ae13cbbe1952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"12\" halign=\"left\">avg_glue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drop_head_at_layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.020513</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-0.046154</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.061538</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.020513</td>\n",
       "      <td>-0.005128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.015385</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-0.015385</td>\n",
       "      <td>-0.020513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-0.041026</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.071795</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.030769</td>\n",
       "      <td>-0.082051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.097436</td>\n",
       "      <td>-0.097436</td>\n",
       "      <td>-0.082051</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.087179</td>\n",
       "      <td>-0.097436</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.123077</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.087179</td>\n",
       "      <td>-0.107692</td>\n",
       "      <td>-0.092308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.102564</td>\n",
       "      <td>-0.097436</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.087179</td>\n",
       "      <td>-0.035897</td>\n",
       "      <td>-0.082051</td>\n",
       "      <td>-0.061538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.082051</td>\n",
       "      <td>-0.087179</td>\n",
       "      <td>-0.092308</td>\n",
       "      <td>-0.087179</td>\n",
       "      <td>-0.097436</td>\n",
       "      <td>-0.112821</td>\n",
       "      <td>-0.123077</td>\n",
       "      <td>-0.117949</td>\n",
       "      <td>-0.179487</td>\n",
       "      <td>-0.174359</td>\n",
       "      <td>-0.189744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.220513</td>\n",
       "      <td>-0.215385</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.220513</td>\n",
       "      <td>-0.184615</td>\n",
       "      <td>-0.194872</td>\n",
       "      <td>-0.169231</td>\n",
       "      <td>-0.184615</td>\n",
       "      <td>-0.184615</td>\n",
       "      <td>-0.184615</td>\n",
       "      <td>-0.184615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.164103</td>\n",
       "      <td>-0.158974</td>\n",
       "      <td>-0.164103</td>\n",
       "      <td>-0.164103</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.174359</td>\n",
       "      <td>-0.174359</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.179487</td>\n",
       "      <td>-0.189744</td>\n",
       "      <td>-0.210256</td>\n",
       "      <td>-0.215385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.235897</td>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.271795</td>\n",
       "      <td>-0.276923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.276923</td>\n",
       "      <td>-0.235897</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.225641</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>-0.276923</td>\n",
       "      <td>-0.292308</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>-0.302564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.292308</td>\n",
       "      <td>-0.312821</td>\n",
       "      <td>-0.302564</td>\n",
       "      <td>-0.271795</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.266667</td>\n",
       "      <td>-0.302564</td>\n",
       "      <td>-0.297436</td>\n",
       "      <td>-0.353846</td>\n",
       "      <td>-0.338462</td>\n",
       "      <td>-0.307692</td>\n",
       "      <td>-0.323077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.302564</td>\n",
       "      <td>-0.312821</td>\n",
       "      <td>-0.312821</td>\n",
       "      <td>-0.235897</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>-0.220513</td>\n",
       "      <td>-0.210256</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>-0.235897</td>\n",
       "      <td>-0.241026</td>\n",
       "      <td>-0.220513</td>\n",
       "      <td>-0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.256410</td>\n",
       "      <td>-0.246154</td>\n",
       "      <td>-0.205128</td>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.261538</td>\n",
       "      <td>-0.276923</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "      <td>-0.251282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    avg_glue                                          \\\n",
       "drop_head                 1         2         3         4         5    \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.020513 -0.041026 -0.025641 -0.046154 -0.056410   \n",
       "2                  -0.015385 -0.010256 -0.015385 -0.020513  0.000000   \n",
       "3                  -0.097436 -0.097436 -0.082051 -0.092308 -0.087179   \n",
       "4                  -0.092308 -0.092308 -0.102564 -0.092308 -0.102564   \n",
       "5                  -0.066667 -0.082051 -0.087179 -0.092308 -0.087179   \n",
       "6                  -0.230769 -0.220513 -0.215385 -0.200000 -0.220513   \n",
       "7                  -0.164103 -0.158974 -0.164103 -0.164103 -0.153846   \n",
       "8                  -0.261538 -0.246154 -0.251282 -0.251282 -0.256410   \n",
       "9                  -0.276923 -0.235897 -0.251282 -0.256410 -0.256410   \n",
       "10                 -0.292308 -0.312821 -0.302564 -0.271795 -0.266667   \n",
       "11                 -0.302564 -0.312821 -0.312821 -0.235897 -0.230769   \n",
       "12                 -0.256410 -0.246154 -0.205128 -0.261538 -0.261538   \n",
       "\n",
       "                                                                      \\\n",
       "drop_head                 6         7         8         9         10   \n",
       "drop_head_at_layer                                                     \n",
       "1                  -0.056410 -0.061538 -0.041026 -0.061538 -0.041026   \n",
       "2                  -0.010256 -0.041026 -0.066667 -0.071795 -0.066667   \n",
       "3                  -0.097436 -0.092308 -0.123077 -0.092308 -0.087179   \n",
       "4                  -0.097436 -0.092308 -0.092308 -0.087179 -0.035897   \n",
       "5                  -0.097436 -0.112821 -0.123077 -0.117949 -0.179487   \n",
       "6                  -0.184615 -0.194872 -0.169231 -0.184615 -0.184615   \n",
       "7                  -0.174359 -0.174359 -0.200000 -0.179487 -0.189744   \n",
       "8                  -0.266667 -0.261538 -0.266667 -0.235897 -0.261538   \n",
       "9                  -0.261538 -0.225641 -0.205128 -0.276923 -0.292308   \n",
       "10                 -0.266667 -0.302564 -0.297436 -0.353846 -0.338462   \n",
       "11                 -0.220513 -0.210256 -0.246154 -0.235897 -0.241026   \n",
       "12                 -0.276923 -0.251282 -0.251282 -0.251282 -0.251282   \n",
       "\n",
       "                                        \n",
       "drop_head                 11        12  \n",
       "drop_head_at_layer                      \n",
       "1                  -0.020513 -0.005128  \n",
       "2                  -0.030769 -0.082051  \n",
       "3                  -0.107692 -0.092308  \n",
       "4                  -0.082051 -0.061538  \n",
       "5                  -0.174359 -0.189744  \n",
       "6                  -0.184615 -0.184615  \n",
       "7                  -0.210256 -0.215385  \n",
       "8                  -0.271795 -0.276923  \n",
       "9                  -0.307692 -0.302564  \n",
       "10                 -0.307692 -0.323077  \n",
       "11                 -0.220513 -0.307692  \n",
       "12                 -0.251282 -0.251282  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_task_result('rte')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d629de-4c66-4803-9e91-c2cada578aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Results re-formmating for layer droping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08b6dd78-6e70-4059-8846-8fc515a46b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_mapper = pd.DataFrame(\n",
    "    {'task': ['sst-2', 'rte', 'mrpc', 'wnli', 'sts-b', 'cola'],\n",
    "     'benchmark': ['accuracy', 'accuracy', 'F-1 score', 'accuracy', 'spearmanr', \"Matthew's correlation\"]}\n",
    ")\n",
    "layer_drop = pd.read_pickle('logs_cleaned/layer_drop_results.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a2f0b73-413b-4c52-b98f-82c84f06f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the mixed parameters column\n",
    "layer_drop['strategy'] = layer_drop['parameter'].apply(lambda x: re.search(r'\\(([^()]+)\\)', x).group(1))\n",
    "layer_drop['n_layer_drop'] = layer_drop['strategy'].apply(lambda x: re.search(r'\\d', x).group()).astype('int')\n",
    "layer_drop['strategy'] = layer_drop['strategy'].apply(lambda x: re.sub(r' \\d', '', x).replace('drop bottom', 'bottom drop').title())\n",
    "layer_drop['layer_drop'] = layer_drop['parameter'].apply(lambda x: re.search(r'([^\\(]+)', x).group(1))\n",
    "layer_drop['values'] = layer_drop['values'].astype('double')\n",
    "layer_drop = layer_drop.drop(columns = 'parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df9a0bc-896f-4a75-a4ba-2db1bd39b2c0",
   "metadata": {},
   "source": [
    "### Core scores of every experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ade85e3-0996-49e6-a129-4a3fccd098ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_drop_core_benchmark = layer_drop.merge(benchmark_mapper, how='inner', on='task') \\\n",
    "    .query('variables == benchmark') \\\n",
    "    .drop(columns=['experiments', 'variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c2ddeeb-b2b1-444f-87a5-4d3fb5d85d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "task\n",
       "cola     9\n",
       "mrpc     9\n",
       "rte      9\n",
       "sst-2    9\n",
       "sts-b    9\n",
       "wnli     9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_drop_core_benchmark.groupby('task').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d2d4685-80ee-4f44-b69f-833b9573fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_drop_core_benchmark = layer_drop.merge(benchmark_mapper, how='inner', on='task') \\\n",
    "    .query('variables == benchmark') \\\n",
    "    .drop(columns=['experiments', 'variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "569c993a-ea7e-456c-bb4e-0022167d8b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>values</th>\n",
       "      <th>strategy</th>\n",
       "      <th>n_layer_drop</th>\n",
       "      <th>layer_drop</th>\n",
       "      <th>benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>0.923165</td>\n",
       "      <td>Top Drop</td>\n",
       "      <td>2</td>\n",
       "      <td>10,11</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>0.911697</td>\n",
       "      <td>Top Drop</td>\n",
       "      <td>4</td>\n",
       "      <td>8,9,10,11</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>0.904817</td>\n",
       "      <td>Top Drop</td>\n",
       "      <td>6</td>\n",
       "      <td>6,7,8,9,10,11</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>0.922018</td>\n",
       "      <td>Bottom Drop</td>\n",
       "      <td>2</td>\n",
       "      <td>0,1</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>0.905963</td>\n",
       "      <td>Bottom Drop</td>\n",
       "      <td>4</td>\n",
       "      <td>0,1,2,3</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     task    values     strategy  n_layer_drop      layer_drop benchmark\n",
       "5   sst-2  0.923165     Top Drop             2          10,11   accuracy\n",
       "16  sst-2  0.911697     Top Drop             4      8,9,10,11   accuracy\n",
       "27  sst-2  0.904817     Top Drop             6  6,7,8,9,10,11   accuracy\n",
       "38  sst-2  0.922018  Bottom Drop             2            0,1   accuracy\n",
       "49  sst-2  0.905963  Bottom Drop             4        0,1,2,3   accuracy"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_drop_core_benchmark.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37f6d1ed-82ec-4f0e-b2f0-5c59fefc9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_drop_core_benchmark.to_csv('logs_cleaned/layer_drop_core_benchmark.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725cafb-5ebb-412e-bd02-7a499515e31c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3af9f58-162e-48fc-b8b4-ce3bcc85032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_mapper = pd.DataFrame(\n",
    "    {'task': ['sst-2', 'rte', 'mrpc', 'wnli', 'sts-b', 'cola'],\n",
    "     'n_epoch': [3, 10, 3, 2, 3, 3]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8ef175c-3d61-4eca-8a9c-2f5d0523a83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>train_time_per_epoch_baseline</th>\n",
       "      <th>inference_latency_baseline</th>\n",
       "      <th>inference_throughput_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cola</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mrpc</td>\n",
       "      <td>55.606937</td>\n",
       "      <td>0.008895</td>\n",
       "      <td>112.422660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rte</td>\n",
       "      <td>30.705949</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>208.603726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>1092.251655</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>112.612348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sts-b</td>\n",
       "      <td>71.349972</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>202.293243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wnli</td>\n",
       "      <td>7.977739</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>194.409047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task  train_time_per_epoch_baseline  inference_latency_baseline  \\\n",
       "0   cola                     138.738982                    0.008906   \n",
       "1   mrpc                      55.606937                    0.008895   \n",
       "2    rte                      30.705949                    0.004794   \n",
       "3  sst-2                    1092.251655                    0.008880   \n",
       "4  sts-b                      71.349972                    0.004943   \n",
       "5   wnli                       7.977739                    0.005144   \n",
       "\n",
       "   inference_throughput_baseline  \n",
       "0                     112.284841  \n",
       "1                     112.422660  \n",
       "2                     208.603726  \n",
       "3                     112.612348  \n",
       "4                     202.293243  \n",
       "5                     194.409047  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COL = ['train_time', 'inference_time', 'Num examples']\n",
    "baseline_time = baseline. \\\n",
    "    query(\"variables in @TARGET_COL\"). \\\n",
    "    pivot_table(index=['task'],\n",
    "                values=['values'],\n",
    "                columns=['variables']).reset_index(col_level=0)\n",
    "baseline_time.columns = [col[0] for col in baseline_time.columns[:-len(TARGET_COL)]] + [col[1] for col in baseline_time.columns[-len(TARGET_COL):]]\n",
    "baseline_time = baseline_time.merge(EPOCHS_mapper, on=\"task\")\n",
    "baseline_time['train_time_per_epoch_baseline'] = baseline_time['train_time'] / baseline_time['n_epoch']\n",
    "baseline_time['inference_latency_baseline'] = baseline_time['inference_time'] / baseline_time['Num examples']\n",
    "baseline_time['inference_throughput_baseline'] = baseline_time['Num examples'] / baseline_time['inference_time']\n",
    "baseline_time = baseline_time[['task', 'train_time_per_epoch_baseline', 'inference_latency_baseline', 'inference_throughput_baseline']]\n",
    "baseline_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdb3571e-0ddf-4026-961a-0e92b54a36cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>experiments</th>\n",
       "      <th>strategy</th>\n",
       "      <th>n_layer_drop</th>\n",
       "      <th>layer_drop</th>\n",
       "      <th>Num examples</th>\n",
       "      <th>inference_time</th>\n",
       "      <th>train_time</th>\n",
       "      <th>n_epoch</th>\n",
       "      <th>train_time_per_epoch</th>\n",
       "      <th>inference_latency</th>\n",
       "      <th>inference_throughput</th>\n",
       "      <th>train_time_per_epoch_baseline</th>\n",
       "      <th>inference_latency_baseline</th>\n",
       "      <th>inference_throughput_baseline</th>\n",
       "      <th>diff_train_time_per_epoch</th>\n",
       "      <th>percentage_diff_train_time_per_epoch</th>\n",
       "      <th>diff_inference_latency</th>\n",
       "      <th>percentage_diff_inference_latency</th>\n",
       "      <th>diff_inference_throughput</th>\n",
       "      <th>percentage_diff_inference_throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cola</td>\n",
       "      <td>Remove Layers</td>\n",
       "      <td>Bottom Drop</td>\n",
       "      <td>2</td>\n",
       "      <td>0,1</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9.267023</td>\n",
       "      <td>326.441859</td>\n",
       "      <td>3</td>\n",
       "      <td>108.813953</td>\n",
       "      <td>0.008885</td>\n",
       "      <td>112.549625</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "      <td>-29.925029</td>\n",
       "      <td>-0.275011</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.002358</td>\n",
       "      <td>0.264784</td>\n",
       "      <td>0.002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cola</td>\n",
       "      <td>Remove Layers</td>\n",
       "      <td>Bottom Drop</td>\n",
       "      <td>4</td>\n",
       "      <td>0,1,2,3</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9.261514</td>\n",
       "      <td>262.275043</td>\n",
       "      <td>3</td>\n",
       "      <td>87.425014</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>112.616577</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "      <td>-51.313968</td>\n",
       "      <td>-0.586948</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>0.331736</td>\n",
       "      <td>0.002946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cola</td>\n",
       "      <td>Remove Layers</td>\n",
       "      <td>Bottom Drop</td>\n",
       "      <td>6</td>\n",
       "      <td>0,1,2,3,4,5</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9.268895</td>\n",
       "      <td>198.315210</td>\n",
       "      <td>3</td>\n",
       "      <td>66.105070</td>\n",
       "      <td>0.008887</td>\n",
       "      <td>112.526899</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "      <td>-72.633912</td>\n",
       "      <td>-1.098765</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.002156</td>\n",
       "      <td>0.242058</td>\n",
       "      <td>0.002151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cola</td>\n",
       "      <td>Remove Layers</td>\n",
       "      <td>Symmetric Drop</td>\n",
       "      <td>2</td>\n",
       "      <td>5,6</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9.273199</td>\n",
       "      <td>326.141196</td>\n",
       "      <td>3</td>\n",
       "      <td>108.713732</td>\n",
       "      <td>0.008891</td>\n",
       "      <td>112.474666</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "      <td>-30.025250</td>\n",
       "      <td>-0.276186</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.189825</td>\n",
       "      <td>0.001688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cola</td>\n",
       "      <td>Remove Layers</td>\n",
       "      <td>Symmetric Drop</td>\n",
       "      <td>4</td>\n",
       "      <td>4,5,6,7</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>9.271496</td>\n",
       "      <td>262.707250</td>\n",
       "      <td>3</td>\n",
       "      <td>87.569083</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>112.495329</td>\n",
       "      <td>138.738982</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>112.284841</td>\n",
       "      <td>-51.169899</td>\n",
       "      <td>-0.584337</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>0.210488</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   task    experiments        strategy  n_layer_drop    layer_drop  \\\n",
       "0  cola  Remove Layers     Bottom Drop             2          0,1    \n",
       "1  cola  Remove Layers     Bottom Drop             4      0,1,2,3    \n",
       "2  cola  Remove Layers     Bottom Drop             6  0,1,2,3,4,5    \n",
       "3  cola  Remove Layers  Symmetric Drop             2          5,6    \n",
       "4  cola  Remove Layers  Symmetric Drop             4      4,5,6,7    \n",
       "\n",
       "   Num examples  inference_time  train_time  n_epoch  train_time_per_epoch  \\\n",
       "0        1043.0        9.267023  326.441859        3            108.813953   \n",
       "1        1043.0        9.261514  262.275043        3             87.425014   \n",
       "2        1043.0        9.268895  198.315210        3             66.105070   \n",
       "3        1043.0        9.273199  326.141196        3            108.713732   \n",
       "4        1043.0        9.271496  262.707250        3             87.569083   \n",
       "\n",
       "   inference_latency  inference_throughput  train_time_per_epoch_baseline  \\\n",
       "0           0.008885            112.549625                     138.738982   \n",
       "1           0.008880            112.616577                     138.738982   \n",
       "2           0.008887            112.526899                     138.738982   \n",
       "3           0.008891            112.474666                     138.738982   \n",
       "4           0.008889            112.495329                     138.738982   \n",
       "\n",
       "   inference_latency_baseline  inference_throughput_baseline  \\\n",
       "0                    0.008906                     112.284841   \n",
       "1                    0.008906                     112.284841   \n",
       "2                    0.008906                     112.284841   \n",
       "3                    0.008906                     112.284841   \n",
       "4                    0.008906                     112.284841   \n",
       "\n",
       "   diff_train_time_per_epoch  percentage_diff_train_time_per_epoch  \\\n",
       "0                 -29.925029                             -0.275011   \n",
       "1                 -51.313968                             -0.586948   \n",
       "2                 -72.633912                             -1.098765   \n",
       "3                 -30.025250                             -0.276186   \n",
       "4                 -51.169899                             -0.584337   \n",
       "\n",
       "   diff_inference_latency  percentage_diff_inference_latency  \\\n",
       "0               -0.000021                          -0.002358   \n",
       "1               -0.000026                          -0.002954   \n",
       "2               -0.000019                          -0.002156   \n",
       "3               -0.000015                          -0.001691   \n",
       "4               -0.000017                          -0.001875   \n",
       "\n",
       "   diff_inference_throughput  percentage_diff_inference_throughput  \n",
       "0                   0.264784                              0.002353  \n",
       "1                   0.331736                              0.002946  \n",
       "2                   0.242058                              0.002151  \n",
       "3                   0.189825                              0.001688  \n",
       "4                   0.210488                              0.001871  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COL = ['train_time', 'inference_time', 'Num examples']\n",
    "layer_drop_time = layer_drop. \\\n",
    "    query(\"variables in @TARGET_COL\"). \\\n",
    "    pivot_table(index=['task', 'experiments', 'strategy', 'n_layer_drop', 'layer_drop'],\n",
    "                values=['values'],\n",
    "                columns=['variables']).reset_index(col_level=0)#. \\\n",
    "layer_drop_time.columns = [col[0] for col in layer_drop_time.columns[:-len(TARGET_COL)]] + [col[1] for col in layer_drop_time.columns[-len(TARGET_COL):]]\n",
    "layer_drop_time = layer_drop_time.merge(EPOCHS_mapper, on=\"task\")\n",
    "layer_drop_time['train_time_per_epoch'] = layer_drop_time['train_time'] / layer_drop_time['n_epoch']\n",
    "layer_drop_time['inference_latency'] = layer_drop_time['inference_time'] / layer_drop_time['Num examples']\n",
    "layer_drop_time['inference_throughput'] = layer_drop_time['Num examples'] / layer_drop_time['inference_time']\n",
    "layer_drop_time = layer_drop_time.merge(baseline_time, on='task', how='inner')\n",
    "\n",
    "for benchmark in ['train_time_per_epoch', 'inference_latency', 'inference_throughput']:\n",
    "    layer_drop_time['diff_' + benchmark] = layer_drop_time[benchmark] - layer_drop_time[benchmark + '_baseline']\n",
    "    layer_drop_time['percentage_diff_' + benchmark] = layer_drop_time['diff_' + benchmark] / layer_drop_time[benchmark]\n",
    "layer_drop_time.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d1e335-8e1e-47b1-ac26-1e27033f6b75",
   "metadata": {},
   "source": [
    "\n",
    "#### Layers 对 speedup的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa3c3f4d-42f4-4e7f-a0be-f0b49380a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_b_base_latency = 7.414978265762329 / 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80e0d69b-170b-4746-bf19-061fe7329abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sts_b_drop2_latency = (9.799771785736084 + 9.799771785736084 + 10.391596794128418) / 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19a1013a-c9c3-43ef-bf92-8cd8d8af3e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.348223343376953"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sts_b_drop2_latency / sts_b_base_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c38bc54b-71eb-436a-822c-63f0684dbf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>n_layer_drop</th>\n",
       "      <th>Fine-tuning speedup</th>\n",
       "      <th>Inference time save</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cola</td>\n",
       "      <td>2</td>\n",
       "      <td>1.275x</td>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cola</td>\n",
       "      <td>4</td>\n",
       "      <td>1.584x</td>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cola</td>\n",
       "      <td>6</td>\n",
       "      <td>2.097x</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mrpc</td>\n",
       "      <td>2</td>\n",
       "      <td>1.187x</td>\n",
       "      <td>0.001843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mrpc</td>\n",
       "      <td>4</td>\n",
       "      <td>1.473x</td>\n",
       "      <td>-0.000850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mrpc</td>\n",
       "      <td>6</td>\n",
       "      <td>1.950x</td>\n",
       "      <td>-0.000129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rte</td>\n",
       "      <td>2</td>\n",
       "      <td>1.179x</td>\n",
       "      <td>0.162885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rte</td>\n",
       "      <td>4</td>\n",
       "      <td>1.459x</td>\n",
       "      <td>0.278680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rte</td>\n",
       "      <td>6</td>\n",
       "      <td>1.912x</td>\n",
       "      <td>0.456770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.272x</td>\n",
       "      <td>0.001071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.525x</td>\n",
       "      <td>0.001682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.018x</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sts-b</td>\n",
       "      <td>2</td>\n",
       "      <td>0.745x</td>\n",
       "      <td>-0.347481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sts-b</td>\n",
       "      <td>4</td>\n",
       "      <td>0.933x</td>\n",
       "      <td>-0.056215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sts-b</td>\n",
       "      <td>6</td>\n",
       "      <td>1.229x</td>\n",
       "      <td>0.194031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wnli</td>\n",
       "      <td>2</td>\n",
       "      <td>1.186x</td>\n",
       "      <td>0.180482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wnli</td>\n",
       "      <td>4</td>\n",
       "      <td>1.489x</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wnli</td>\n",
       "      <td>6</td>\n",
       "      <td>1.965x</td>\n",
       "      <td>0.460209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     task  n_layer_drop Fine-tuning speedup  Inference time save\n",
       "0    cola             2              1.275x             0.001905\n",
       "1    cola             4              1.584x             0.002427\n",
       "2    cola             6              2.097x             0.002035\n",
       "3    mrpc             2              1.187x             0.001843\n",
       "4    mrpc             4              1.473x            -0.000850\n",
       "5    mrpc             6              1.950x            -0.000129\n",
       "6     rte             2              1.179x             0.162885\n",
       "7     rte             4              1.459x             0.278680\n",
       "8     rte             6              1.912x             0.456770\n",
       "9   sst-2             2              1.272x             0.001071\n",
       "10  sst-2             4              1.525x             0.001682\n",
       "11  sst-2             6              2.018x             0.001105\n",
       "12  sts-b             2              0.745x            -0.347481\n",
       "13  sts-b             4              0.933x            -0.056215\n",
       "14  sts-b             6              1.229x             0.194031\n",
       "15   wnli             2              1.186x             0.180482\n",
       "16   wnli             4              1.489x             0.339300\n",
       "17   wnli             6              1.965x             0.460209"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_speedup(df):\n",
    "    df_output = df[['task', 'n_layer_drop']].iloc[0]\n",
    "    df_output['Fine-tuning speedup'] = sum(df['train_time_per_epoch_baseline']) / sum(df['train_time_per_epoch'])\n",
    "    df_output['Fine-tuning speedup'] = '%.3f' % df_output['Fine-tuning speedup']  + 'x'\n",
    "    df_output['Inference time save'] = sum(df['inference_latency_baseline'] - df['inference_latency']) / sum(df['inference_latency_baseline'])\n",
    "    #df_output['Inference time save(%)'] = 100 * df_output['Inference time save(%)']\n",
    "    return df_output\n",
    "layer_drop_time.groupby(['task', 'n_layer_drop'], as_index=False).apply(get_speedup).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3936f121-52d1-4c1a-9d3a-f0b3b01cdad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>n_layer_drop</th>\n",
       "      <th>Fine-tuning speedup</th>\n",
       "      <th>Inference time save</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rte</td>\n",
       "      <td>2</td>\n",
       "      <td>1.179x</td>\n",
       "      <td>0.162885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rte</td>\n",
       "      <td>4</td>\n",
       "      <td>1.459x</td>\n",
       "      <td>0.278680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rte</td>\n",
       "      <td>6</td>\n",
       "      <td>1.912x</td>\n",
       "      <td>0.456770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wnli</td>\n",
       "      <td>2</td>\n",
       "      <td>1.186x</td>\n",
       "      <td>0.180482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wnli</td>\n",
       "      <td>4</td>\n",
       "      <td>1.489x</td>\n",
       "      <td>0.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wnli</td>\n",
       "      <td>6</td>\n",
       "      <td>1.965x</td>\n",
       "      <td>0.460209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    task  n_layer_drop Fine-tuning speedup  Inference time save\n",
       "6    rte             2              1.179x             0.162885\n",
       "7    rte             4              1.459x             0.278680\n",
       "8    rte             6              1.912x             0.456770\n",
       "15  wnli             2              1.186x             0.180482\n",
       "16  wnli             4              1.489x             0.339300\n",
       "17  wnli             6              1.965x             0.460209"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_drop_time.groupby(['task', 'n_layer_drop'], as_index=False).apply(get_speedup).reset_index(drop=True). \\\n",
    "    query('task in [\"rte\", \"wnli\"]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
