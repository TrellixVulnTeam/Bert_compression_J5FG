训练 full SST-2:

tot 3276.75496506691 =========
02:24:31-INFO: loading archive file <https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz> from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02:24:31-INFO: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmprs399nrn
02:24:36-INFO: Model config {
"attention_probs_dropout_prob": 0.1,
"hidden_act": "gelu",
"hidden_dropout_prob": 0.1,
"hidden_size": 768,
"initializer_range": 0.02,
"intermediate_size": 3072,
"max_position_embeddings": 512,
"num_attention_heads": 12,
"num_hidden_layers": 12,
"type_vocab_size": 2,
"vocab_size": 30522
}
测试：
02:24:39-INFO: ***** Running evaluation *****
02:24:39-INFO:   Num examples = 872
02:24:39-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:24:46-INFO: ***** Eval results *****
02:24:46-INFO:   Accuracy = 0.9288990825688074
02:24:46-INFO:   eval_accuracy = 0.9288990825688074
02:24:46-INFO:   eval_loss = 0.23426478555692093
02:24:46-INFO:   global_step = 6315
02:24:46-INFO:   inference_time = 7.743378162384033
02:24:46-INFO:   loss = 0.13983491269350995





========test

Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.
02:27:48-INFO: device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
{'cola': <class 'classifier_data.ColaProcessor'>, 'mnli': <class 'classifier_data.MnliProcessor'>, 'mnli-mis': <class 'classifier_data.MnliMismatchedProcessor'>, 'mrpc': <class 'classifier_data.MrpcProcessor'>, 'sst-2': <class 'classifier_data.Sst2Processor'>}
02:27:48-INFO: loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
02:27:49-INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02:27:49-INFO: extracting archive file /root/.pytorch_pretrained_bert/distributed_-1/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpxts9_ngl
02:27:54-INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

02:27:57-INFO: Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
02:27:57-INFO: Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
02:28:02-INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
02:28:02-INFO: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp_xuh7idt
02:28:08-INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

剪枝测试：
attention_head_mask ['1:1']
['1', '1']
02:28:10-INFO: ***** Running evaluation *****
02:28:10-INFO:   Num examples = 872
02:28:10-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:28:18-INFO: ***** Eval results *****
02:28:18-INFO:   Accuracy = 0.930045871559633
02:28:18-INFO:   eval_accuracy = 0.930045871559633
02:28:18-INFO:   eval_loss = 0.23572358821651765
02:28:18-INFO:   global_step = 0
02:28:18-INFO:   inference_time = 7.750413179397583
02:28:18-INFO:   loss = None
attention_head_mask ['1:2']
['1', '2']
02:28:18-INFO: ***** Running evaluation *****
02:28:18-INFO:   Num examples = 872
02:28:18-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:28:26-INFO: ***** Eval results *****
02:28:26-INFO:   Accuracy = 0.9288990825688074
02:28:26-INFO:   eval_accuracy = 0.9288990825688074
02:28:26-INFO:   eval_loss = 0.22957886329719
02:28:26-INFO:   global_step = 0
02:28:26-INFO:   inference_time = 7.729496955871582
02:28:26-INFO:   loss = None
attention_head_mask ['1:3']
['1', '3']
02:28:26-INFO: ***** Running evaluation *****
02:28:26-INFO:   Num examples = 872
02:28:26-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:28:33-INFO: ***** Eval results *****
02:28:33-INFO:   Accuracy = 0.930045871559633
02:28:33-INFO:   eval_accuracy = 0.930045871559633
02:28:33-INFO:   eval_loss = 0.23564235094402516
02:28:33-INFO:   global_step = 0
02:28:33-INFO:   inference_time = 7.728451728820801
02:28:33-INFO:   loss = None
attention_head_mask ['1:4']
['1', '4']
02:28:33-INFO: ***** Running evaluation *****
02:28:33-INFO:   Num examples = 872
02:28:33-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:28:41-INFO: ***** Eval results *****
02:28:41-INFO:   Accuracy = 0.9277522935779816
02:28:41-INFO:   eval_accuracy = 0.9277522935779816
02:28:41-INFO:   eval_loss = 0.2321222499012947
02:28:41-INFO:   global_step = 0
02:28:41-INFO:   inference_time = 7.729111194610596
02:28:41-INFO:   loss = None
attention_head_mask ['1:5']
['1', '5']
02:28:41-INFO: ***** Running evaluation *****
02:28:41-INFO:   Num examples = 872
02:28:41-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:28:49-INFO: ***** Eval results *****
02:28:49-INFO:   Accuracy = 0.930045871559633
02:28:49-INFO:   eval_accuracy = 0.930045871559633
02:28:49-INFO:   eval_loss = 0.2367012897240264
02:28:49-INFO:   global_step = 0
02:28:49-INFO:   inference_time = 7.728532075881958
02:28:49-INFO:   loss = None
attention_head_mask ['1:6']
['1', '6']
02:28:49-INFO: ***** Running evaluation *****
02:28:49-INFO:   Num examples = 872
02:28:49-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:28:57-INFO: ***** Eval results *****
02:28:57-INFO:   Accuracy = 0.9288990825688074
02:28:57-INFO:   eval_accuracy = 0.9288990825688074
02:28:57-INFO:   eval_loss = 0.2269506218976208
02:28:57-INFO:   global_step = 0
02:28:57-INFO:   inference_time = 7.727540016174316
02:28:57-INFO:   loss = None
attention_head_mask ['1:7']
['1', '7']
02:28:57-INFO: ***** Running evaluation *****
02:28:57-INFO:   Num examples = 872
02:28:57-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:05-INFO: ***** Eval results *****
02:29:05-INFO:   Accuracy = 0.9277522935779816
02:29:05-INFO:   eval_accuracy = 0.9277522935779816
02:29:05-INFO:   eval_loss = 0.23393984059137957
02:29:05-INFO:   global_step = 0
02:29:05-INFO:   inference_time = 7.7311625480651855
02:29:05-INFO:   loss = None
attention_head_mask ['1:8']
['1', '8']
02:29:05-INFO: ***** Running evaluation *****
02:29:05-INFO:   Num examples = 872
02:29:05-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:12-INFO: ***** Eval results *****
02:29:12-INFO:   Accuracy = 0.9277522935779816
02:29:12-INFO:   eval_accuracy = 0.9277522935779816
02:29:12-INFO:   eval_loss = 0.23664165527692863
02:29:12-INFO:   global_step = 0
02:29:12-INFO:   inference_time = 7.726896524429321
02:29:12-INFO:   loss = None
attention_head_mask ['1:9']
['1', '9']
02:29:12-INFO: ***** Running evaluation *****
02:29:12-INFO:   Num examples = 872
02:29:12-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:20-INFO: ***** Eval results *****
02:29:20-INFO:   Accuracy = 0.926605504587156
02:29:20-INFO:   eval_accuracy = 0.926605504587156
02:29:20-INFO:   eval_loss = 0.22887067004506076
02:29:20-INFO:   global_step = 0
02:29:20-INFO:   inference_time = 7.728217124938965
02:29:20-INFO:   loss = None
attention_head_mask ['1:10']
['1', '10']
02:29:20-INFO: ***** Running evaluation *****
02:29:20-INFO:   Num examples = 872
02:29:20-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:28-INFO: ***** Eval results *****
02:29:28-INFO:   Accuracy = 0.9277522935779816
02:29:28-INFO:   eval_accuracy = 0.9277522935779816
02:29:28-INFO:   eval_loss = 0.23243194246398552
02:29:28-INFO:   global_step = 0
02:29:28-INFO:   inference_time = 7.727656126022339
02:29:28-INFO:   loss = None
attention_head_mask ['1:11']
['1', '11']
02:29:28-INFO: ***** Running evaluation *****
02:29:28-INFO:   Num examples = 872
02:29:28-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:36-INFO: ***** Eval results *****
02:29:36-INFO:   Accuracy = 0.9323394495412844
02:29:36-INFO:   eval_accuracy = 0.9323394495412844
02:29:36-INFO:   eval_loss = 0.2300624315227781
02:29:36-INFO:   global_step = 0
02:29:36-INFO:   inference_time = 7.728579998016357
02:29:36-INFO:   loss = None
attention_head_mask ['1:12']
['1', '12']
02:29:36-INFO: ***** Running evaluation *****
02:29:36-INFO:   Num examples = 872
02:29:36-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:29:43-INFO: ***** Eval results *****
02:29:43-INFO:   Accuracy = 0.930045871559633
02:29:43-INFO:   eval_accuracy = 0.930045871559633
02:29:43-INFO:   eval_loss = 0.232066045116101
02:29:43-INFO:   global_step = 0
02:29:43-INFO:   inference_time = 7.729733467102051
02:29:43-INFO:   loss = None
attention_head_mask ['2:1']
['2', '1']
02:29:43-INFO: ***** Running evaluation *****
02:29:43-INFO:   Num examples = 872
02:29:43-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:29:51-INFO: ***** Eval results *****
02:29:51-INFO:   Accuracy = 0.9311926605504587
02:29:51-INFO:   eval_accuracy = 0.9311926605504587
02:29:51-INFO:   eval_loss = 0.23346928766529476
02:29:51-INFO:   global_step = 0
02:29:51-INFO:   inference_time = 7.7404725551605225
02:29:51-INFO:   loss = None
attention_head_mask ['2:2']
['2', '2']
02:29:51-INFO: ***** Running evaluation *****
02:29:51-INFO:   Num examples = 872
02:29:51-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:29:59-INFO: ***** Eval results *****
02:29:59-INFO:   Accuracy = 0.9311926605504587
02:29:59-INFO:   eval_accuracy = 0.9311926605504587
02:29:59-INFO:   eval_loss = 0.2309270240366459
02:29:59-INFO:   global_step = 0
02:29:59-INFO:   inference_time = 7.740814208984375
02:29:59-INFO:   loss = None
attention_head_mask ['2:3']
['2', '3']
02:29:59-INFO: ***** Running evaluation *****
02:29:59-INFO:   Num examples = 872
02:29:59-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:07-INFO: ***** Eval results *****
02:30:07-INFO:   Accuracy = 0.930045871559633
02:30:07-INFO:   eval_accuracy = 0.930045871559633
02:30:07-INFO:   eval_loss = 0.23099217071597064
02:30:07-INFO:   global_step = 0
02:30:07-INFO:   inference_time = 7.741201877593994
02:30:07-INFO:   loss = None
attention_head_mask ['2:4']
['2', '4']
02:30:07-INFO: ***** Running evaluation *****
02:30:07-INFO:   Num examples = 872
02:30:07-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:15-INFO: ***** Eval results *****
02:30:15-INFO:   Accuracy = 0.930045871559633
02:30:15-INFO:   eval_accuracy = 0.930045871559633
02:30:15-INFO:   eval_loss = 0.23001149483025074
02:30:15-INFO:   global_step = 0
02:30:15-INFO:   inference_time = 7.741677522659302
02:30:15-INFO:   loss = None
attention_head_mask ['2:5']
['2', '5']
02:30:15-INFO: ***** Running evaluation *****
02:30:15-INFO:   Num examples = 872
02:30:15-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:22-INFO: ***** Eval results *****
02:30:22-INFO:   Accuracy = 0.9288990825688074
02:30:22-INFO:   eval_accuracy = 0.9288990825688074
02:30:22-INFO:   eval_loss = 0.2313683547212609
02:30:22-INFO:   global_step = 0
02:30:22-INFO:   inference_time = 7.741473197937012
02:30:22-INFO:   loss = None
attention_head_mask ['2:6']
['2', '6']
02:30:22-INFO: ***** Running evaluation *****
02:30:22-INFO:   Num examples = 872
02:30:22-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:30-INFO: ***** Eval results *****
02:30:30-INFO:   Accuracy = 0.9288990825688074
02:30:30-INFO:   eval_accuracy = 0.9288990825688074
02:30:30-INFO:   eval_loss = 0.23097278044692107
02:30:30-INFO:   global_step = 0
02:30:30-INFO:   inference_time = 7.740198373794556
02:30:30-INFO:   loss = None
attention_head_mask ['2:7']
['2', '7']
02:30:30-INFO: ***** Running evaluation *****
02:30:30-INFO:   Num examples = 872
02:30:30-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:38-INFO: ***** Eval results *****
02:30:38-INFO:   Accuracy = 0.9311926605504587
02:30:38-INFO:   eval_accuracy = 0.9311926605504587
02:30:38-INFO:   eval_loss = 0.2295539771605815
02:30:38-INFO:   global_step = 0
02:30:38-INFO:   inference_time = 7.741871118545532
02:30:38-INFO:   loss = None
attention_head_mask ['2:8']
['2', '8']
02:30:38-INFO: ***** Running evaluation *****
02:30:38-INFO:   Num examples = 872
02:30:38-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:46-INFO: ***** Eval results *****
02:30:46-INFO:   Accuracy = 0.930045871559633
02:30:46-INFO:   eval_accuracy = 0.930045871559633
02:30:46-INFO:   eval_loss = 0.22861903799431665
02:30:46-INFO:   global_step = 0
02:30:46-INFO:   inference_time = 7.741168260574341
02:30:46-INFO:   loss = None
attention_head_mask ['2:9']
['2', '9']
02:30:46-INFO: ***** Running evaluation *****
02:30:46-INFO:   Num examples = 872
02:30:46-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:30:53-INFO: ***** Eval results *****
02:30:53-INFO:   Accuracy = 0.9288990825688074
02:30:53-INFO:   eval_accuracy = 0.9288990825688074
02:30:53-INFO:   eval_loss = 0.22987947227167232
02:30:53-INFO:   global_step = 0
02:30:53-INFO:   inference_time = 7.742199182510376
02:30:53-INFO:   loss = None
attention_head_mask ['2:10']
['2', '10']
02:30:53-INFO: ***** Running evaluation *****
02:30:53-INFO:   Num examples = 872
02:30:53-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:01-INFO: ***** Eval results *****
02:31:01-INFO:   Accuracy = 0.930045871559633
02:31:01-INFO:   eval_accuracy = 0.930045871559633
02:31:01-INFO:   eval_loss = 0.23283259623817035
02:31:01-INFO:   global_step = 0
02:31:01-INFO:   inference_time = 7.742317199707031
02:31:01-INFO:   loss = None
attention_head_mask ['2:11']
['2', '11']
02:31:01-INFO: ***** Running evaluation *****
02:31:01-INFO:   Num examples = 872
02:31:01-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:09-INFO: ***** Eval results *****
02:31:09-INFO:   Accuracy = 0.9311926605504587
02:31:09-INFO:   eval_accuracy = 0.9311926605504587
02:31:09-INFO:   eval_loss = 0.23029052426240273
02:31:09-INFO:   global_step = 0
02:31:09-INFO:   inference_time = 7.741181135177612
02:31:09-INFO:   loss = None
attention_head_mask ['2:12']
['2', '12']
02:31:09-INFO: ***** Running evaluation *****
02:31:09-INFO:   Num examples = 872
02:31:09-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:17-INFO: ***** Eval results *****
02:31:17-INFO:   Accuracy = 0.9288990825688074
02:31:17-INFO:   eval_accuracy = 0.9288990825688074
02:31:17-INFO:   eval_loss = 0.23642386669026955
02:31:17-INFO:   global_step = 0
02:31:17-INFO:   inference_time = 7.7412261962890625
02:31:17-INFO:   loss = None
attention_head_mask ['3:1']
['3', '1']
02:31:17-INFO: ***** Running evaluation *****
02:31:17-INFO:   Num examples = 872
02:31:17-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:25-INFO: ***** Eval results *****
02:31:25-INFO:   Accuracy = 0.9254587155963303
02:31:25-INFO:   eval_accuracy = 0.9254587155963303
02:31:25-INFO:   eval_loss = 0.23669620869415148
02:31:25-INFO:   global_step = 0
02:31:25-INFO:   inference_time = 7.754271745681763
02:31:25-INFO:   loss = None
attention_head_mask ['3:2']
['3', '2']
02:31:25-INFO: ***** Running evaluation *****
02:31:25-INFO:   Num examples = 872
02:31:25-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:32-INFO: ***** Eval results *****
02:31:32-INFO:   Accuracy = 0.9288990825688074
02:31:32-INFO:   eval_accuracy = 0.9288990825688074
02:31:32-INFO:   eval_loss = 0.2352415586688689
02:31:32-INFO:   global_step = 0
02:31:32-INFO:   inference_time = 7.754134893417358
02:31:32-INFO:   loss = None
attention_head_mask ['3:3']
['3', '3']
02:31:32-INFO: ***** Running evaluation *****
02:31:32-INFO:   Num examples = 872
02:31:32-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:40-INFO: ***** Eval results *****
02:31:40-INFO:   Accuracy = 0.9288990825688074
02:31:40-INFO:   eval_accuracy = 0.9288990825688074
02:31:40-INFO:   eval_loss = 0.23493641069425003
02:31:40-INFO:   global_step = 0
02:31:40-INFO:   inference_time = 7.75306248664856
02:31:40-INFO:   loss = None
attention_head_mask ['3:4']
['3', '4']
02:31:40-INFO: ***** Running evaluation *****
02:31:40-INFO:   Num examples = 872
02:31:40-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:31:48-INFO: ***** Eval results *****
02:31:48-INFO:   Accuracy = 0.9288990825688074
02:31:48-INFO:   eval_accuracy = 0.9288990825688074
02:31:48-INFO:   eval_loss = 0.23490822820791177
02:31:48-INFO:   global_step = 0
02:31:48-INFO:   inference_time = 7.754455089569092
02:31:48-INFO:   loss = None
attention_head_mask ['3:5']
['3', '5']
02:31:48-INFO: ***** Running evaluation *****
02:31:48-INFO:   Num examples = 872
02:31:48-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:31:56-INFO: ***** Eval results *****
02:31:56-INFO:   Accuracy = 0.9288990825688074
02:31:56-INFO:   eval_accuracy = 0.9288990825688074
02:31:56-INFO:   eval_loss = 0.23337585359279597
02:31:56-INFO:   global_step = 0
02:31:56-INFO:   inference_time = 7.756183624267578
02:31:56-INFO:   loss = None
attention_head_mask ['3:6']
['3', '6']
02:31:56-INFO: ***** Running evaluation *****
02:31:56-INFO:   Num examples = 872
02:31:56-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:32:04-INFO: ***** Eval results *****
02:32:04-INFO:   Accuracy = 0.9277522935779816
02:32:04-INFO:   eval_accuracy = 0.9277522935779816
02:32:04-INFO:   eval_loss = 0.23871736734041146
02:32:04-INFO:   global_step = 0
02:32:04-INFO:   inference_time = 7.753817558288574
02:32:04-INFO:   loss = None
attention_head_mask ['3:7']
['3', '7']
02:32:04-INFO: ***** Running evaluation *****
02:32:04-INFO:   Num examples = 872
02:32:04-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:32:11-INFO: ***** Eval results *****
02:32:11-INFO:   Accuracy = 0.930045871559633
02:32:11-INFO:   eval_accuracy = 0.930045871559633
02:32:11-INFO:   eval_loss = 0.24253488970654352
02:32:11-INFO:   global_step = 0
02:32:11-INFO:   inference_time = 7.754010200500488
02:32:11-INFO:   loss = None
attention_head_mask ['3:8']
['3', '8']
02:32:11-INFO: ***** Running evaluation *****
02:32:11-INFO:   Num examples = 872
02:32:11-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:32:19-INFO: ***** Eval results *****
02:32:19-INFO:   Accuracy = 0.9288990825688074
02:32:19-INFO:   eval_accuracy = 0.9288990825688074
02:32:19-INFO:   eval_loss = 0.23699436642761743
02:32:19-INFO:   global_step = 0
02:32:19-INFO:   inference_time = 7.754465818405151
02:32:19-INFO:   loss = None
attention_head_mask ['3:9']
['3', '9']
02:32:19-INFO: ***** Running evaluation *****
02:32:19-INFO:   Num examples = 872
02:32:19-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:32:27-INFO: ***** Eval results *****
02:32:27-INFO:   Accuracy = 0.9288990825688074
02:32:27-INFO:   eval_accuracy = 0.9288990825688074
02:32:27-INFO:   eval_loss = 0.23634429355817183
02:32:27-INFO:   global_step = 0
02:32:27-INFO:   inference_time = 7.755911588668823
02:32:27-INFO:   loss = None
attention_head_mask ['3:10']
['3', '10']
02:32:27-INFO: ***** Running evaluation *****
02:32:27-INFO:   Num examples = 872
02:32:27-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:32:35-INFO: ***** Eval results *****
02:32:35-INFO:   Accuracy = 0.930045871559633
02:32:35-INFO:   eval_accuracy = 0.930045871559633
02:32:35-INFO:   eval_loss = 0.2348129146599344
02:32:35-INFO:   global_step = 0
02:32:35-INFO:   inference_time = 7.753474235534668
02:32:35-INFO:   loss = None
attention_head_mask ['3:11']
['3', '11']
02:32:35-INFO: ***** Running evaluation *****
02:32:35-INFO:   Num examples = 872
02:32:35-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:32:43-INFO: ***** Eval results *****
02:32:43-INFO:   Accuracy = 0.9288990825688074
02:32:43-INFO:   eval_accuracy = 0.9288990825688074
02:32:43-INFO:   eval_loss = 0.23592058017051645
02:32:43-INFO:   global_step = 0
02:32:43-INFO:   inference_time = 7.753981113433838
02:32:43-INFO:   loss = None
attention_head_mask ['3:12']
['3', '12']
02:32:43-INFO: ***** Running evaluation *****
02:32:43-INFO:   Num examples = 872
02:32:43-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:32:50-INFO: ***** Eval results *****
02:32:50-INFO:   Accuracy = 0.930045871559633
02:32:50-INFO:   eval_accuracy = 0.930045871559633
02:32:50-INFO:   eval_loss = 0.23546426696702838
02:32:50-INFO:   global_step = 0
02:32:50-INFO:   inference_time = 7.755461931228638
02:32:50-INFO:   loss = None
attention_head_mask ['4:1']
['4', '1']
02:32:50-INFO: ***** Running evaluation *****
02:32:50-INFO:   Num examples = 872
02:32:50-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:32:58-INFO: ***** Eval results *****
02:32:58-INFO:   Accuracy = 0.9311926605504587
02:32:58-INFO:   eval_accuracy = 0.9311926605504587
02:32:58-INFO:   eval_loss = 0.23680588756022708
02:32:58-INFO:   global_step = 0
02:32:58-INFO:   inference_time = 7.768114328384399
02:32:58-INFO:   loss = None
attention_head_mask ['4:2']
['4', '2']
02:32:58-INFO: ***** Running evaluation *****
02:32:58-INFO:   Num examples = 872
02:32:58-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:06-INFO: ***** Eval results *****
02:33:06-INFO:   Accuracy = 0.930045871559633
02:33:06-INFO:   eval_accuracy = 0.930045871559633
02:33:06-INFO:   eval_loss = 0.23466317960992455
02:33:06-INFO:   global_step = 0
02:33:06-INFO:   inference_time = 7.768560409545898
02:33:06-INFO:   loss = None
attention_head_mask ['4:3']
['4', '3']
02:33:06-INFO: ***** Running evaluation *****
02:33:06-INFO:   Num examples = 872
02:33:06-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:14-INFO: ***** Eval results *****
02:33:14-INFO:   Accuracy = 0.930045871559633
02:33:14-INFO:   eval_accuracy = 0.930045871559633
02:33:14-INFO:   eval_loss = 0.23652315578822578
02:33:14-INFO:   global_step = 0
02:33:14-INFO:   inference_time = 7.767470598220825
02:33:14-INFO:   loss = None
attention_head_mask ['4:4']
['4', '4']
02:33:14-INFO: ***** Running evaluation *****
02:33:14-INFO:   Num examples = 872
02:33:14-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:22-INFO: ***** Eval results *****
02:33:22-INFO:   Accuracy = 0.9311926605504587
02:33:22-INFO:   eval_accuracy = 0.9311926605504587
02:33:22-INFO:   eval_loss = 0.23517337148743017
02:33:22-INFO:   global_step = 0
02:33:22-INFO:   inference_time = 7.768521547317505
02:33:22-INFO:   loss = None
attention_head_mask ['4:5']
['4', '5']
02:33:22-INFO: ***** Running evaluation *****
02:33:22-INFO:   Num examples = 872
02:33:22-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:29-INFO: ***** Eval results *****
02:33:29-INFO:   Accuracy = 0.930045871559633
02:33:29-INFO:   eval_accuracy = 0.930045871559633
02:33:29-INFO:   eval_loss = 0.23536287786971247
02:33:29-INFO:   global_step = 0
02:33:29-INFO:   inference_time = 7.766942977905273
02:33:29-INFO:   loss = None
attention_head_mask ['4:6']
['4', '6']
02:33:29-INFO: ***** Running evaluation *****
02:33:29-INFO:   Num examples = 872
02:33:29-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:37-INFO: ***** Eval results *****
02:33:37-INFO:   Accuracy = 0.930045871559633
02:33:37-INFO:   eval_accuracy = 0.930045871559633
02:33:37-INFO:   eval_loss = 0.23696042424333946
02:33:37-INFO:   global_step = 0
02:33:37-INFO:   inference_time = 7.7668821811676025
02:33:37-INFO:   loss = None
attention_head_mask ['4:7']
['4', '7']
02:33:37-INFO: ***** Running evaluation *****
02:33:37-INFO:   Num examples = 872
02:33:37-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:45-INFO: ***** Eval results *****
02:33:45-INFO:   Accuracy = 0.9311926605504587
02:33:45-INFO:   eval_accuracy = 0.9311926605504587
02:33:45-INFO:   eval_loss = 0.23719217315582292
02:33:45-INFO:   global_step = 0
02:33:45-INFO:   inference_time = 7.7679173946380615
02:33:45-INFO:   loss = None
attention_head_mask ['4:8']
['4', '8']
02:33:45-INFO: ***** Running evaluation *****
02:33:45-INFO:   Num examples = 872
02:33:45-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:33:53-INFO: ***** Eval results *****
02:33:53-INFO:   Accuracy = 0.9311926605504587
02:33:53-INFO:   eval_accuracy = 0.9311926605504587
02:33:53-INFO:   eval_loss = 0.23559612182102033
02:33:53-INFO:   global_step = 0
02:33:53-INFO:   inference_time = 7.767883062362671
02:33:53-INFO:   loss = None
attention_head_mask ['4:9']
['4', '9']
02:33:53-INFO: ***** Running evaluation *****
02:33:53-INFO:   Num examples = 872
02:33:53-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:34:01-INFO: ***** Eval results *****
02:34:01-INFO:   Accuracy = 0.930045871559633
02:34:01-INFO:   eval_accuracy = 0.930045871559633
02:34:01-INFO:   eval_loss = 0.23383005389145442
02:34:01-INFO:   global_step = 0
02:34:01-INFO:   inference_time = 7.768350601196289
02:34:01-INFO:   loss = None
attention_head_mask ['4:10']
['4', '10']
02:34:01-INFO: ***** Running evaluation *****
02:34:01-INFO:   Num examples = 872
02:34:01-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:34:08-INFO: ***** Eval results *****
02:34:08-INFO:   Accuracy = 0.926605504587156
02:34:08-INFO:   eval_accuracy = 0.926605504587156
02:34:08-INFO:   eval_loss = 0.23730022154216254
02:34:08-INFO:   global_step = 0
02:34:08-INFO:   inference_time = 7.768494129180908
02:34:08-INFO:   loss = None
attention_head_mask ['4:11']
['4', '11']
02:34:08-INFO: ***** Running evaluation *****
02:34:08-INFO:   Num examples = 872
02:34:08-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:34:16-INFO: ***** Eval results *****
02:34:16-INFO:   Accuracy = 0.9311926605504587
02:34:16-INFO:   eval_accuracy = 0.9311926605504587
02:34:16-INFO:   eval_loss = 0.2392175252150212
02:34:16-INFO:   global_step = 0
02:34:16-INFO:   inference_time = 7.767462253570557
02:34:16-INFO:   loss = None
attention_head_mask ['4:12']
['4', '12']
02:34:16-INFO: ***** Running evaluation *****
02:34:16-INFO:   Num examples = 872
02:34:16-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:34:24-INFO: ***** Eval results *****
02:34:24-INFO:   Accuracy = 0.9311926605504587
02:34:24-INFO:   eval_accuracy = 0.9311926605504587
02:34:24-INFO:   eval_loss = 0.23519059383709515
02:34:24-INFO:   global_step = 0
02:34:24-INFO:   inference_time = 7.768168210983276
02:34:24-INFO:   loss = None
attention_head_mask ['5:1']
['5', '1']
02:34:24-INFO: ***** Running evaluation *****
02:34:24-INFO:   Num examples = 872
02:34:24-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:34:32-INFO: ***** Eval results *****
02:34:32-INFO:   Accuracy = 0.9311926605504587
02:34:32-INFO:   eval_accuracy = 0.9311926605504587
02:34:32-INFO:   eval_loss = 0.23436170290889485
02:34:32-INFO:   global_step = 0
02:34:32-INFO:   inference_time = 7.781564474105835
02:34:32-INFO:   loss = None
attention_head_mask ['5:2']
['5', '2']
02:34:32-INFO: ***** Running evaluation *****
02:34:32-INFO:   Num examples = 872
02:34:32-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:34:40-INFO: ***** Eval results *****
02:34:40-INFO:   Accuracy = 0.930045871559633
02:34:40-INFO:   eval_accuracy = 0.930045871559633
02:34:40-INFO:   eval_loss = 0.23327043226787023
02:34:40-INFO:   global_step = 0
02:34:40-INFO:   inference_time = 7.780228137969971
02:34:40-INFO:   loss = None
attention_head_mask ['5:3']
['5', '3']
02:34:40-INFO: ***** Running evaluation *****
02:34:40-INFO:   Num examples = 872
02:34:40-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:34:48-INFO: ***** Eval results *****
02:34:48-INFO:   Accuracy = 0.9288990825688074
02:34:48-INFO:   eval_accuracy = 0.9288990825688074
02:34:48-INFO:   eval_loss = 0.2383244478675936
02:34:48-INFO:   global_step = 0
02:34:48-INFO:   inference_time = 7.77956748008728
02:34:48-INFO:   loss = None
attention_head_mask ['5:4']
['5', '4']
02:34:48-INFO: ***** Running evaluation *****
02:34:48-INFO:   Num examples = 872
02:34:48-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:34:55-INFO: ***** Eval results *****
02:34:55-INFO:   Accuracy = 0.930045871559633
02:34:55-INFO:   eval_accuracy = 0.930045871559633
02:34:55-INFO:   eval_loss = 0.23739539459347725
02:34:55-INFO:   global_step = 0
02:34:55-INFO:   inference_time = 7.781455039978027
02:34:55-INFO:   loss = None
attention_head_mask ['5:5']
['5', '5']
02:34:55-INFO: ***** Running evaluation *****
02:34:55-INFO:   Num examples = 872
02:34:55-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:03-INFO: ***** Eval results *****
02:35:03-INFO:   Accuracy = 0.9288990825688074
02:35:03-INFO:   eval_accuracy = 0.9288990825688074
02:35:03-INFO:   eval_loss = 0.2371053543340947
02:35:03-INFO:   global_step = 0
02:35:03-INFO:   inference_time = 7.782111167907715
02:35:03-INFO:   loss = None
attention_head_mask ['5:6']
['5', '6']
02:35:03-INFO: ***** Running evaluation *****
02:35:03-INFO:   Num examples = 872
02:35:03-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:11-INFO: ***** Eval results *****
02:35:11-INFO:   Accuracy = 0.930045871559633
02:35:11-INFO:   eval_accuracy = 0.930045871559633
02:35:11-INFO:   eval_loss = 0.23463258094021253
02:35:11-INFO:   global_step = 0
02:35:11-INFO:   inference_time = 7.779928684234619
02:35:11-INFO:   loss = None
attention_head_mask ['5:7']
['5', '7']
02:35:11-INFO: ***** Running evaluation *****
02:35:11-INFO:   Num examples = 872
02:35:11-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:19-INFO: ***** Eval results *****
02:35:19-INFO:   Accuracy = 0.9311926605504587
02:35:19-INFO:   eval_accuracy = 0.9311926605504587
02:35:19-INFO:   eval_loss = 0.2313474491238594
02:35:19-INFO:   global_step = 0
02:35:19-INFO:   inference_time = 7.779503107070923
02:35:19-INFO:   loss = None
attention_head_mask ['5:8']
['5', '8']
02:35:19-INFO: ***** Running evaluation *****
02:35:19-INFO:   Num examples = 872
02:35:19-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:27-INFO: ***** Eval results *****
02:35:27-INFO:   Accuracy = 0.9323394495412844
02:35:27-INFO:   eval_accuracy = 0.9323394495412844
02:35:27-INFO:   eval_loss = 0.23495800400684988
02:35:27-INFO:   global_step = 0
02:35:27-INFO:   inference_time = 7.779992341995239
02:35:27-INFO:   loss = None
attention_head_mask ['5:9']
['5', '9']
02:35:27-INFO: ***** Running evaluation *****
02:35:27-INFO:   Num examples = 872
02:35:27-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:34-INFO: ***** Eval results *****
02:35:34-INFO:   Accuracy = 0.9288990825688074
02:35:34-INFO:   eval_accuracy = 0.9288990825688074
02:35:34-INFO:   eval_loss = 0.23654031094961933
02:35:34-INFO:   global_step = 0
02:35:34-INFO:   inference_time = 7.7803356647491455
02:35:34-INFO:   loss = None
attention_head_mask ['5:10']
['5', '10']
02:35:34-INFO: ***** Running evaluation *****
02:35:34-INFO:   Num examples = 872
02:35:34-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:42-INFO: ***** Eval results *****
02:35:42-INFO:   Accuracy = 0.930045871559633
02:35:42-INFO:   eval_accuracy = 0.930045871559633
02:35:42-INFO:   eval_loss = 0.2346453270209687
02:35:42-INFO:   global_step = 0
02:35:42-INFO:   inference_time = 7.7797770500183105
02:35:42-INFO:   loss = None
attention_head_mask ['5:11']
['5', '11']
02:35:42-INFO: ***** Running evaluation *****
02:35:42-INFO:   Num examples = 872
02:35:42-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:50-INFO: ***** Eval results *****
02:35:50-INFO:   Accuracy = 0.930045871559633
02:35:50-INFO:   eval_accuracy = 0.930045871559633
02:35:50-INFO:   eval_loss = 0.23321207759103604
02:35:50-INFO:   global_step = 0
02:35:50-INFO:   inference_time = 7.781713247299194
02:35:50-INFO:   loss = None
attention_head_mask ['5:12']
['5', '12']
02:35:50-INFO: ***** Running evaluation *****
02:35:50-INFO:   Num examples = 872
02:35:50-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:35:58-INFO: ***** Eval results *****
02:35:58-INFO:   Accuracy = 0.9288990825688074
02:35:58-INFO:   eval_accuracy = 0.9288990825688074
02:35:58-INFO:   eval_loss = 0.2364954212680459
02:35:58-INFO:   global_step = 0
02:35:58-INFO:   inference_time = 7.782252788543701
02:35:58-INFO:   loss = None
attention_head_mask ['6:1']
['6', '1']
02:35:58-INFO: ***** Running evaluation *****
02:35:58-INFO:   Num examples = 872
02:35:58-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:06-INFO: ***** Eval results *****
02:36:06-INFO:   Accuracy = 0.926605504587156
02:36:06-INFO:   eval_accuracy = 0.926605504587156
02:36:06-INFO:   eval_loss = 0.2397151999840779
02:36:06-INFO:   global_step = 0
02:36:06-INFO:   inference_time = 7.79523777961731
02:36:06-INFO:   loss = None
attention_head_mask ['6:2']
['6', '2']
02:36:06-INFO: ***** Running evaluation *****
02:36:06-INFO:   Num examples = 872
02:36:06-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:14-INFO: ***** Eval results *****
02:36:14-INFO:   Accuracy = 0.9288990825688074
02:36:14-INFO:   eval_accuracy = 0.9288990825688074
02:36:14-INFO:   eval_loss = 0.2363004873373679
02:36:14-INFO:   global_step = 0
02:36:14-INFO:   inference_time = 7.793611764907837
02:36:14-INFO:   loss = None
attention_head_mask ['6:3']
['6', '3']
02:36:14-INFO: ***** Running evaluation *****
02:36:14-INFO:   Num examples = 872
02:36:14-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:21-INFO: ***** Eval results *****
02:36:21-INFO:   Accuracy = 0.9288990825688074
02:36:21-INFO:   eval_accuracy = 0.9288990825688074
02:36:21-INFO:   eval_loss = 0.23662260028400592
02:36:21-INFO:   global_step = 0
02:36:21-INFO:   inference_time = 7.7934863567352295
02:36:21-INFO:   loss = None
attention_head_mask ['6:4']
['6', '4']
02:36:21-INFO: ***** Running evaluation *****
02:36:21-INFO:   Num examples = 872
02:36:21-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:29-INFO: ***** Eval results *****
02:36:29-INFO:   Accuracy = 0.9254587155963303
02:36:29-INFO:   eval_accuracy = 0.9254587155963303
02:36:29-INFO:   eval_loss = 0.2351207353972963
02:36:29-INFO:   global_step = 0
02:36:29-INFO:   inference_time = 7.794697284698486
02:36:29-INFO:   loss = None
attention_head_mask ['6:5']
['6', '5']
02:36:29-INFO: ***** Running evaluation *****
02:36:29-INFO:   Num examples = 872
02:36:29-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:37-INFO: ***** Eval results *****
02:36:37-INFO:   Accuracy = 0.9254587155963303
02:36:37-INFO:   eval_accuracy = 0.9254587155963303
02:36:37-INFO:   eval_loss = 0.23724174938563788
02:36:37-INFO:   global_step = 0
02:36:37-INFO:   inference_time = 7.795468330383301
02:36:37-INFO:   loss = None
attention_head_mask ['6:6']
['6', '6']
02:36:37-INFO: ***** Running evaluation *****
02:36:37-INFO:   Num examples = 872
02:36:37-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:45-INFO: ***** Eval results *****
02:36:45-INFO:   Accuracy = 0.926605504587156
02:36:45-INFO:   eval_accuracy = 0.926605504587156
02:36:45-INFO:   eval_loss = 0.23595359568883265
02:36:45-INFO:   global_step = 0
02:36:45-INFO:   inference_time = 7.79382848739624
02:36:45-INFO:   loss = None
attention_head_mask ['6:7']
['6', '7']
02:36:45-INFO: ***** Running evaluation *****
02:36:45-INFO:   Num examples = 872
02:36:45-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:36:53-INFO: ***** Eval results *****
02:36:53-INFO:   Accuracy = 0.9254587155963303
02:36:53-INFO:   eval_accuracy = 0.9254587155963303
02:36:53-INFO:   eval_loss = 0.2357378681190312
02:36:53-INFO:   global_step = 0
02:36:53-INFO:   inference_time = 7.792468309402466
02:36:53-INFO:   loss = None
attention_head_mask ['6:8']
['6', '8']
02:36:53-INFO: ***** Running evaluation *****
02:36:53-INFO:   Num examples = 872
02:36:53-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:37:01-INFO: ***** Eval results *****
02:37:01-INFO:   Accuracy = 0.9277522935779816
02:37:01-INFO:   eval_accuracy = 0.9277522935779816
02:37:01-INFO:   eval_loss = 0.23311363479920796
02:37:01-INFO:   global_step = 0
02:37:01-INFO:   inference_time = 7.794828414916992
02:37:01-INFO:   loss = None
attention_head_mask ['6:9']
['6', '9']
02:37:01-INFO: ***** Running evaluation *****
02:37:01-INFO:   Num examples = 872
02:37:01-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:37:09-INFO: ***** Eval results *****
02:37:09-INFO:   Accuracy = 0.9288990825688074
02:37:09-INFO:   eval_accuracy = 0.9288990825688074
02:37:09-INFO:   eval_loss = 0.23618020370070422
02:37:09-INFO:   global_step = 0
02:37:09-INFO:   inference_time = 7.793048620223999
02:37:09-INFO:   loss = None
attention_head_mask ['6:10']
['6', '10']
02:37:09-INFO: ***** Running evaluation *****
02:37:09-INFO:   Num examples = 872
02:37:09-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:37:16-INFO: ***** Eval results *****
02:37:16-INFO:   Accuracy = 0.9231651376146789
02:37:16-INFO:   eval_accuracy = 0.9231651376146789
02:37:16-INFO:   eval_loss = 0.23672916148123996
02:37:16-INFO:   global_step = 0
02:37:16-INFO:   inference_time = 7.793778419494629
02:37:16-INFO:   loss = None
attention_head_mask ['6:11']
['6', '11']
02:37:16-INFO: ***** Running evaluation *****
02:37:16-INFO:   Num examples = 872
02:37:16-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:37:24-INFO: ***** Eval results *****
02:37:24-INFO:   Accuracy = 0.9243119266055045
02:37:24-INFO:   eval_accuracy = 0.9243119266055045
02:37:24-INFO:   eval_loss = 0.23835355515724846
02:37:24-INFO:   global_step = 0
02:37:24-INFO:   inference_time = 7.793676376342773
02:37:24-INFO:   loss = None
attention_head_mask ['6:12']
['6', '12']
02:37:24-INFO: ***** Running evaluation *****
02:37:24-INFO:   Num examples = 872
02:37:24-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:37:32-INFO: ***** Eval results *****
02:37:32-INFO:   Accuracy = 0.930045871559633
02:37:32-INFO:   eval_accuracy = 0.930045871559633
02:37:32-INFO:   eval_loss = 0.2346514854580164
02:37:32-INFO:   global_step = 0
02:37:32-INFO:   inference_time = 7.793974876403809
02:37:32-INFO:   loss = None
attention_head_mask ['7:1']
['7', '1']
02:37:32-INFO: ***** Running evaluation *****
02:37:32-INFO:   Num examples = 872
02:37:32-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:37:40-INFO: ***** Eval results *****
02:37:40-INFO:   Accuracy = 0.9277522935779816
02:37:40-INFO:   eval_accuracy = 0.9277522935779816
02:37:40-INFO:   eval_loss = 0.23211553719426906
02:37:40-INFO:   global_step = 0
02:37:40-INFO:   inference_time = 7.808488368988037
02:37:40-INFO:   loss = None
attention_head_mask ['7:2']
['7', '2']
02:37:40-INFO: ***** Running evaluation *****
02:37:40-INFO:   Num examples = 872
02:37:40-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:37:48-INFO: ***** Eval results *****
02:37:48-INFO:   Accuracy = 0.930045871559633
02:37:48-INFO:   eval_accuracy = 0.930045871559633
02:37:48-INFO:   eval_loss = 0.23625588164265668
02:37:48-INFO:   global_step = 0
02:37:48-INFO:   inference_time = 7.807315349578857
02:37:48-INFO:   loss = None
attention_head_mask ['7:3']
['7', '3']
02:37:48-INFO: ***** Running evaluation *****
02:37:48-INFO:   Num examples = 872
02:37:48-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:37:56-INFO: ***** Eval results *****
02:37:56-INFO:   Accuracy = 0.9288990825688074
02:37:56-INFO:   eval_accuracy = 0.9288990825688074
02:37:56-INFO:   eval_loss = 0.23412293501730477
02:37:56-INFO:   global_step = 0
02:37:56-INFO:   inference_time = 7.80661416053772
02:37:56-INFO:   loss = None
attention_head_mask ['7:4']
['7', '4']
02:37:56-INFO: ***** Running evaluation *****
02:37:56-INFO:   Num examples = 872
02:37:56-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:03-INFO: ***** Eval results *****
02:38:03-INFO:   Accuracy = 0.930045871559633
02:38:03-INFO:   eval_accuracy = 0.930045871559633
02:38:03-INFO:   eval_loss = 0.23511364437373622
02:38:03-INFO:   global_step = 0
02:38:03-INFO:   inference_time = 7.8066229820251465
02:38:03-INFO:   loss = None
attention_head_mask ['7:5']
['7', '5']
02:38:03-INFO: ***** Running evaluation *****
02:38:03-INFO:   Num examples = 872
02:38:03-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:11-INFO: ***** Eval results *****
02:38:11-INFO:   Accuracy = 0.9288990825688074
02:38:11-INFO:   eval_accuracy = 0.9288990825688074
02:38:11-INFO:   eval_loss = 0.2327997723727354
02:38:11-INFO:   global_step = 0
02:38:11-INFO:   inference_time = 7.807642936706543
02:38:11-INFO:   loss = None
attention_head_mask ['7:6']
['7', '6']
02:38:11-INFO: ***** Running evaluation *****
02:38:11-INFO:   Num examples = 872
02:38:11-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:19-INFO: ***** Eval results *****
02:38:19-INFO:   Accuracy = 0.9277522935779816
02:38:19-INFO:   eval_accuracy = 0.9277522935779816
02:38:19-INFO:   eval_loss = 0.2341343341395259
02:38:19-INFO:   global_step = 0
02:38:19-INFO:   inference_time = 7.8092262744903564
02:38:19-INFO:   loss = None
attention_head_mask ['7:7']
['7', '7']
02:38:19-INFO: ***** Running evaluation *****
02:38:19-INFO:   Num examples = 872
02:38:19-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:27-INFO: ***** Eval results *****
02:38:27-INFO:   Accuracy = 0.9311926605504587
02:38:27-INFO:   eval_accuracy = 0.9311926605504587
02:38:27-INFO:   eval_loss = 0.23986761790833303
02:38:27-INFO:   global_step = 0
02:38:27-INFO:   inference_time = 7.80516505241394
02:38:27-INFO:   loss = None
attention_head_mask ['7:8']
['7', '8']
02:38:27-INFO: ***** Running evaluation *****
02:38:27-INFO:   Num examples = 872
02:38:27-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:35-INFO: ***** Eval results *****
02:38:35-INFO:   Accuracy = 0.9311926605504587
02:38:35-INFO:   eval_accuracy = 0.9311926605504587
02:38:35-INFO:   eval_loss = 0.23352035906698024
02:38:35-INFO:   global_step = 0
02:38:35-INFO:   inference_time = 7.808422803878784
02:38:35-INFO:   loss = None
attention_head_mask ['7:9']
['7', '9']
02:38:35-INFO: ***** Running evaluation *****
02:38:35-INFO:   Num examples = 872
02:38:35-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:43-INFO: ***** Eval results *****
02:38:43-INFO:   Accuracy = 0.9288990825688074
02:38:43-INFO:   eval_accuracy = 0.9288990825688074
02:38:43-INFO:   eval_loss = 0.23483683681115508
02:38:43-INFO:   global_step = 0
02:38:43-INFO:   inference_time = 7.80686616897583
02:38:43-INFO:   loss = None
attention_head_mask ['7:10']
['7', '10']
02:38:43-INFO: ***** Running evaluation *****
02:38:43-INFO:   Num examples = 872
02:38:43-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:51-INFO: ***** Eval results *****
02:38:51-INFO:   Accuracy = 0.9288990825688074
02:38:51-INFO:   eval_accuracy = 0.9288990825688074
02:38:51-INFO:   eval_loss = 0.23372559402404086
02:38:51-INFO:   global_step = 0
02:38:51-INFO:   inference_time = 7.805779457092285
02:38:51-INFO:   loss = None
attention_head_mask ['7:11']
['7', '11']
02:38:51-INFO: ***** Running evaluation *****
02:38:51-INFO:   Num examples = 872
02:38:51-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:38:58-INFO: ***** Eval results *****
02:38:58-INFO:   Accuracy = 0.930045871559633
02:38:58-INFO:   eval_accuracy = 0.930045871559633
02:38:58-INFO:   eval_loss = 0.2391376848598676
02:38:58-INFO:   global_step = 0
02:38:58-INFO:   inference_time = 7.808351039886475
02:38:58-INFO:   loss = None
attention_head_mask ['7:12']
['7', '12']
02:38:58-INFO: ***** Running evaluation *****
02:38:58-INFO:   Num examples = 872
02:38:58-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:06-INFO: ***** Eval results *****
02:39:06-INFO:   Accuracy = 0.9311926605504587
02:39:06-INFO:   eval_accuracy = 0.9311926605504587
02:39:06-INFO:   eval_loss = 0.2329445622329201
02:39:06-INFO:   global_step = 0
02:39:06-INFO:   inference_time = 7.806621789932251
02:39:06-INFO:   loss = None
attention_head_mask ['8:1']
['8', '1']
02:39:06-INFO: ***** Running evaluation *****
02:39:06-INFO:   Num examples = 872
02:39:06-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:14-INFO: ***** Eval results *****
02:39:14-INFO:   Accuracy = 0.926605504587156
02:39:14-INFO:   eval_accuracy = 0.926605504587156
02:39:14-INFO:   eval_loss = 0.2274601633128311
02:39:14-INFO:   global_step = 0
02:39:14-INFO:   inference_time = 7.819126605987549
02:39:14-INFO:   loss = None
attention_head_mask ['8:2']
['8', '2']
02:39:14-INFO: ***** Running evaluation *****
02:39:14-INFO:   Num examples = 872
02:39:14-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:22-INFO: ***** Eval results *****
02:39:22-INFO:   Accuracy = 0.9254587155963303
02:39:22-INFO:   eval_accuracy = 0.9254587155963303
02:39:22-INFO:   eval_loss = 0.23027513349162682
02:39:22-INFO:   global_step = 0
02:39:22-INFO:   inference_time = 7.8207714557647705
02:39:22-INFO:   loss = None
attention_head_mask ['8:3']
['8', '3']
02:39:22-INFO: ***** Running evaluation *****
02:39:22-INFO:   Num examples = 872
02:39:22-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:30-INFO: ***** Eval results *****
02:39:30-INFO:   Accuracy = 0.9288990825688074
02:39:30-INFO:   eval_accuracy = 0.9288990825688074
02:39:30-INFO:   eval_loss = 0.23301041033118963
02:39:30-INFO:   global_step = 0
02:39:30-INFO:   inference_time = 7.81837797164917
02:39:30-INFO:   loss = None
attention_head_mask ['8:4']
['8', '4']
02:39:30-INFO: ***** Running evaluation *****
02:39:30-INFO:   Num examples = 872
02:39:30-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:38-INFO: ***** Eval results *****
02:39:38-INFO:   Accuracy = 0.9277522935779816
02:39:38-INFO:   eval_accuracy = 0.9277522935779816
02:39:38-INFO:   eval_loss = 0.22985427607116954
02:39:38-INFO:   global_step = 0
02:39:38-INFO:   inference_time = 7.818447589874268
02:39:38-INFO:   loss = None
attention_head_mask ['8:5']
['8', '5']
02:39:38-INFO: ***** Running evaluation *****
02:39:38-INFO:   Num examples = 872
02:39:38-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:46-INFO: ***** Eval results *****
02:39:46-INFO:   Accuracy = 0.930045871559633
02:39:46-INFO:   eval_accuracy = 0.930045871559633
02:39:46-INFO:   eval_loss = 0.23123902042529412
02:39:46-INFO:   global_step = 0
02:39:46-INFO:   inference_time = 7.820836544036865
02:39:46-INFO:   loss = None
attention_head_mask ['8:6']
['8', '6']
02:39:46-INFO: ***** Running evaluation *****
02:39:46-INFO:   Num examples = 872
02:39:46-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:39:53-INFO: ***** Eval results *****
02:39:53-INFO:   Accuracy = 0.9288990825688074
02:39:53-INFO:   eval_accuracy = 0.9288990825688074
02:39:53-INFO:   eval_loss = 0.22967063056837236
02:39:53-INFO:   global_step = 0
02:39:53-INFO:   inference_time = 7.820233106613159
02:39:53-INFO:   loss = None
attention_head_mask ['8:7']
['8', '7']
02:39:53-INFO: ***** Running evaluation *****
02:39:53-INFO:   Num examples = 872
02:39:53-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:40:01-INFO: ***** Eval results *****
02:40:01-INFO:   Accuracy = 0.9288990825688074
02:40:01-INFO:   eval_accuracy = 0.9288990825688074
02:40:01-INFO:   eval_loss = 0.23186135032613361
02:40:01-INFO:   global_step = 0
02:40:01-INFO:   inference_time = 7.8180108070373535
02:40:01-INFO:   loss = None
attention_head_mask ['8:8']
['8', '8']
02:40:01-INFO: ***** Running evaluation *****
02:40:01-INFO:   Num examples = 872
02:40:01-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:40:09-INFO: ***** Eval results *****
02:40:09-INFO:   Accuracy = 0.9311926605504587
02:40:09-INFO:   eval_accuracy = 0.9311926605504587
02:40:09-INFO:   eval_loss = 0.23320278225998795
02:40:09-INFO:   global_step = 0
02:40:09-INFO:   inference_time = 7.8220953941345215
02:40:09-INFO:   loss = None
attention_head_mask ['8:9']
['8', '9']
02:40:09-INFO: ***** Running evaluation *****
02:40:09-INFO:   Num examples = 872
02:40:09-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:40:17-INFO: ***** Eval results *****
02:40:17-INFO:   Accuracy = 0.930045871559633
02:40:17-INFO:   eval_accuracy = 0.930045871559633
02:40:17-INFO:   eval_loss = 0.23247368627094797
02:40:17-INFO:   global_step = 0
02:40:17-INFO:   inference_time = 7.81965184211731
02:40:17-INFO:   loss = None
attention_head_mask ['8:10']
['8', '10']
02:40:17-INFO: ***** Running evaluation *****
02:40:17-INFO:   Num examples = 872
02:40:17-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:40:25-INFO: ***** Eval results *****
02:40:25-INFO:   Accuracy = 0.9311926605504587
02:40:25-INFO:   eval_accuracy = 0.9311926605504587
02:40:25-INFO:   eval_loss = 0.2296229720647846
02:40:25-INFO:   global_step = 0
02:40:25-INFO:   inference_time = 7.8199546337127686
02:40:25-INFO:   loss = None
attention_head_mask ['8:11']
['8', '11']
02:40:25-INFO: ***** Running evaluation *****
02:40:25-INFO:   Num examples = 872
02:40:25-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.57it/s]
02:40:33-INFO: ***** Eval results *****
02:40:33-INFO:   Accuracy = 0.9288990825688074
02:40:33-INFO:   eval_accuracy = 0.9288990825688074
02:40:33-INFO:   eval_loss = 0.2342015606617289
02:40:33-INFO:   global_step = 0
02:40:33-INFO:   inference_time = 7.820613145828247
02:40:33-INFO:   loss = None
attention_head_mask ['8:12']
['8', '12']
02:40:33-INFO: ***** Running evaluation *****
02:40:33-INFO:   Num examples = 872
02:40:33-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:40:41-INFO: ***** Eval results *****
02:40:41-INFO:   Accuracy = 0.930045871559633
02:40:41-INFO:   eval_accuracy = 0.930045871559633
02:40:41-INFO:   eval_loss = 0.23408502247184515
02:40:41-INFO:   global_step = 0
02:40:41-INFO:   inference_time = 7.821914434432983
02:40:41-INFO:   loss = None
attention_head_mask ['9:1']
['9', '1']
02:40:41-INFO: ***** Running evaluation *****
02:40:41-INFO:   Num examples = 872
02:40:41-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:40:48-INFO: ***** Eval results *****
02:40:48-INFO:   Accuracy = 0.9288990825688074
02:40:48-INFO:   eval_accuracy = 0.9288990825688074
02:40:48-INFO:   eval_loss = 0.23487124359235168
02:40:48-INFO:   global_step = 0
02:40:48-INFO:   inference_time = 7.834023952484131
02:40:48-INFO:   loss = None
attention_head_mask ['9:2']
['9', '2']
02:40:48-INFO: ***** Running evaluation *****
02:40:48-INFO:   Num examples = 872
02:40:48-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:40:56-INFO: ***** Eval results *****
02:40:56-INFO:   Accuracy = 0.9254587155963303
02:40:56-INFO:   eval_accuracy = 0.9254587155963303
02:40:56-INFO:   eval_loss = 0.23480406243886268
02:40:56-INFO:   global_step = 0
02:40:56-INFO:   inference_time = 7.8343706130981445
02:40:56-INFO:   loss = None
attention_head_mask ['9:3']
['9', '3']
02:40:56-INFO: ***** Running evaluation *****
02:40:56-INFO:   Num examples = 872
02:40:56-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:04-INFO: ***** Eval results *****
02:41:04-INFO:   Accuracy = 0.9288990825688074
02:41:04-INFO:   eval_accuracy = 0.9288990825688074
02:41:04-INFO:   eval_loss = 0.23429357513253177
02:41:04-INFO:   global_step = 0
02:41:04-INFO:   inference_time = 7.835134029388428
02:41:04-INFO:   loss = None
attention_head_mask ['9:4']
['9', '4']
02:41:04-INFO: ***** Running evaluation *****
02:41:04-INFO:   Num examples = 872
02:41:04-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:12-INFO: ***** Eval results *****
02:41:12-INFO:   Accuracy = 0.9288990825688074
02:41:12-INFO:   eval_accuracy = 0.9288990825688074
02:41:12-INFO:   eval_loss = 0.23646042722144298
02:41:12-INFO:   global_step = 0
02:41:12-INFO:   inference_time = 7.832873106002808
02:41:12-INFO:   loss = None
attention_head_mask ['9:5']
['9', '5']
02:41:12-INFO: ***** Running evaluation *****
02:41:12-INFO:   Num examples = 872
02:41:12-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:20-INFO: ***** Eval results *****
02:41:20-INFO:   Accuracy = 0.930045871559633
02:41:20-INFO:   eval_accuracy = 0.930045871559633
02:41:20-INFO:   eval_loss = 0.23265250672453217
02:41:20-INFO:   global_step = 0
02:41:20-INFO:   inference_time = 7.832287073135376
02:41:20-INFO:   loss = None
attention_head_mask ['9:6']
['9', '6']
02:41:20-INFO: ***** Running evaluation *****
02:41:20-INFO:   Num examples = 872
02:41:20-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:28-INFO: ***** Eval results *****
02:41:28-INFO:   Accuracy = 0.930045871559633
02:41:28-INFO:   eval_accuracy = 0.930045871559633
02:41:28-INFO:   eval_loss = 0.2361412963031658
02:41:28-INFO:   global_step = 0
02:41:28-INFO:   inference_time = 7.832916259765625
02:41:28-INFO:   loss = None
attention_head_mask ['9:7']
['9', '7']
02:41:28-INFO: ***** Running evaluation *****
02:41:28-INFO:   Num examples = 872
02:41:28-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:36-INFO: ***** Eval results *****
02:41:36-INFO:   Accuracy = 0.9311926605504587
02:41:36-INFO:   eval_accuracy = 0.9311926605504587
02:41:36-INFO:   eval_loss = 0.23202752780967525
02:41:36-INFO:   global_step = 0
02:41:36-INFO:   inference_time = 7.8328537940979
02:41:36-INFO:   loss = None
attention_head_mask ['9:8']
['9', '8']
02:41:36-INFO: ***** Running evaluation *****
02:41:36-INFO:   Num examples = 872
02:41:36-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:44-INFO: ***** Eval results *****
02:41:44-INFO:   Accuracy = 0.9288990825688074
02:41:44-INFO:   eval_accuracy = 0.9288990825688074
02:41:44-INFO:   eval_loss = 0.22958356368222407
02:41:44-INFO:   global_step = 0
02:41:44-INFO:   inference_time = 7.8334715366363525
02:41:44-INFO:   loss = None
attention_head_mask ['9:9']
['9', '9']
02:41:44-INFO: ***** Running evaluation *****
02:41:44-INFO:   Num examples = 872
02:41:44-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:51-INFO: ***** Eval results *****
02:41:51-INFO:   Accuracy = 0.9277522935779816
02:41:51-INFO:   eval_accuracy = 0.9277522935779816
02:41:51-INFO:   eval_loss = 0.22743893567738788
02:41:51-INFO:   global_step = 0
02:41:51-INFO:   inference_time = 7.833263158798218
02:41:51-INFO:   loss = None
attention_head_mask ['9:10']
['9', '10']
02:41:51-INFO: ***** Running evaluation *****
02:41:51-INFO:   Num examples = 872
02:41:51-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:41:59-INFO: ***** Eval results *****
02:41:59-INFO:   Accuracy = 0.9243119266055045
02:41:59-INFO:   eval_accuracy = 0.9243119266055045
02:41:59-INFO:   eval_loss = 0.2234576219426734
02:41:59-INFO:   global_step = 0
02:41:59-INFO:   inference_time = 7.8326380252838135
02:41:59-INFO:   loss = None
attention_head_mask ['9:11']
['9', '11']
02:41:59-INFO: ***** Running evaluation *****
02:41:59-INFO:   Num examples = 872
02:41:59-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:42:07-INFO: ***** Eval results *****
02:42:07-INFO:   Accuracy = 0.926605504587156
02:42:07-INFO:   eval_accuracy = 0.926605504587156
02:42:07-INFO:   eval_loss = 0.22958187572658062
02:42:07-INFO:   global_step = 0
02:42:07-INFO:   inference_time = 7.8347554206848145
02:42:07-INFO:   loss = None
attention_head_mask ['9:12']
['9', '12']
02:42:07-INFO: ***** Running evaluation *****
02:42:07-INFO:   Num examples = 872
02:42:07-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:42:15-INFO: ***** Eval results *****
02:42:15-INFO:   Accuracy = 0.930045871559633
02:42:15-INFO:   eval_accuracy = 0.930045871559633
02:42:15-INFO:   eval_loss = 0.22995613169457232
02:42:15-INFO:   global_step = 0
02:42:15-INFO:   inference_time = 7.833467721939087
02:42:15-INFO:   loss = None
attention_head_mask ['10:1']
['10', '1']
02:42:15-INFO: ***** Running evaluation *****
02:42:15-INFO:   Num examples = 872
02:42:15-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:42:23-INFO: ***** Eval results *****
02:42:23-INFO:   Accuracy = 0.9288990825688074
02:42:23-INFO:   eval_accuracy = 0.9288990825688074
02:42:23-INFO:   eval_loss = 0.2295730951508241
02:42:23-INFO:   global_step = 0
02:42:23-INFO:   inference_time = 7.848329305648804
02:42:23-INFO:   loss = None
attention_head_mask ['10:2']
['10', '2']
02:42:23-INFO: ***** Running evaluation *****
02:42:23-INFO:   Num examples = 872
02:42:23-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.56it/s]
02:42:31-INFO: ***** Eval results *****
02:42:31-INFO:   Accuracy = 0.9288990825688074
02:42:31-INFO:   eval_accuracy = 0.9288990825688074
02:42:31-INFO:   eval_loss = 0.23177323962694832
02:42:31-INFO:   global_step = 0
02:42:31-INFO:   inference_time = 7.844042778015137
02:42:31-INFO:   loss = None
attention_head_mask ['10:3']
['10', '3']
02:42:31-INFO: ***** Running evaluation *****
02:42:31-INFO:   Num examples = 872
02:42:31-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:42:39-INFO: ***** Eval results *****
02:42:39-INFO:   Accuracy = 0.930045871559633
02:42:39-INFO:   eval_accuracy = 0.930045871559633
02:42:39-INFO:   eval_loss = 0.22105675882526807
02:42:39-INFO:   global_step = 0
02:42:39-INFO:   inference_time = 7.847085237503052
02:42:39-INFO:   loss = None
attention_head_mask ['10:4']
['10', '4']
02:42:39-INFO: ***** Running evaluation *****
02:42:39-INFO:   Num examples = 872
02:42:39-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:42:47-INFO: ***** Eval results *****
02:42:47-INFO:   Accuracy = 0.930045871559633
02:42:47-INFO:   eval_accuracy = 0.930045871559633
02:42:47-INFO:   eval_loss = 0.2280223645669009
02:42:47-INFO:   global_step = 0
02:42:47-INFO:   inference_time = 7.846029043197632
02:42:47-INFO:   loss = None
attention_head_mask ['10:5']
['10', '5']
02:42:47-INFO: ***** Running evaluation *****
02:42:47-INFO:   Num examples = 872
02:42:47-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:42:55-INFO: ***** Eval results *****
02:42:55-INFO:   Accuracy = 0.9311926605504587
02:42:55-INFO:   eval_accuracy = 0.9311926605504587
02:42:55-INFO:   eval_loss = 0.23123223707079887
02:42:55-INFO:   global_step = 0
02:42:55-INFO:   inference_time = 7.846989393234253
02:42:55-INFO:   loss = None
attention_head_mask ['10:6']
['10', '6']
02:42:55-INFO: ***** Running evaluation *****
02:42:55-INFO:   Num examples = 872
02:42:55-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:02-INFO: ***** Eval results *****
02:43:02-INFO:   Accuracy = 0.9277522935779816
02:43:02-INFO:   eval_accuracy = 0.9277522935779816
02:43:02-INFO:   eval_loss = 0.22502275842374989
02:43:02-INFO:   global_step = 0
02:43:02-INFO:   inference_time = 7.8455846309661865
02:43:02-INFO:   loss = None
attention_head_mask ['10:7']
['10', '7']
02:43:02-INFO: ***** Running evaluation *****
02:43:02-INFO:   Num examples = 872
02:43:02-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:10-INFO: ***** Eval results *****
02:43:10-INFO:   Accuracy = 0.930045871559633
02:43:10-INFO:   eval_accuracy = 0.930045871559633
02:43:10-INFO:   eval_loss = 0.2277599017002753
02:43:10-INFO:   global_step = 0
02:43:10-INFO:   inference_time = 7.845900535583496
02:43:10-INFO:   loss = None
attention_head_mask ['10:8']
['10', '8']
02:43:10-INFO: ***** Running evaluation *****
02:43:10-INFO:   Num examples = 872
02:43:10-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:18-INFO: ***** Eval results *****
02:43:18-INFO:   Accuracy = 0.9288990825688074
02:43:18-INFO:   eval_accuracy = 0.9288990825688074
02:43:18-INFO:   eval_loss = 0.22727561994854892
02:43:18-INFO:   global_step = 0
02:43:18-INFO:   inference_time = 7.84851861000061
02:43:18-INFO:   loss = None
attention_head_mask ['10:9']
['10', '9']
02:43:18-INFO: ***** Running evaluation *****
02:43:18-INFO:   Num examples = 872
02:43:18-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:26-INFO: ***** Eval results *****
02:43:26-INFO:   Accuracy = 0.930045871559633
02:43:26-INFO:   eval_accuracy = 0.930045871559633
02:43:26-INFO:   eval_loss = 0.22814777766221336
02:43:26-INFO:   global_step = 0
02:43:26-INFO:   inference_time = 7.845046520233154
02:43:26-INFO:   loss = None
attention_head_mask ['10:10']
['10', '10']
02:43:26-INFO: ***** Running evaluation *****
02:43:26-INFO:   Num examples = 872
02:43:26-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:34-INFO: ***** Eval results *****
02:43:34-INFO:   Accuracy = 0.930045871559633
02:43:34-INFO:   eval_accuracy = 0.930045871559633
02:43:34-INFO:   eval_loss = 0.2306235351466707
02:43:34-INFO:   global_step = 0
02:43:34-INFO:   inference_time = 7.846371650695801
02:43:34-INFO:   loss = None
attention_head_mask ['10:11']
['10', '11']
02:43:34-INFO: ***** Running evaluation *****
02:43:34-INFO:   Num examples = 872
02:43:34-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:42-INFO: ***** Eval results *****
02:43:42-INFO:   Accuracy = 0.9277522935779816
02:43:42-INFO:   eval_accuracy = 0.9277522935779816
02:43:42-INFO:   eval_loss = 0.2225489661629711
02:43:42-INFO:   global_step = 0
02:43:42-INFO:   inference_time = 7.848247766494751
02:43:42-INFO:   loss = None
attention_head_mask ['10:12']
['10', '12']
02:43:42-INFO: ***** Running evaluation *****
02:43:42-INFO:   Num examples = 872
02:43:42-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:50-INFO: ***** Eval results *****
02:43:50-INFO:   Accuracy = 0.930045871559633
02:43:50-INFO:   eval_accuracy = 0.930045871559633
02:43:50-INFO:   eval_loss = 0.23270804042528784
02:43:50-INFO:   global_step = 0
02:43:50-INFO:   inference_time = 7.846011400222778
02:43:50-INFO:   loss = None
attention_head_mask ['11:1']
['11', '1']
02:43:50-INFO: ***** Running evaluation *****
02:43:50-INFO:   Num examples = 872
02:43:50-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:43:58-INFO: ***** Eval results *****
02:43:58-INFO:   Accuracy = 0.926605504587156
02:43:58-INFO:   eval_accuracy = 0.926605504587156
02:43:58-INFO:   eval_loss = 0.23480734422004648
02:43:58-INFO:   global_step = 0
02:43:58-INFO:   inference_time = 7.865472316741943
02:43:58-INFO:   loss = None
attention_head_mask ['11:2']
['11', '2']
02:43:58-INFO: ***** Running evaluation *****
02:43:58-INFO:   Num examples = 872
02:43:58-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:06-INFO: ***** Eval results *****
02:44:06-INFO:   Accuracy = 0.930045871559633
02:44:06-INFO:   eval_accuracy = 0.930045871559633
02:44:06-INFO:   eval_loss = 0.22904941719025373
02:44:06-INFO:   global_step = 0
02:44:06-INFO:   inference_time = 7.862088918685913
02:44:06-INFO:   loss = None
attention_head_mask ['11:3']
['11', '3']
02:44:06-INFO: ***** Running evaluation *****
02:44:06-INFO:   Num examples = 872
02:44:06-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:13-INFO: ***** Eval results *****
02:44:13-INFO:   Accuracy = 0.9288990825688074
02:44:13-INFO:   eval_accuracy = 0.9288990825688074
02:44:13-INFO:   eval_loss = 0.23283386350210225
02:44:13-INFO:   global_step = 0
02:44:13-INFO:   inference_time = 7.860814332962036
02:44:13-INFO:   loss = None
attention_head_mask ['11:4']
['11', '4']
02:44:13-INFO: ***** Running evaluation *****
02:44:13-INFO:   Num examples = 872
02:44:13-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:21-INFO: ***** Eval results *****
02:44:21-INFO:   Accuracy = 0.9311926605504587
02:44:21-INFO:   eval_accuracy = 0.9311926605504587
02:44:21-INFO:   eval_loss = 0.23463135159441403
02:44:21-INFO:   global_step = 0
02:44:21-INFO:   inference_time = 7.858558416366577
02:44:21-INFO:   loss = None
attention_head_mask ['11:5']
['11', '5']
02:44:21-INFO: ***** Running evaluation *****
02:44:21-INFO:   Num examples = 872
02:44:21-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:29-INFO: ***** Eval results *****
02:44:29-INFO:   Accuracy = 0.9243119266055045
02:44:29-INFO:   eval_accuracy = 0.9243119266055045
02:44:29-INFO:   eval_loss = 0.2280475478619337
02:44:29-INFO:   global_step = 0
02:44:29-INFO:   inference_time = 7.8596351146698
02:44:29-INFO:   loss = None
attention_head_mask ['11:6']
['11', '6']
02:44:29-INFO: ***** Running evaluation *****
02:44:29-INFO:   Num examples = 872
02:44:29-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:37-INFO: ***** Eval results *****
02:44:37-INFO:   Accuracy = 0.9311926605504587
02:44:37-INFO:   eval_accuracy = 0.9311926605504587
02:44:37-INFO:   eval_loss = 0.23349579377099872
02:44:37-INFO:   global_step = 0
02:44:37-INFO:   inference_time = 7.859476804733276
02:44:37-INFO:   loss = None
attention_head_mask ['11:7']
['11', '7']
02:44:37-INFO: ***** Running evaluation *****
02:44:37-INFO:   Num examples = 872
02:44:37-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:45-INFO: ***** Eval results *****
02:44:45-INFO:   Accuracy = 0.9277522935779816
02:44:45-INFO:   eval_accuracy = 0.9277522935779816
02:44:45-INFO:   eval_loss = 0.23137982136436872
02:44:45-INFO:   global_step = 0
02:44:45-INFO:   inference_time = 7.860615491867065
02:44:45-INFO:   loss = None
attention_head_mask ['11:8']
['11', '8']
02:44:45-INFO: ***** Running evaluation *****
02:44:45-INFO:   Num examples = 872
02:44:45-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:44:53-INFO: ***** Eval results *****
02:44:53-INFO:   Accuracy = 0.9277522935779816
02:44:53-INFO:   eval_accuracy = 0.9277522935779816
02:44:53-INFO:   eval_loss = 0.23278974861438786
02:44:53-INFO:   global_step = 0
02:44:53-INFO:   inference_time = 7.858635187149048
02:44:53-INFO:   loss = None
attention_head_mask ['11:9']
['11', '9']
02:44:53-INFO: ***** Running evaluation *****
02:44:53-INFO:   Num examples = 872
02:44:53-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:45:01-INFO: ***** Eval results *****
02:45:01-INFO:   Accuracy = 0.930045871559633
02:45:01-INFO:   eval_accuracy = 0.930045871559633
02:45:01-INFO:   eval_loss = 0.23246071274791444
02:45:01-INFO:   global_step = 0
02:45:01-INFO:   inference_time = 7.858607530593872
02:45:01-INFO:   loss = None
attention_head_mask ['11:10']
['11', '10']
02:45:01-INFO: ***** Running evaluation *****
02:45:01-INFO:   Num examples = 872
02:45:01-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.54it/s]
02:45:09-INFO: ***** Eval results *****
02:45:09-INFO:   Accuracy = 0.9311926605504587
02:45:09-INFO:   eval_accuracy = 0.9311926605504587
02:45:09-INFO:   eval_loss = 0.23133254031251585
02:45:09-INFO:   global_step = 0
02:45:09-INFO:   inference_time = 7.865709543228149
02:45:09-INFO:   loss = None
attention_head_mask ['11:11']
['11', '11']
02:45:09-INFO: ***** Running evaluation *****
02:45:09-INFO:   Num examples = 872
02:45:09-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:45:17-INFO: ***** Eval results *****
02:45:17-INFO:   Accuracy = 0.930045871559633
02:45:17-INFO:   eval_accuracy = 0.930045871559633
02:45:17-INFO:   eval_loss = 0.23073096367131388
02:45:17-INFO:   global_step = 0
02:45:17-INFO:   inference_time = 7.8593034744262695
02:45:17-INFO:   loss = None
attention_head_mask ['11:12']
['11', '12']
02:45:17-INFO: ***** Running evaluation *****
02:45:17-INFO:   Num examples = 872
02:45:17-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.55it/s]
02:45:25-INFO: ***** Eval results *****
02:45:25-INFO:   Accuracy = 0.9288990825688074
02:45:25-INFO:   eval_accuracy = 0.9288990825688074
02:45:25-INFO:   eval_loss = 0.2207310198407088
02:45:25-INFO:   global_step = 0
02:45:25-INFO:   inference_time = 7.858251571655273
02:45:25-INFO:   loss = None
attention_head_mask ['12:1']
['12', '1']
02:45:25-INFO: ***** Running evaluation *****
02:45:25-INFO:   Num examples = 872
02:45:25-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.54it/s]
02:45:32-INFO: ***** Eval results *****
02:45:32-INFO:   Accuracy = 0.9254587155963303
02:45:32-INFO:   eval_accuracy = 0.9254587155963303
02:45:32-INFO:   eval_loss = 0.21832259624664271
02:45:32-INFO:   global_step = 0
02:45:32-INFO:   inference_time = 7.8702380657196045
02:45:32-INFO:   loss = None
attention_head_mask ['12:2']
['12', '2']
02:45:33-INFO: ***** Running evaluation *****
02:45:33-INFO:   Num examples = 872
02:45:33-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.54it/s]
02:45:40-INFO: ***** Eval results *****
02:45:40-INFO:   Accuracy = 0.9254587155963303
02:45:40-INFO:   eval_accuracy = 0.9254587155963303
02:45:40-INFO:   eval_loss = 0.21841583786798374
02:45:40-INFO:   global_step = 0
02:45:40-INFO:   inference_time = 7.871493816375732
02:45:40-INFO:   loss = None
attention_head_mask ['12:3']
['12', '3']
02:45:40-INFO: ***** Running evaluation *****
02:45:40-INFO:   Num examples = 872
02:45:40-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.54it/s]
02:45:48-INFO: ***** Eval results *****
02:45:48-INFO:   Accuracy = 0.930045871559633
02:45:48-INFO:   eval_accuracy = 0.930045871559633
02:45:48-INFO:   eval_loss = 0.22359406908175775
02:45:48-INFO:   global_step = 0
02:45:48-INFO:   inference_time = 7.871984481811523
02:45:48-INFO:   loss = None
attention_head_mask ['12:4']
['12', '4']
02:50:20-INFO: ***** Running evaluation *****
02:50:20-INFO:   Num examples = 872
02:50:20-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.59it/s]
02:50:28-INFO: ***** Eval results *****
02:50:28-INFO:   Accuracy = 0.9277522935779816
02:50:28-INFO:   eval_accuracy = 0.9277522935779816
02:50:28-INFO:   eval_loss = 0.233596340620092
02:50:28-INFO:   global_step = 0
02:50:28-INFO:   inference_time = 7.755081653594971
02:50:28-INFO:   loss = None
attention_head_mask ['12:5']
['12', '5']
02:50:28-INFO: ***** Running evaluation *****
02:50:28-INFO:   Num examples = 872
02:50:28-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.61it/s]
02:50:36-INFO: ***** Eval results *****
02:50:36-INFO:   Accuracy = 0.9288990825688074
02:50:36-INFO:   eval_accuracy = 0.9288990825688074
02:50:36-INFO:   eval_loss = 0.22888057266495057
02:50:36-INFO:   global_step = 0
02:50:36-INFO:   inference_time = 7.732149839401245
02:50:36-INFO:   loss = None
attention_head_mask ['12:6']
['12', '6']
02:50:36-INFO: ***** Running evaluation *****
02:50:36-INFO:   Num examples = 872
02:50:36-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:50:44-INFO: ***** Eval results *****
02:50:44-INFO:   Accuracy = 0.9288990825688074
02:50:44-INFO:   eval_accuracy = 0.9288990825688074
02:50:44-INFO:   eval_loss = 0.2290349095793707
02:50:44-INFO:   global_step = 0
02:50:44-INFO:   inference_time = 7.738322973251343
02:50:44-INFO:   loss = None
attention_head_mask ['12:7']
['12', '7']
02:50:44-INFO: ***** Running evaluation *****
02:50:44-INFO:   Num examples = 872
02:50:44-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:50:52-INFO: ***** Eval results *****
02:50:52-INFO:   Accuracy = 0.9288990825688074
02:50:52-INFO:   eval_accuracy = 0.9288990825688074
02:50:52-INFO:   eval_loss = 0.22395001870713063
02:50:52-INFO:   global_step = 0
02:50:52-INFO:   inference_time = 7.740888833999634
02:50:52-INFO:   loss = None
attention_head_mask ['12:8']
['12', '8']
02:50:52-INFO: ***** Running evaluation *****
02:50:52-INFO:   Num examples = 872
02:50:52-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:50:59-INFO: ***** Eval results *****
02:50:59-INFO:   Accuracy = 0.9288990825688074
02:50:59-INFO:   eval_accuracy = 0.9288990825688074
02:50:59-INFO:   eval_loss = 0.2339617178908416
02:50:59-INFO:   global_step = 0
02:50:59-INFO:   inference_time = 7.733635902404785
02:50:59-INFO:   loss = None
attention_head_mask ['12:9']
['12', '9']
02:50:59-INFO: ***** Running evaluation *****
02:50:59-INFO:   Num examples = 872
02:50:59-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:51:07-INFO: ***** Eval results *****
02:51:07-INFO:   Accuracy = 0.9323394495412844
02:51:07-INFO:   eval_accuracy = 0.9323394495412844
02:51:07-INFO:   eval_loss = 0.23308992984571628
02:51:07-INFO:   global_step = 0
02:51:07-INFO:   inference_time = 7.732900381088257
02:51:07-INFO:   loss = None
attention_head_mask ['12:10']
['12', '10']
02:51:07-INFO: ***** Running evaluation *****
02:51:07-INFO:   Num examples = 872
02:51:07-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:51:15-INFO: ***** Eval results *****
02:51:15-INFO:   Accuracy = 0.9288990825688074
02:51:15-INFO:   eval_accuracy = 0.9288990825688074
02:51:15-INFO:   eval_loss = 0.23632571114493267
02:51:15-INFO:   global_step = 0
02:51:15-INFO:   inference_time = 7.73317551612854
02:51:15-INFO:   loss = None
attention_head_mask ['12:11']
['12', '11']
02:51:15-INFO: ***** Running evaluation *****
02:51:15-INFO:   Num examples = 872
02:51:15-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.60it/s]
02:51:23-INFO: ***** Eval results *****
02:51:23-INFO:   Accuracy = 0.9277522935779816
02:51:23-INFO:   eval_accuracy = 0.9277522935779816
02:51:23-INFO:   eval_loss = 0.22956024802156857
02:51:23-INFO:   global_step = 0
02:51:23-INFO:   inference_time = 7.7343878746032715
02:51:23-INFO:   loss = None
attention_head_mask ['12:12']
['12', '12']
02:51:23-INFO: ***** Running evaluation *****
02:51:23-INFO:   Num examples = 872
02:51:23-INFO:   Batch size = 32
Evaluating: 100% 28/28 [00:07<00:00,  3.58it/s]
02:51:30-INFO: ***** Eval results *****
02:51:30-INFO:   Accuracy = 0.9277522935779816
02:51:30-INFO:   eval_accuracy = 0.9277522935779816
02:51:30-INFO:   eval_loss = 0.2335926710761019
02:51:30-INFO:   global_step = 0
02:51:30-INFO:   inference_time = 7.7792510986328125
02:51:30-INFO:   loss = None