MNLI

训练：

16:38:59-INFO: ***** Running training *****
16:38:59-INFO:   Num examples = 3668
16:38:59-INFO:   Batch size = 32
16:38:59-INFO:   Num steps = 342.0
Epoch:   0% 0/3 [00:00<?, ?it/s]
Iteration:   0% 0/115 [00:00<?, ?it/s]/content/drive/MyDrive/are-16-heads-really-better-than-1/pytorch-pretrained-BERT/pytorch_pretrained_bert/optimization.py:144: UserWarning: This overload of add_ is deprecated:
add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)
next_m.mul_(beta1).add_(1 - beta1, grad)
Iteration:   1% 1/115 [00:00<01:41,  1.13it/s]
Iteration:   2% 2/115 [00:01<01:30,  1.25it/s]
Iteration:   3% 3/115 [00:02<01:26,  1.29it/s]
Iteration:   3% 4/115 [00:03<01:24,  1.31it/s]
Iteration:   4% 5/115 [00:03<01:23,  1.32it/s]
Iteration:   5% 6/115 [00:04<01:22,  1.32it/s]
Iteration:   6% 7/115 [00:05<01:21,  1.32it/s]
Iteration:   7% 8/115 [00:06<01:20,  1.33it/s]
Iteration:   8% 9/115 [00:06<01:19,  1.33it/s]
Iteration:   9% 10/115 [00:07<01:19,  1.33it/s]
Iteration:  10% 11/115 [00:08<01:18,  1.33it/s]
Iteration:  10% 12/115 [00:09<01:17,  1.33it/s]
Iteration:  11% 13/115 [00:09<01:16,  1.33it/s]
Iteration:  12% 14/115 [00:10<01:15,  1.33it/s]
Iteration:  13% 15/115 [00:11<01:15,  1.33it/s]
Iteration:  14% 16/115 [00:12<01:14,  1.33it/s]
Iteration:  15% 17/115 [00:12<01:13,  1.33it/s]
Iteration:  16% 18/115 [00:13<01:12,  1.33it/s]
Iteration:  17% 19/115 [00:14<01:12,  1.33it/s]
Iteration:  17% 20/115 [00:15<01:11,  1.33it/s]
Iteration:  18% 21/115 [00:15<01:10,  1.33it/s]
Iteration:  19% 22/115 [00:16<01:10,  1.33it/s]
Iteration:  20% 23/115 [00:17<01:09,  1.32it/s]
Iteration:  21% 24/115 [00:18<01:08,  1.32it/s]
Iteration:  22% 25/115 [00:18<01:08,  1.32it/s]
Iteration:  23% 26/115 [00:19<01:07,  1.32it/s]
Iteration:  23% 27/115 [00:20<01:06,  1.32it/s]
Iteration:  24% 28/115 [00:21<01:05,  1.32it/s]
Iteration:  25% 29/115 [00:21<01:05,  1.32it/s]
Iteration:  26% 30/115 [00:22<01:04,  1.32it/s]
Iteration:  27% 31/115 [00:23<01:04,  1.31it/s]
Iteration:  28% 32/115 [00:24<01:03,  1.31it/s]
Iteration:  29% 33/115 [00:25<01:02,  1.31it/s]
Iteration:  30% 34/115 [00:25<01:01,  1.31it/s]
Iteration:  30% 35/115 [00:26<01:01,  1.31it/s]
Iteration:  31% 36/115 [00:27<01:00,  1.31it/s]
Iteration:  32% 37/115 [00:28<00:59,  1.31it/s]
Iteration:  33% 38/115 [00:28<00:58,  1.31it/s]
Iteration:  34% 39/115 [00:29<00:58,  1.30it/s]
Iteration:  35% 40/115 [00:30<00:57,  1.30it/s]
Iteration:  36% 41/115 [00:31<00:56,  1.30it/s]
Iteration:  37% 42/115 [00:31<00:56,  1.30it/s]
Iteration:  37% 43/115 [00:32<00:55,  1.29it/s]
Iteration:  38% 44/115 [00:33<00:54,  1.29it/s]
Iteration:  39% 45/115 [00:34<00:54,  1.29it/s]
Iteration:  40% 46/115 [00:35<00:53,  1.29it/s]
Iteration:  41% 47/115 [00:35<00:52,  1.29it/s]
Iteration:  42% 48/115 [00:36<00:51,  1.29it/s]
Iteration:  43% 49/115 [00:37<00:51,  1.29it/s]
Iteration:  43% 50/115 [00:38<00:50,  1.29it/s]
Iteration:  44% 51/115 [00:38<00:49,  1.29it/s]
Iteration:  45% 52/115 [00:39<00:49,  1.28it/s]
Iteration:  46% 53/115 [00:40<00:48,  1.29it/s]
Iteration:  47% 54/115 [00:41<00:47,  1.28it/s]
Iteration:  48% 55/115 [00:42<00:46,  1.28it/s]
Iteration:  49% 56/115 [00:42<00:46,  1.28it/s]
Iteration:  50% 57/115 [00:43<00:45,  1.28it/s]
Iteration:  50% 58/115 [00:44<00:44,  1.28it/s]
Iteration:  51% 59/115 [00:45<00:43,  1.28it/s]
Iteration:  52% 60/115 [00:45<00:42,  1.28it/s]
Iteration:  53% 61/115 [00:46<00:42,  1.28it/s]
Iteration:  54% 62/115 [00:47<00:41,  1.28it/s]
Iteration:  55% 63/115 [00:48<00:40,  1.27it/s]
Iteration:  56% 64/115 [00:49<00:40,  1.27it/s]
Iteration:  57% 65/115 [00:49<00:39,  1.28it/s]
Iteration:  57% 66/115 [00:50<00:38,  1.27it/s]
Iteration:  58% 67/115 [00:51<00:37,  1.27it/s]
Iteration:  59% 68/115 [00:52<00:37,  1.27it/s]
Iteration:  60% 69/115 [00:53<00:36,  1.27it/s]
Iteration:  61% 70/115 [00:53<00:35,  1.27it/s]
Iteration:  62% 71/115 [00:54<00:34,  1.27it/s]
Iteration:  63% 72/115 [00:55<00:33,  1.27it/s]
Iteration:  63% 73/115 [00:56<00:33,  1.27it/s]
Iteration:  64% 74/115 [00:56<00:32,  1.27it/s]
Iteration:  65% 75/115 [00:57<00:31,  1.27it/s]
Iteration:  66% 76/115 [00:58<00:30,  1.27it/s]
Iteration:  67% 77/115 [00:59<00:29,  1.27it/s]
Iteration:  68% 78/115 [01:00<00:29,  1.27it/s]
Iteration:  69% 79/115 [01:00<00:28,  1.27it/s]
Iteration:  70% 80/115 [01:01<00:27,  1.27it/s]
Iteration:  70% 81/115 [01:02<00:26,  1.27it/s]
Iteration:  71% 82/115 [01:03<00:26,  1.26it/s]
Iteration:  72% 83/115 [01:04<00:25,  1.26it/s]
Iteration:  73% 84/115 [01:04<00:24,  1.27it/s]
Iteration:  74% 85/115 [01:05<00:23,  1.26it/s]
Iteration:  75% 86/115 [01:06<00:22,  1.26it/s]
Iteration:  76% 87/115 [01:07<00:22,  1.27it/s]
Iteration:  77% 88/115 [01:08<00:21,  1.26it/s]
Iteration:  77% 89/115 [01:08<00:20,  1.26it/s]
Iteration:  78% 90/115 [01:09<00:19,  1.26it/s]
Iteration:  79% 91/115 [01:10<00:18,  1.27it/s]
Iteration:  80% 92/115 [01:11<00:18,  1.26it/s]
Iteration:  81% 93/115 [01:12<00:17,  1.26it/s]
Iteration:  82% 94/115 [01:12<00:16,  1.26it/s]
Iteration:  83% 95/115 [01:13<00:15,  1.27it/s]
Iteration:  83% 96/115 [01:14<00:14,  1.27it/s]
Iteration:  84% 97/115 [01:15<00:14,  1.27it/s]
Iteration:  85% 98/115 [01:15<00:13,  1.27it/s]
Iteration:  86% 99/115 [01:16<00:12,  1.27it/s]
Iteration:  87% 100/115 [01:17<00:11,  1.27it/s]
Iteration:  88% 101/115 [01:18<00:11,  1.27it/s]
Iteration:  89% 102/115 [01:19<00:10,  1.27it/s]
Iteration:  90% 103/115 [01:19<00:09,  1.27it/s]
Iteration:  90% 104/115 [01:20<00:08,  1.26it/s]
Iteration:  91% 105/115 [01:21<00:07,  1.27it/s]
Iteration:  92% 106/115 [01:22<00:07,  1.26it/s]
Iteration:  93% 107/115 [01:23<00:06,  1.27it/s]
Iteration:  94% 108/115 [01:23<00:05,  1.26it/s]
Iteration:  95% 109/115 [01:24<00:04,  1.26it/s]
Iteration:  96% 110/115 [01:25<00:03,  1.26it/s]
Iteration:  97% 111/115 [01:26<00:03,  1.26it/s]
Iteration:  97% 112/115 [01:27<00:02,  1.26it/s]
Iteration:  98% 113/115 [01:27<00:01,  1.26it/s]
Iteration:  99% 114/115 [01:28<00:00,  1.26it/s]
Iteration: 100% 115/115 [01:29<00:00,  1.29it/s]
Epoch:  33% 1/3 [01:29<02:58, 89.13s/it]
Iteration:   0% 0/115 [00:00<?, ?it/s]
Iteration:   1% 1/115 [00:00<01:28,  1.28it/s]
Iteration:   2% 2/115 [00:01<01:28,  1.27it/s]
Iteration:   3% 3/115 [00:02<01:28,  1.26it/s]
Iteration:   3% 4/115 [00:03<01:28,  1.26it/s]
Iteration:   4% 5/115 [00:03<01:27,  1.26it/s]
Iteration:   5% 6/115 [00:04<01:26,  1.26it/s]
Iteration:   6% 7/115 [00:05<01:26,  1.25it/s]
Iteration:   7% 8/115 [00:06<01:25,  1.25it/s]
Iteration:   8% 9/115 [00:07<01:24,  1.25it/s]
Iteration:   9% 10/115 [00:07<01:23,  1.25it/s]
Iteration:  10% 11/115 [00:08<01:23,  1.25it/s]
Iteration:  10% 12/115 [00:09<01:22,  1.25it/s]
Iteration:  11% 13/115 [00:10<01:21,  1.25it/s]
Iteration:  12% 14/115 [00:11<01:20,  1.25it/s]
Iteration:  13% 15/115 [00:11<01:19,  1.25it/s]
Iteration:  14% 16/115 [00:12<01:19,  1.25it/s]
Iteration:  15% 17/115 [00:13<01:18,  1.25it/s]
Iteration:  16% 18/115 [00:14<01:17,  1.25it/s]
Iteration:  17% 19/115 [00:15<01:17,  1.24it/s]
Iteration:  17% 20/115 [00:15<01:16,  1.24it/s]
Iteration:  18% 21/115 [00:16<01:15,  1.24it/s]
Iteration:  19% 22/115 [00:17<01:14,  1.24it/s]
Iteration:  20% 23/115 [00:18<01:14,  1.24it/s]
Iteration:  21% 24/115 [00:19<01:13,  1.24it/s]
Iteration:  22% 25/115 [00:20<01:12,  1.24it/s]
Iteration:  23% 26/115 [00:20<01:12,  1.23it/s]
Iteration:  23% 27/115 [00:21<01:11,  1.24it/s]
Iteration:  24% 28/115 [00:22<01:10,  1.23it/s]
Iteration:  25% 29/115 [00:23<01:09,  1.23it/s]
Iteration:  26% 30/115 [00:24<01:08,  1.23it/s]
Iteration:  27% 31/115 [00:24<01:08,  1.23it/s]
Iteration:  28% 32/115 [00:25<01:07,  1.23it/s]
Iteration:  29% 33/115 [00:26<01:06,  1.23it/s]
Iteration:  30% 34/115 [00:27<01:05,  1.23it/s]
Iteration:  30% 35/115 [00:28<01:05,  1.23it/s]
Iteration:  31% 36/115 [00:28<01:04,  1.23it/s]
Iteration:  32% 37/115 [00:29<01:03,  1.23it/s]
Iteration:  33% 38/115 [00:30<01:02,  1.23it/s]
Iteration:  34% 39/115 [00:31<01:01,  1.23it/s]
Iteration:  35% 40/115 [00:32<01:01,  1.23it/s]
Iteration:  36% 41/115 [00:33<01:00,  1.23it/s]
Iteration:  37% 42/115 [00:33<00:59,  1.22it/s]
Iteration:  37% 43/115 [00:34<00:58,  1.22it/s]
Iteration:  38% 44/115 [00:35<00:58,  1.22it/s]
Iteration:  39% 45/115 [00:36<00:57,  1.22it/s]
Iteration:  40% 46/115 [00:37<00:56,  1.22it/s]
Iteration:  41% 47/115 [00:37<00:55,  1.22it/s]
Iteration:  42% 48/115 [00:38<00:54,  1.22it/s]
Iteration:  43% 49/115 [00:39<00:53,  1.23it/s]
Iteration:  43% 50/115 [00:40<00:53,  1.23it/s]
Iteration:  44% 51/115 [00:41<00:52,  1.22it/s]
Iteration:  45% 52/115 [00:42<00:51,  1.22it/s]
Iteration:  46% 53/115 [00:42<00:50,  1.22it/s]
Iteration:  47% 54/115 [00:43<00:50,  1.22it/s]
Iteration:  48% 55/115 [00:44<00:49,  1.22it/s]
Iteration:  49% 56/115 [00:45<00:48,  1.22it/s]
Iteration:  50% 57/115 [00:46<00:47,  1.22it/s]
Iteration:  50% 58/115 [00:46<00:46,  1.22it/s]
Iteration:  51% 59/115 [00:47<00:45,  1.22it/s]
Iteration:  52% 60/115 [00:48<00:45,  1.22it/s]
Iteration:  53% 61/115 [00:49<00:44,  1.22it/s]
Iteration:  54% 62/115 [00:50<00:43,  1.21it/s]
Iteration:  55% 63/115 [00:51<00:42,  1.22it/s]
Iteration:  56% 64/115 [00:51<00:41,  1.22it/s]
Iteration:  57% 65/115 [00:52<00:40,  1.22it/s]
Iteration:  57% 66/115 [00:53<00:40,  1.22it/s]
Iteration:  58% 67/115 [00:54<00:39,  1.23it/s]
Iteration:  59% 68/115 [00:55<00:38,  1.23it/s]
Iteration:  60% 69/115 [00:55<00:37,  1.22it/s]
Iteration:  61% 70/115 [00:56<00:36,  1.22it/s]
Iteration:  62% 71/115 [00:57<00:36,  1.22it/s]
Iteration:  63% 72/115 [00:58<00:35,  1.22it/s]
Iteration:  63% 73/115 [00:59<00:34,  1.22it/s]
Iteration:  64% 74/115 [01:00<00:33,  1.22it/s]
Iteration:  65% 75/115 [01:00<00:32,  1.22it/s]
Iteration:  66% 76/115 [01:01<00:31,  1.22it/s]
Iteration:  67% 77/115 [01:02<00:31,  1.22it/s]
Iteration:  68% 78/115 [01:03<00:30,  1.22it/s]
Iteration:  69% 79/115 [01:04<00:29,  1.22it/s]
Iteration:  70% 80/115 [01:04<00:28,  1.22it/s]
Iteration:  70% 81/115 [01:05<00:27,  1.22it/s]
Iteration:  71% 82/115 [01:06<00:27,  1.22it/s]
Iteration:  72% 83/115 [01:07<00:26,  1.22it/s]
Iteration:  73% 84/115 [01:08<00:25,  1.22it/s]
Iteration:  74% 85/115 [01:09<00:24,  1.22it/s]
Iteration:  75% 86/115 [01:09<00:23,  1.22it/s]
Iteration:  76% 87/115 [01:10<00:22,  1.22it/s]
Iteration:  77% 88/115 [01:11<00:22,  1.22it/s]
Iteration:  77% 89/115 [01:12<00:21,  1.22it/s]
Iteration:  78% 90/115 [01:13<00:20,  1.22it/s]
Iteration:  79% 91/115 [01:13<00:19,  1.22it/s]
Iteration:  80% 92/115 [01:14<00:18,  1.22it/s]
Iteration:  81% 93/115 [01:15<00:18,  1.22it/s]
Iteration:  82% 94/115 [01:16<00:17,  1.22it/s]
Iteration:  83% 95/115 [01:17<00:16,  1.22it/s]
Iteration:  83% 96/115 [01:18<00:15,  1.22it/s]
Iteration:  84% 97/115 [01:18<00:14,  1.22it/s]
Iteration:  85% 98/115 [01:19<00:13,  1.22it/s]
Iteration:  86% 99/115 [01:20<00:13,  1.22it/s]
Iteration:  87% 100/115 [01:21<00:12,  1.22it/s]
Iteration:  88% 101/115 [01:22<00:11,  1.22it/s]
Iteration:  89% 102/115 [01:23<00:10,  1.22it/s]
Iteration:  90% 103/115 [01:23<00:09,  1.22it/s]
Iteration:  90% 104/115 [01:24<00:09,  1.21it/s]
Iteration:  91% 105/115 [01:25<00:08,  1.21it/s]
Iteration:  92% 106/115 [01:26<00:07,  1.21it/s]
Iteration:  93% 107/115 [01:27<00:06,  1.21it/s]
Iteration:  94% 108/115 [01:27<00:05,  1.21it/s]
Iteration:  95% 109/115 [01:28<00:04,  1.22it/s]
Iteration:  96% 110/115 [01:29<00:04,  1.21it/s]
Iteration:  97% 111/115 [01:30<00:03,  1.21it/s]
Iteration:  97% 112/115 [01:31<00:02,  1.22it/s]
Iteration:  98% 113/115 [01:32<00:01,  1.21it/s]
Iteration:  99% 114/115 [01:32<00:00,  1.21it/s]
Iteration: 100% 115/115 [01:33<00:00,  1.23it/s]
Epoch:  67% 2/3 [03:02<01:31, 91.67s/it]
Iteration:   0% 0/115 [00:00<?, ?it/s]
Iteration:   1% 1/115 [00:00<01:33,  1.22it/s]
Iteration:   2% 2/115 [00:01<01:33,  1.21it/s]
Iteration:   3% 3/115 [00:02<01:32,  1.21it/s]
Iteration:   3% 4/115 [00:03<01:34,  1.18it/s]
Iteration:   4% 5/115 [00:04<01:31,  1.20it/s]
Iteration:   5% 6/115 [00:05<01:31,  1.19it/s]
Iteration:   6% 7/115 [00:05<01:30,  1.20it/s]
Iteration:   7% 8/115 [00:06<01:28,  1.20it/s]
Iteration:   8% 9/115 [00:07<01:27,  1.21it/s]
Iteration:   9% 10/115 [00:08<01:26,  1.21it/s]
Iteration:  10% 11/115 [00:09<01:26,  1.21it/s]
Iteration:  10% 12/115 [00:09<01:25,  1.21it/s]
Iteration:  11% 13/115 [00:10<01:24,  1.21it/s]
Iteration:  12% 14/115 [00:11<01:23,  1.21it/s]
Iteration:  13% 15/115 [00:12<01:22,  1.21it/s]
Iteration:  14% 16/115 [00:13<01:21,  1.21it/s]
Iteration:  15% 17/115 [00:14<01:21,  1.21it/s]
Iteration:  16% 18/115 [00:14<01:20,  1.21it/s]
Iteration:  17% 19/115 [00:15<01:19,  1.21it/s]
Iteration:  17% 20/115 [00:16<01:18,  1.21it/s]
Iteration:  18% 21/115 [00:17<01:17,  1.21it/s]
Iteration:  19% 22/115 [00:18<01:17,  1.21it/s]
Iteration:  20% 23/115 [00:19<01:16,  1.21it/s]
Iteration:  21% 24/115 [00:19<01:15,  1.21it/s]
Iteration:  22% 25/115 [00:20<01:14,  1.21it/s]
Iteration:  23% 26/115 [00:21<01:13,  1.20it/s]
Iteration:  23% 27/115 [00:22<01:13,  1.20it/s]
Iteration:  24% 28/115 [00:23<01:12,  1.21it/s]
Iteration:  25% 29/115 [00:24<01:11,  1.21it/s]
Iteration:  26% 30/115 [00:24<01:10,  1.20it/s]
Iteration:  27% 31/115 [00:25<01:09,  1.20it/s]
Iteration:  28% 32/115 [00:26<01:09,  1.20it/s]
Iteration:  29% 33/115 [00:27<01:08,  1.20it/s]
Iteration:  30% 34/115 [00:28<01:07,  1.20it/s]
Iteration:  30% 35/115 [00:29<01:06,  1.20it/s]
Iteration:  31% 36/115 [00:29<01:05,  1.20it/s]
Iteration:  32% 37/115 [00:30<01:04,  1.20it/s]
Iteration:  33% 38/115 [00:31<01:04,  1.20it/s]
Iteration:  34% 39/115 [00:32<01:03,  1.20it/s]
Iteration:  35% 40/115 [00:33<01:02,  1.20it/s]
Iteration:  36% 41/115 [00:34<01:01,  1.20it/s]
Iteration:  37% 42/115 [00:34<01:00,  1.20it/s]
Iteration:  37% 43/115 [00:35<00:59,  1.21it/s]
Iteration:  38% 44/115 [00:36<00:58,  1.20it/s]
Iteration:  39% 45/115 [00:37<00:58,  1.20it/s]
Iteration:  40% 46/115 [00:38<00:57,  1.20it/s]
Iteration:  41% 47/115 [00:39<00:56,  1.20it/s]
Iteration:  42% 48/115 [00:39<00:55,  1.20it/s]
Iteration:  43% 49/115 [00:40<00:55,  1.20it/s]
Iteration:  43% 50/115 [00:41<00:54,  1.20it/s]
Iteration:  44% 51/115 [00:42<00:53,  1.20it/s]
Iteration:  45% 52/115 [00:43<00:52,  1.20it/s]
Iteration:  46% 53/115 [00:44<00:51,  1.19it/s]
Iteration:  47% 54/115 [00:44<00:50,  1.20it/s]
Iteration:  48% 55/115 [00:45<00:50,  1.20it/s]
Iteration:  49% 56/115 [00:46<00:49,  1.20it/s]
Iteration:  50% 57/115 [00:47<00:48,  1.20it/s]
Iteration:  50% 58/115 [00:48<00:47,  1.20it/s]
Iteration:  51% 59/115 [00:49<00:46,  1.19it/s]
Iteration:  52% 60/115 [00:49<00:45,  1.20it/s]
Iteration:  53% 61/115 [00:50<00:45,  1.20it/s]
Iteration:  54% 62/115 [00:51<00:44,  1.20it/s]
Iteration:  55% 63/115 [00:52<00:43,  1.20it/s]
Iteration:  56% 64/115 [00:53<00:42,  1.19it/s]
Iteration:  57% 65/115 [00:54<00:41,  1.19it/s]
Iteration:  57% 66/115 [00:54<00:41,  1.19it/s]
Iteration:  58% 67/115 [00:55<00:40,  1.19it/s]
Iteration:  59% 68/115 [00:56<00:39,  1.19it/s]
Iteration:  60% 69/115 [00:57<00:38,  1.19it/s]
Iteration:  61% 70/115 [00:58<00:37,  1.19it/s]
Iteration:  62% 71/115 [00:59<00:37,  1.19it/s]
Iteration:  63% 72/115 [00:59<00:36,  1.19it/s]
Iteration:  63% 73/115 [01:00<00:35,  1.19it/s]
Iteration:  64% 74/115 [01:01<00:34,  1.19it/s]
Iteration:  65% 75/115 [01:02<00:33,  1.19it/s]
Iteration:  66% 76/115 [01:03<00:32,  1.19it/s]
Iteration:  67% 77/115 [01:04<00:31,  1.19it/s]
Iteration:  68% 78/115 [01:05<00:31,  1.19it/s]
Iteration:  69% 79/115 [01:05<00:30,  1.19it/s]
Iteration:  70% 80/115 [01:06<00:29,  1.19it/s]
Iteration:  70% 81/115 [01:07<00:28,  1.19it/s]
Iteration:  71% 82/115 [01:08<00:27,  1.19it/s]
Iteration:  72% 83/115 [01:09<00:26,  1.19it/s]
Iteration:  73% 84/115 [01:10<00:26,  1.19it/s]
Iteration:  74% 85/115 [01:10<00:25,  1.19it/s]
Iteration:  75% 86/115 [01:11<00:24,  1.19it/s]
Iteration:  76% 87/115 [01:12<00:23,  1.19it/s]
Iteration:  77% 88/115 [01:13<00:22,  1.19it/s]
Iteration:  77% 89/115 [01:14<00:21,  1.19it/s]
Iteration:  78% 90/115 [01:15<00:21,  1.19it/s]
Iteration:  79% 91/115 [01:15<00:20,  1.19it/s]
Iteration:  80% 92/115 [01:16<00:19,  1.19it/s]
Iteration:  81% 93/115 [01:17<00:18,  1.19it/s]
Iteration:  82% 94/115 [01:18<00:17,  1.19it/s]
Iteration:  83% 95/115 [01:19<00:16,  1.19it/s]
Iteration:  83% 96/115 [01:20<00:15,  1.19it/s]
Iteration:  84% 97/115 [01:21<00:15,  1.19it/s]
Iteration:  85% 98/115 [01:21<00:14,  1.19it/s]
Iteration:  86% 99/115 [01:22<00:13,  1.19it/s]
Iteration:  87% 100/115 [01:23<00:12,  1.19it/s]
Iteration:  88% 101/115 [01:24<00:11,  1.19it/s]
Iteration:  89% 102/115 [01:25<00:10,  1.18it/s]
Iteration:  90% 103/115 [01:26<00:10,  1.18it/s]
Iteration:  90% 104/115 [01:26<00:09,  1.18it/s]
Iteration:  91% 105/115 [01:27<00:08,  1.18it/s]
Iteration:  92% 106/115 [01:28<00:07,  1.18it/s]
Iteration:  93% 107/115 [01:29<00:06,  1.18it/s]
Iteration:  94% 108/115 [01:30<00:05,  1.18it/s]
Iteration:  95% 109/115 [01:31<00:05,  1.18it/s]
Iteration:  96% 110/115 [01:32<00:04,  1.18it/s]
Iteration:  97% 111/115 [01:32<00:03,  1.18it/s]
Iteration:  97% 112/115 [01:33<00:02,  1.18it/s]
Iteration:  98% 113/115 [01:34<00:01,  1.18it/s]
Iteration:  99% 114/115 [01:35<00:00,  1.19it/s]
Iteration: 100% 115/115 [01:35<00:00,  1.20it/s]
Epoch: 100% 3/3 [04:38<00:00, 92.84s/it]
16:43:38-INFO: ***** Finished training *****
16:43:38-INFO:   Global step = 3668
16:43:38-INFO:   Training loss = 0.411
tot 278.5137462615967 =========
16:43:41-INFO: <https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz> not found in cache, downloading to /tmp/tmp7ummmv9i
100% 407873900/407873900 [00:33<00:00, 12207538.29B/s]
16:44:16-INFO: copying /tmp/tmp7ummmv9i to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
16:44:16-INFO: creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
16:44:16-INFO: removing temp file /tmp/tmp7ummmv9i
16:44:16-INFO: loading archive file <https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz> from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
16:44:16-INFO: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp0otiu8_x
16:44:20-INFO: Model config {
"attention_probs_dropout_prob": 0.1,
"hidden_act": "gelu",
"hidden_dropout_prob": 0.1,
"hidden_size": 768,
"initializer_range": 0.02,
"intermediate_size": 3072,
"max_position_embeddings": 512,
"num_attention_heads": 12,
"num_hidden_layers": 12,
"type_vocab_size": 2,
"vocab_size": 30522
}



测试：

16:44:22-INFO: ***** Running evaluation *****
16:44:22-INFO:   Num examples = 408
16:44:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.91it/s]
16:44:28-INFO: ***** Eval results *****
16:44:28-INFO:   F-1 score = 0.9008695652173914
16:44:28-INFO:   eval_accuracy = 0.8602941176470589
16:44:28-INFO:   eval_loss = 0.3765607671095775
16:44:28-INFO:   global_step = 345
16:44:28-INFO:   inference_time = 6.788403034210205
16:44:28-INFO:   loss = 0.4107570111319639



16:49:42-INFO: Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']
16:49:42-INFO: Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
16:49:47-INFO: loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba
16:49:47-INFO: extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpsvxyd07u
16:49:51-INFO: Model config {
  "attention_probs_dropout_prob": 0.1,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "type_vocab_size": 2,
  "vocab_size": 30522
}



测试head剪枝：

attention_head_mask ['1:1']
['1', '1']
16:49:53-INFO: ***** Running evaluation *****
16:49:53-INFO:   Num examples = 408
16:49:53-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.08it/s]
16:49:59-INFO: ***** Eval results *****
16:49:59-INFO:   F-1 score = 0.9008695652173914
16:49:59-INFO:   eval_accuracy = 0.8602941176470589
16:49:59-INFO:   eval_loss = 0.37275193746273333
16:49:59-INFO:   global_step = 0
16:49:59-INFO:   inference_time = 6.18770694732666
16:49:59-INFO:   loss = None
attention_head_mask ['1:2']
['1', '2']
16:49:59-INFO: ***** Running evaluation *****
16:49:59-INFO:   Num examples = 408
16:49:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.10it/s]
16:50:05-INFO: ***** Eval results *****
16:50:05-INFO:   F-1 score = 0.8961937716262977
16:50:05-INFO:   eval_accuracy = 0.8529411764705882
16:50:05-INFO:   eval_loss = 0.3814176286642368
16:50:05-INFO:   global_step = 0
16:50:05-INFO:   inference_time = 6.18612265586853
16:50:05-INFO:   loss = None
attention_head_mask ['1:3']
['1', '3']
16:50:05-INFO: ***** Running evaluation *****
16:50:05-INFO:   Num examples = 408
16:50:05-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.09it/s]
16:50:11-INFO: ***** Eval results *****
16:50:11-INFO:   F-1 score = 0.8993055555555555
16:50:11-INFO:   eval_accuracy = 0.8578431372549019
16:50:11-INFO:   eval_loss = 0.3755735388168922
16:50:11-INFO:   global_step = 0
16:50:11-INFO:   inference_time = 6.209527254104614
16:50:11-INFO:   loss = None
attention_head_mask ['1:4']
['1', '4']
16:50:11-INFO: ***** Running evaluation *****
16:50:11-INFO:   Num examples = 408
16:50:11-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.09it/s]
16:50:17-INFO: ***** Eval results *****
16:50:17-INFO:   F-1 score = 0.906896551724138
16:50:17-INFO:   eval_accuracy = 0.8676470588235294
16:50:17-INFO:   eval_loss = 0.3782016600553806
16:50:17-INFO:   global_step = 0
16:50:17-INFO:   inference_time = 6.197864532470703
16:50:17-INFO:   loss = None
attention_head_mask ['1:5']
['1', '5']
16:50:17-INFO: ***** Running evaluation *****
16:50:17-INFO:   Num examples = 408
16:50:17-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.09it/s]
16:50:24-INFO: ***** Eval results *****
16:50:24-INFO:   F-1 score = 0.9008695652173914
16:50:24-INFO:   eval_accuracy = 0.8602941176470589
16:50:24-INFO:   eval_loss = 0.3688046553960213
16:50:24-INFO:   global_step = 0
16:50:24-INFO:   inference_time = 6.208428859710693
16:50:24-INFO:   loss = None
attention_head_mask ['1:6']
['1', '6']
16:50:24-INFO: ***** Running evaluation *****
16:50:24-INFO:   Num examples = 408
16:50:24-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.09it/s]
16:50:30-INFO: ***** Eval results *****
16:50:30-INFO:   F-1 score = 0.8984509466437176
16:50:30-INFO:   eval_accuracy = 0.8553921568627451
16:50:30-INFO:   eval_loss = 0.3768148628564981
16:50:30-INFO:   global_step = 0
16:50:30-INFO:   inference_time = 6.2076122760772705
16:50:30-INFO:   loss = None
attention_head_mask ['1:7']
['1', '7']
16:50:30-INFO: ***** Running evaluation *****
16:50:30-INFO:   Num examples = 408
16:50:30-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.08it/s]
16:50:36-INFO: ***** Eval results *****
16:50:36-INFO:   F-1 score = 0.8996539792387542
16:50:36-INFO:   eval_accuracy = 0.8578431372549019
16:50:36-INFO:   eval_loss = 0.3746452583716466
16:50:36-INFO:   global_step = 0
16:50:36-INFO:   inference_time = 6.2490129470825195
16:50:36-INFO:   loss = None
attention_head_mask ['1:8']
['1', '8']
16:50:36-INFO: ***** Running evaluation *****
16:50:36-INFO:   Num examples = 408
16:50:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.06it/s]
16:50:43-INFO: ***** Eval results *****
16:50:43-INFO:   F-1 score = 0.9012131715771231
16:50:43-INFO:   eval_accuracy = 0.8602941176470589
16:50:43-INFO:   eval_loss = 0.3773716986179352
16:50:43-INFO:   global_step = 0
16:50:43-INFO:   inference_time = 6.3045103549957275
16:50:43-INFO:   loss = None
attention_head_mask ['1:9']
['1', '9']
16:50:43-INFO: ***** Running evaluation *****
16:50:43-INFO:   Num examples = 408
16:50:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.04it/s]
16:50:49-INFO: ***** Eval results *****
16:50:49-INFO:   F-1 score = 0.8982456140350877
16:50:49-INFO:   eval_accuracy = 0.8578431372549019
16:50:49-INFO:   eval_loss = 0.35644474854836095
16:50:49-INFO:   global_step = 0
16:50:49-INFO:   inference_time = 6.364531517028809
16:50:49-INFO:   loss = None
attention_head_mask ['1:10']
['1', '10']
16:50:49-INFO: ***** Running evaluation *****
16:50:49-INFO:   Num examples = 408
16:50:49-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.01it/s]
16:50:55-INFO: ***** Eval results *****
16:50:55-INFO:   F-1 score = 0.903448275862069
16:50:55-INFO:   eval_accuracy = 0.8627450980392157
16:50:55-INFO:   eval_loss = 0.3858653742533464
16:50:55-INFO:   global_step = 0
16:50:55-INFO:   inference_time = 6.4447021484375
16:50:55-INFO:   loss = None
attention_head_mask ['1:11']
['1', '11']
16:50:55-INFO: ***** Running evaluation *****
16:50:55-INFO:   Num examples = 408
16:50:55-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.00it/s]
16:51:02-INFO: ***** Eval results *****
16:51:02-INFO:   F-1 score = 0.9018932874354562
16:51:02-INFO:   eval_accuracy = 0.8602941176470589
16:51:02-INFO:   eval_loss = 0.3861247507425455
16:51:02-INFO:   global_step = 0
16:51:02-INFO:   inference_time = 6.489213705062866
16:51:02-INFO:   loss = None
attention_head_mask ['1:12']
['1', '12']
16:51:02-INFO: ***** Running evaluation *****
16:51:02-INFO:   Num examples = 408
16:51:02-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.02it/s]
16:51:08-INFO: ***** Eval results *****
16:51:08-INFO:   F-1 score = 0.9012131715771231
16:51:08-INFO:   eval_accuracy = 0.8602941176470589
16:51:08-INFO:   eval_loss = 0.3781616458526024
16:51:08-INFO:   global_step = 0
16:51:08-INFO:   inference_time = 6.433061838150024
16:51:08-INFO:   loss = None
attention_head_mask ['2:1']
['2', '1']
16:51:08-INFO: ***** Running evaluation *****
16:51:08-INFO:   Num examples = 408
16:51:08-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  2.00it/s]
16:51:15-INFO: ***** Eval results *****
16:51:15-INFO:   F-1 score = 0.8993055555555555
16:51:15-INFO:   eval_accuracy = 0.8578431372549019
16:51:15-INFO:   eval_loss = 0.3711437525657507
16:51:15-INFO:   global_step = 0
16:51:15-INFO:   inference_time = 6.495637655258179
16:51:15-INFO:   loss = None
attention_head_mask ['2:2']
['2', '2']
16:51:15-INFO: ***** Running evaluation *****
16:51:15-INFO:   Num examples = 408
16:51:15-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.98it/s]
16:51:21-INFO: ***** Eval results *****
16:51:21-INFO:   F-1 score = 0.9053356282271946
16:51:21-INFO:   eval_accuracy = 0.8651960784313726
16:51:21-INFO:   eval_loss = 0.38622687527766597
16:51:21-INFO:   global_step = 0
16:51:21-INFO:   inference_time = 6.558332443237305
16:51:21-INFO:   loss = None
attention_head_mask ['2:3']
['2', '3']
16:51:21-INFO: ***** Running evaluation *****
16:51:21-INFO:   Num examples = 408
16:51:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.97it/s]
16:51:28-INFO: ***** Eval results *****
16:51:28-INFO:   F-1 score = 0.9003436426116839
16:51:28-INFO:   eval_accuracy = 0.8578431372549019
16:51:28-INFO:   eval_loss = 0.38499369529577404
16:51:28-INFO:   global_step = 0
16:51:28-INFO:   inference_time = 6.597840070724487
16:51:28-INFO:   loss = None
attention_head_mask ['2:4']
['2', '4']
16:51:28-INFO: ***** Running evaluation *****
16:51:28-INFO:   Num examples = 408
16:51:28-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.95it/s]
16:51:35-INFO: ***** Eval results *****
16:51:35-INFO:   F-1 score = 0.8981001727115717
16:51:35-INFO:   eval_accuracy = 0.8553921568627451
16:51:35-INFO:   eval_loss = 0.37707087053702426
16:51:35-INFO:   global_step = 0
16:51:35-INFO:   inference_time = 6.6539459228515625
16:51:35-INFO:   loss = None
attention_head_mask ['2:5']
['2', '5']
16:51:35-INFO: ***** Running evaluation *****
16:51:35-INFO:   Num examples = 408
16:51:35-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.93it/s]
16:51:41-INFO: ***** Eval results *****
16:51:41-INFO:   F-1 score = 0.8984509466437176
16:51:41-INFO:   eval_accuracy = 0.8553921568627451
16:51:41-INFO:   eval_loss = 0.3795597874201261
16:51:41-INFO:   global_step = 0
16:51:41-INFO:   inference_time = 6.708465576171875
16:51:41-INFO:   loss = None
attention_head_mask ['2:6']
['2', '6']
16:51:41-INFO: ***** Running evaluation *****
16:51:41-INFO:   Num examples = 408
16:51:41-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.92it/s]
16:51:48-INFO: ***** Eval results *****
16:51:48-INFO:   F-1 score = 0.9050086355785838
16:51:48-INFO:   eval_accuracy = 0.8651960784313726
16:51:48-INFO:   eval_loss = 0.37603106750891757
16:51:48-INFO:   global_step = 0
16:51:48-INFO:   inference_time = 6.745068550109863
16:51:48-INFO:   loss = None
attention_head_mask ['2:7']
['2', '7']
16:51:48-INFO: ***** Running evaluation *****
16:51:48-INFO:   Num examples = 408
16:51:48-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.91it/s]
16:51:55-INFO: ***** Eval results *****
16:51:55-INFO:   F-1 score = 0.8999999999999999
16:51:55-INFO:   eval_accuracy = 0.8578431372549019
16:51:55-INFO:   eval_loss = 0.3761418072076944
16:51:55-INFO:   global_step = 0
16:51:55-INFO:   inference_time = 6.789089202880859
16:51:55-INFO:   loss = None
attention_head_mask ['2:8']
['2', '8']
16:51:55-INFO: ***** Running evaluation *****
16:51:55-INFO:   Num examples = 408
16:51:55-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.90it/s]
16:52:02-INFO: ***** Eval results *****
16:52:02-INFO:   F-1 score = 0.9017543859649123
16:52:02-INFO:   eval_accuracy = 0.8627450980392157
16:52:02-INFO:   eval_loss = 0.3545144016926105
16:52:02-INFO:   global_step = 0
16:52:02-INFO:   inference_time = 6.836250066757202
16:52:02-INFO:   loss = None
attention_head_mask ['2:9']
['2', '9']
16:52:02-INFO: ***** Running evaluation *****
16:52:02-INFO:   Num examples = 408
16:52:02-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.88it/s]
16:52:09-INFO: ***** Eval results *****
16:52:09-INFO:   F-1 score = 0.8993055555555555
16:52:09-INFO:   eval_accuracy = 0.8578431372549019
16:52:09-INFO:   eval_loss = 0.3615675259094972
16:52:09-INFO:   global_step = 0
16:52:09-INFO:   inference_time = 6.890144348144531
16:52:09-INFO:   loss = None
attention_head_mask ['2:10']
['2', '10']
16:52:09-INFO: ***** Running evaluation *****
16:52:09-INFO:   Num examples = 408
16:52:09-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.87it/s]
16:52:16-INFO: ***** Eval results *****
16:52:16-INFO:   F-1 score = 0.9012131715771231
16:52:16-INFO:   eval_accuracy = 0.8602941176470589
16:52:16-INFO:   eval_loss = 0.3713795726115887
16:52:16-INFO:   global_step = 0
16:52:16-INFO:   inference_time = 6.929617643356323
16:52:16-INFO:   loss = None
attention_head_mask ['2:11']
['2', '11']
16:52:16-INFO: ***** Running evaluation *****
16:52:16-INFO:   Num examples = 408
16:52:16-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.86it/s]
16:52:23-INFO: ***** Eval results *****
16:52:23-INFO:   F-1 score = 0.902229845626072
16:52:23-INFO:   eval_accuracy = 0.8602941176470589
16:52:23-INFO:   eval_loss = 0.3842671330158527
16:52:23-INFO:   global_step = 0
16:52:23-INFO:   inference_time = 6.988442420959473
16:52:23-INFO:   loss = None
attention_head_mask ['2:12']
['2', '12']
16:52:23-INFO: ***** Running evaluation *****
16:52:23-INFO:   Num examples = 408
16:52:23-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.85it/s]
16:52:30-INFO: ***** Eval results *****
16:52:30-INFO:   F-1 score = 0.8943894389438943
16:52:30-INFO:   eval_accuracy = 0.8431372549019608
16:52:30-INFO:   eval_loss = 0.4522557304455684
16:52:30-INFO:   global_step = 0
16:52:30-INFO:   inference_time = 7.018508195877075
16:52:30-INFO:   loss = None
attention_head_mask ['3:1']
['3', '1']
16:52:30-INFO: ***** Running evaluation *****
16:52:30-INFO:   Num examples = 408
16:52:30-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.84it/s]
16:52:37-INFO: ***** Eval results *****
16:52:37-INFO:   F-1 score = 0.8948247078464107
16:52:37-INFO:   eval_accuracy = 0.8455882352941176
16:52:37-INFO:   eval_loss = 0.43787943055996525
16:52:37-INFO:   global_step = 0
16:52:37-INFO:   inference_time = 7.051594018936157
16:52:37-INFO:   loss = None
attention_head_mask ['3:2']
['3', '2']
16:52:37-INFO: ***** Running evaluation *****
16:52:37-INFO:   Num examples = 408
16:52:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.83it/s]
16:52:44-INFO: ***** Eval results *****
16:52:44-INFO:   F-1 score = 0.8947368421052632
16:52:44-INFO:   eval_accuracy = 0.8431372549019608
16:52:44-INFO:   eval_loss = 0.46873769278709704
16:52:44-INFO:   global_step = 0
16:52:44-INFO:   inference_time = 7.08445405960083
16:52:44-INFO:   loss = None
attention_head_mask ['3:3']
['3', '3']
16:52:44-INFO: ***** Running evaluation *****
16:52:44-INFO:   Num examples = 408
16:52:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:06<00:00,  1.86it/s]
16:52:51-INFO: ***** Eval results *****
16:52:51-INFO:   F-1 score = 0.8936170212765958
16:52:51-INFO:   eval_accuracy = 0.8406862745098039
16:52:51-INFO:   eval_loss = 0.46784242873008436
16:52:51-INFO:   global_step = 0
16:52:51-INFO:   inference_time = 6.98387885093689
16:52:51-INFO:   loss = None
attention_head_mask ['3:4']
['3', '4']
16:52:51-INFO: ***** Running evaluation *****
16:52:51-INFO:   Num examples = 408
16:52:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.85it/s]
16:52:58-INFO: ***** Eval results *****
16:52:58-INFO:   F-1 score = 0.8943894389438943
16:52:58-INFO:   eval_accuracy = 0.8431372549019608
16:52:58-INFO:   eval_loss = 0.4651515529705928
16:52:58-INFO:   global_step = 0
16:52:58-INFO:   inference_time = 7.0083794593811035
16:52:58-INFO:   loss = None
attention_head_mask ['3:5']
['3', '5']
16:52:58-INFO: ***** Running evaluation *****
16:52:58-INFO:   Num examples = 408
16:52:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.84it/s]
16:53:05-INFO: ***** Eval results *****
16:53:05-INFO:   F-1 score = 0.8955223880597015
16:53:05-INFO:   eval_accuracy = 0.8455882352941176
16:53:05-INFO:   eval_loss = 0.44896613634549654
16:53:05-INFO:   global_step = 0
16:53:05-INFO:   inference_time = 7.040524244308472
16:53:05-INFO:   loss = None
attention_head_mask ['3:6']
['3', '6']
16:53:05-INFO: ***** Running evaluation *****
16:53:05-INFO:   Num examples = 408
16:53:05-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.84it/s]
16:53:12-INFO: ***** Eval results *****
16:53:12-INFO:   F-1 score = 0.8929159802306424
16:53:12-INFO:   eval_accuracy = 0.8406862745098039
16:53:12-INFO:   eval_loss = 0.45923106143107784
16:53:12-INFO:   global_step = 0
16:53:12-INFO:   inference_time = 7.0621654987335205
16:53:12-INFO:   loss = None
attention_head_mask ['3:7']
['3', '7']
16:53:12-INFO: ***** Running evaluation *****
16:53:12-INFO:   Num examples = 408
16:53:12-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.83it/s]
16:53:19-INFO: ***** Eval results *****
16:53:19-INFO:   F-1 score = 0.8544891640866873
16:53:19-INFO:   eval_accuracy = 0.7696078431372549
16:53:19-INFO:   eval_loss = 0.8058819151841677
16:53:19-INFO:   global_step = 0
16:53:19-INFO:   inference_time = 7.083157300949097
16:53:19-INFO:   loss = None
attention_head_mask ['3:8']
['3', '8']
16:53:19-INFO: ***** Running evaluation *****
16:53:19-INFO:   Num examples = 408
16:53:19-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.83it/s]
16:53:26-INFO: ***** Eval results *****
16:53:26-INFO:   F-1 score = 0.8940397350993377
16:53:26-INFO:   eval_accuracy = 0.8431372549019608
16:53:26-INFO:   eval_loss = 0.4441576600074768
16:53:26-INFO:   global_step = 0
16:53:26-INFO:   inference_time = 7.083627462387085
16:53:26-INFO:   loss = None
attention_head_mask ['3:9']
['3', '9']
16:53:26-INFO: ***** Running evaluation *****
16:53:26-INFO:   Num examples = 408
16:53:26-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.82it/s]
16:53:33-INFO: ***** Eval results *****
16:53:33-INFO:   F-1 score = 0.8914473684210527
16:53:33-INFO:   eval_accuracy = 0.8382352941176471
16:53:33-INFO:   eval_loss = 0.45299151654426867
16:53:33-INFO:   global_step = 0
16:53:33-INFO:   inference_time = 7.119739294052124
16:53:33-INFO:   loss = None
attention_head_mask ['3:10']
['3', '10']
16:53:33-INFO: ***** Running evaluation *****
16:53:33-INFO:   Num examples = 408
16:53:33-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.82it/s]
16:53:41-INFO: ***** Eval results *****
16:53:41-INFO:   F-1 score = 0.8991735537190082
16:53:41-INFO:   eval_accuracy = 0.8504901960784313
16:53:41-INFO:   eval_loss = 0.436993359373166
16:53:41-INFO:   global_step = 0
16:53:41-INFO:   inference_time = 7.133899211883545
16:53:41-INFO:   loss = None
attention_head_mask ['3:11']
['3', '11']
16:53:41-INFO: ***** Running evaluation *****
16:53:41-INFO:   Num examples = 408
16:53:41-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.82it/s]
16:53:48-INFO: ***** Eval results *****
16:53:48-INFO:   F-1 score = 0.8866995073891626
16:53:48-INFO:   eval_accuracy = 0.8308823529411765
16:53:48-INFO:   eval_loss = 0.4776175113824698
16:53:48-INFO:   global_step = 0
16:53:48-INFO:   inference_time = 7.149272918701172
16:53:48-INFO:   loss = None
attention_head_mask ['3:12']
['3', '12']
16:53:48-INFO: ***** Running evaluation *****
16:53:48-INFO:   Num examples = 408
16:53:48-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.81it/s]
16:53:55-INFO: ***** Eval results *****
16:53:55-INFO:   F-1 score = 0.8926174496644296
16:53:55-INFO:   eval_accuracy = 0.8431372549019608
16:53:55-INFO:   eval_loss = 0.39741169947844285
16:53:55-INFO:   global_step = 0
16:53:55-INFO:   inference_time = 7.17105770111084
16:53:55-INFO:   loss = None
attention_head_mask ['4:1']
['4', '1']
16:53:55-INFO: ***** Running evaluation *****
16:53:55-INFO:   Num examples = 408
16:53:55-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.81it/s]
16:54:02-INFO: ***** Eval results *****
16:54:02-INFO:   F-1 score = 0.8810289389067525
16:54:02-INFO:   eval_accuracy = 0.8186274509803921
16:54:02-INFO:   eval_loss = 0.5640691220760345
16:54:02-INFO:   global_step = 0
16:54:02-INFO:   inference_time = 7.1815125942230225
16:54:02-INFO:   loss = None
attention_head_mask ['4:2']
['4', '2']
16:54:02-INFO: ***** Running evaluation *****
16:54:02-INFO:   Num examples = 408
16:54:02-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.80it/s]
16:54:09-INFO: ***** Eval results *****
16:54:09-INFO:   F-1 score = 0.8903878583473862
16:54:09-INFO:   eval_accuracy = 0.8406862745098039
16:54:09-INFO:   eval_loss = 0.39596531138970303
16:54:09-INFO:   global_step = 0
16:54:09-INFO:   inference_time = 7.198745250701904
16:54:09-INFO:   loss = None
attention_head_mask ['4:3']
['4', '3']
16:54:09-INFO: ***** Running evaluation *****
16:54:09-INFO:   Num examples = 408
16:54:09-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.79it/s]
16:54:17-INFO: ***** Eval results *****
16:54:17-INFO:   F-1 score = 0.8941176470588236
16:54:17-INFO:   eval_accuracy = 0.8455882352941176
16:54:17-INFO:   eval_loss = 0.39608333431757414
16:54:17-INFO:   global_step = 0
16:54:17-INFO:   inference_time = 7.232359886169434
16:54:17-INFO:   loss = None
attention_head_mask ['4:4']
['4', '4']
16:54:17-INFO: ***** Running evaluation *****
16:54:17-INFO:   Num examples = 408
16:54:17-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.79it/s]
16:54:24-INFO: ***** Eval results *****
16:54:24-INFO:   F-1 score = 0.8903878583473862
16:54:24-INFO:   eval_accuracy = 0.8406862745098039
16:54:24-INFO:   eval_loss = 0.3969461929339629
16:54:24-INFO:   global_step = 0
16:54:24-INFO:   inference_time = 7.256241798400879
16:54:24-INFO:   loss = None
attention_head_mask ['4:5']
['4', '5']
16:54:24-INFO: ***** Running evaluation *****
16:54:24-INFO:   Num examples = 408
16:54:24-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.79it/s]
16:54:31-INFO: ***** Eval results *****
16:54:31-INFO:   F-1 score = 0.8941176470588236
16:54:31-INFO:   eval_accuracy = 0.8455882352941176
16:54:31-INFO:   eval_loss = 0.3953648473207767
16:54:31-INFO:   global_step = 0
16:54:31-INFO:   inference_time = 7.249175786972046
16:54:31-INFO:   loss = None
attention_head_mask ['4:6']
['4', '6']
16:54:31-INFO: ***** Running evaluation *****
16:54:31-INFO:   Num examples = 408
16:54:31-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.78it/s]
16:54:38-INFO: ***** Eval results *****
16:54:38-INFO:   F-1 score = 0.9008403361344538
16:54:38-INFO:   eval_accuracy = 0.8553921568627451
16:54:38-INFO:   eval_loss = 0.3951029066856091
16:54:38-INFO:   global_step = 0
16:54:38-INFO:   inference_time = 7.2820751667022705
16:54:38-INFO:   loss = None
attention_head_mask ['4:7']
['4', '7']
16:54:38-INFO: ***** Running evaluation *****
16:54:38-INFO:   Num examples = 408
16:54:38-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.78it/s]
16:54:46-INFO: ***** Eval results *****
16:54:46-INFO:   F-1 score = 0.8981636060100167
16:54:46-INFO:   eval_accuracy = 0.8504901960784313
16:54:46-INFO:   eval_loss = 0.40617106740291303
16:54:46-INFO:   global_step = 0
16:54:46-INFO:   inference_time = 7.293552875518799
16:54:46-INFO:   loss = None
attention_head_mask ['4:8']
['4', '8']
16:54:46-INFO: ***** Running evaluation *****
16:54:46-INFO:   Num examples = 408
16:54:46-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.77it/s]
16:54:53-INFO: ***** Eval results *****
16:54:53-INFO:   F-1 score = 0.8922056384742951
16:54:53-INFO:   eval_accuracy = 0.8406862745098039
16:54:53-INFO:   eval_loss = 0.43004360565772426
16:54:53-INFO:   global_step = 0
16:54:53-INFO:   inference_time = 7.3141069412231445
16:54:53-INFO:   loss = None
attention_head_mask ['4:9']
['4', '9']
16:54:53-INFO: ***** Running evaluation *****
16:54:53-INFO:   Num examples = 408
16:54:53-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.77it/s]
16:55:00-INFO: ***** Eval results *****
16:55:00-INFO:   F-1 score = 0.8951747088186357
16:55:00-INFO:   eval_accuracy = 0.8455882352941176
16:55:00-INFO:   eval_loss = 0.39901771339086384
16:55:00-INFO:   global_step = 0
16:55:00-INFO:   inference_time = 7.324550628662109
16:55:00-INFO:   loss = None
attention_head_mask ['4:10']
['4', '10']
16:55:00-INFO: ***** Running evaluation *****
16:55:00-INFO:   Num examples = 408
16:55:00-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.77it/s]
16:55:08-INFO: ***** Eval results *****
16:55:08-INFO:   F-1 score = 0.8948247078464107
16:55:08-INFO:   eval_accuracy = 0.8455882352941176
16:55:08-INFO:   eval_loss = 0.4091800485665982
16:55:08-INFO:   global_step = 0
16:55:08-INFO:   inference_time = 7.332191705703735
16:55:08-INFO:   loss = None
attention_head_mask ['4:11']
['4', '11']
16:55:08-INFO: ***** Running evaluation *****
16:55:08-INFO:   Num examples = 408
16:55:08-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.77it/s]
16:55:15-INFO: ***** Eval results *****
16:55:15-INFO:   F-1 score = 0.8996539792387542
16:55:15-INFO:   eval_accuracy = 0.8578431372549019
16:55:15-INFO:   eval_loss = 0.3712943574556938
16:55:15-INFO:   global_step = 0
16:55:15-INFO:   inference_time = 7.346689939498901
16:55:15-INFO:   loss = None
attention_head_mask ['4:12']
['4', '12']
16:55:15-INFO: ***** Running evaluation *****
16:55:15-INFO:   Num examples = 408
16:55:15-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.76it/s]
16:55:23-INFO: ***** Eval results *****
16:55:23-INFO:   F-1 score = 0.8926174496644296
16:55:23-INFO:   eval_accuracy = 0.8431372549019608
16:55:23-INFO:   eval_loss = 0.4010521196402036
16:55:23-INFO:   global_step = 0
16:55:23-INFO:   inference_time = 7.369832515716553
16:55:23-INFO:   loss = None
attention_head_mask ['5:1']
['5', '1']
16:55:23-INFO: ***** Running evaluation *****
16:55:23-INFO:   Num examples = 408
16:55:23-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.76it/s]
16:55:30-INFO: ***** Eval results *****
16:55:30-INFO:   F-1 score = 0.8892617449664431
16:55:30-INFO:   eval_accuracy = 0.8382352941176471
16:55:30-INFO:   eval_loss = 0.40372625107948595
16:55:30-INFO:   global_step = 0
16:55:30-INFO:   inference_time = 7.386814832687378
16:55:30-INFO:   loss = None
attention_head_mask ['5:2']
['5', '2']
16:55:30-INFO: ***** Running evaluation *****
16:55:30-INFO:   Num examples = 408
16:55:30-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.75it/s]
16:55:37-INFO: ***** Eval results *****
16:55:37-INFO:   F-1 score = 0.8926174496644296
16:55:37-INFO:   eval_accuracy = 0.8431372549019608
16:55:37-INFO:   eval_loss = 0.40853646053717685
16:55:37-INFO:   global_step = 0
16:55:37-INFO:   inference_time = 7.395582914352417
16:55:37-INFO:   loss = None
attention_head_mask ['5:3']
['5', '3']
16:55:37-INFO: ***** Running evaluation *****
16:55:37-INFO:   Num examples = 408
16:55:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.75it/s]
16:55:45-INFO: ***** Eval results *****
16:55:45-INFO:   F-1 score = 0.891846921797005
16:55:45-INFO:   eval_accuracy = 0.8406862745098039
16:55:45-INFO:   eval_loss = 0.4255568579985545
16:55:45-INFO:   global_step = 0
16:55:45-INFO:   inference_time = 7.416041851043701
16:55:45-INFO:   loss = None
attention_head_mask ['5:4']
['5', '4']
16:55:45-INFO: ***** Running evaluation *****
16:55:45-INFO:   Num examples = 408
16:55:45-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.75it/s]
16:55:52-INFO: ***** Eval results *****
16:55:52-INFO:   F-1 score = 0.8823529411764706
16:55:52-INFO:   eval_accuracy = 0.8333333333333334
16:55:52-INFO:   eval_loss = 0.389992519066884
16:55:52-INFO:   global_step = 0
16:55:52-INFO:   inference_time = 7.424485445022583
16:55:52-INFO:   loss = None
attention_head_mask ['5:5']
['5', '5']
16:55:52-INFO: ***** Running evaluation *****
16:55:52-INFO:   Num examples = 408
16:55:52-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.75it/s]
16:56:00-INFO: ***** Eval results *****
16:56:00-INFO:   F-1 score = 0.8929765886287626
16:56:00-INFO:   eval_accuracy = 0.8431372549019608
16:56:00-INFO:   eval_loss = 0.4054115999203462
16:56:00-INFO:   global_step = 0
16:56:00-INFO:   inference_time = 7.4353110790252686
16:56:00-INFO:   loss = None
attention_head_mask ['5:6']
['5', '6']
16:56:00-INFO: ***** Running evaluation *****
16:56:00-INFO:   Num examples = 408
16:56:00-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:07-INFO: ***** Eval results *****
16:56:07-INFO:   F-1 score = 0.8922558922558923
16:56:07-INFO:   eval_accuracy = 0.8431372549019608
16:56:07-INFO:   eval_loss = 0.40020764561799854
16:56:07-INFO:   global_step = 0
16:56:07-INFO:   inference_time = 7.455032110214233
16:56:07-INFO:   loss = None
attention_head_mask ['5:7']
['5', '7']
16:56:07-INFO: ***** Running evaluation *****
16:56:07-INFO:   Num examples = 408
16:56:07-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:15-INFO: ***** Eval results *****
16:56:15-INFO:   F-1 score = 0.8956228956228957
16:56:15-INFO:   eval_accuracy = 0.8480392156862745
16:56:15-INFO:   eval_loss = 0.40013718605041504
16:56:15-INFO:   global_step = 0
16:56:15-INFO:   inference_time = 7.463508367538452
16:56:15-INFO:   loss = None
attention_head_mask ['5:8']
['5', '8']
16:56:15-INFO: ***** Running evaluation *****
16:56:15-INFO:   Num examples = 408
16:56:15-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:22-INFO: ***** Eval results *****
16:56:22-INFO:   F-1 score = 0.8911222780569515
16:56:22-INFO:   eval_accuracy = 0.8406862745098039
16:56:22-INFO:   eval_loss = 0.4083563811503924
16:56:22-INFO:   global_step = 0
16:56:22-INFO:   inference_time = 7.454270362854004
16:56:22-INFO:   loss = None
attention_head_mask ['5:9']
['5', '9']
16:56:22-INFO: ***** Running evaluation *****
16:56:22-INFO:   Num examples = 408
16:56:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:30-INFO: ***** Eval results *****
16:56:30-INFO:   F-1 score = 0.8907563025210083
16:56:30-INFO:   eval_accuracy = 0.8406862745098039
16:56:30-INFO:   eval_loss = 0.4020441552767387
16:56:30-INFO:   global_step = 0
16:56:30-INFO:   inference_time = 7.468632936477661
16:56:30-INFO:   loss = None
attention_head_mask ['5:10']
['5', '10']
16:56:30-INFO: ***** Running evaluation *****
16:56:30-INFO:   Num examples = 408
16:56:30-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:37-INFO: ***** Eval results *****
16:56:37-INFO:   F-1 score = 0.8896321070234114
16:56:37-INFO:   eval_accuracy = 0.8382352941176471
16:56:37-INFO:   eval_loss = 0.4096017766457338
16:56:37-INFO:   global_step = 0
16:56:37-INFO:   inference_time = 7.4589784145355225
16:56:37-INFO:   loss = None
attention_head_mask ['5:11']
['5', '11']
16:56:37-INFO: ***** Running evaluation *****
16:56:37-INFO:   Num examples = 408
16:56:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:45-INFO: ***** Eval results *****
16:56:45-INFO:   F-1 score = 0.8956228956228957
16:56:45-INFO:   eval_accuracy = 0.8480392156862745
16:56:45-INFO:   eval_loss = 0.40096965432167053
16:56:45-INFO:   global_step = 0
16:56:45-INFO:   inference_time = 7.475170850753784
16:56:45-INFO:   loss = None
attention_head_mask ['5:12']
['5', '12']
16:56:45-INFO: ***** Running evaluation *****
16:56:45-INFO:   Num examples = 408
16:56:45-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:56:52-INFO: ***** Eval results *****
16:56:52-INFO:   F-1 score = 0.8926174496644296
16:56:52-INFO:   eval_accuracy = 0.8431372549019608
16:56:52-INFO:   eval_loss = 0.4066490622667166
16:56:52-INFO:   global_step = 0
16:56:52-INFO:   inference_time = 7.449263572692871
16:56:52-INFO:   loss = None
attention_head_mask ['6:1']
['6', '1']
16:56:52-INFO: ***** Running evaluation *****
16:56:52-INFO:   Num examples = 408
16:56:52-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:00-INFO: ***** Eval results *****
16:57:00-INFO:   F-1 score = 0.902027027027027
16:57:00-INFO:   eval_accuracy = 0.8578431372549019
16:57:00-INFO:   eval_loss = 0.40970216347621036
16:57:00-INFO:   global_step = 0
16:57:00-INFO:   inference_time = 7.454784870147705
16:57:00-INFO:   loss = None
attention_head_mask ['6:2']
['6', '2']
16:57:00-INFO: ***** Running evaluation *****
16:57:00-INFO:   Num examples = 408
16:57:00-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:07-INFO: ***** Eval results *****
16:57:07-INFO:   F-1 score = 0.8941176470588236
16:57:07-INFO:   eval_accuracy = 0.8455882352941176
16:57:07-INFO:   eval_loss = 0.4070243617663017
16:57:07-INFO:   global_step = 0
16:57:07-INFO:   inference_time = 7.471742391586304
16:57:07-INFO:   loss = None
attention_head_mask ['6:3']
['6', '3']
16:57:07-INFO: ***** Running evaluation *****
16:57:07-INFO:   Num examples = 408
16:57:07-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:15-INFO: ***** Eval results *****
16:57:15-INFO:   F-1 score = 0.8911222780569515
16:57:15-INFO:   eval_accuracy = 0.8406862745098039
16:57:15-INFO:   eval_loss = 0.41086684282009417
16:57:15-INFO:   global_step = 0
16:57:15-INFO:   inference_time = 7.467170000076294
16:57:15-INFO:   loss = None
attention_head_mask ['6:4']
['6', '4']
16:57:15-INFO: ***** Running evaluation *****
16:57:15-INFO:   Num examples = 408
16:57:15-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:22-INFO: ***** Eval results *****
16:57:22-INFO:   F-1 score = 0.8911222780569515
16:57:22-INFO:   eval_accuracy = 0.8406862745098039
16:57:22-INFO:   eval_loss = 0.4083003057883336
16:57:22-INFO:   global_step = 0
16:57:22-INFO:   inference_time = 7.471465349197388
16:57:22-INFO:   loss = None
attention_head_mask ['6:5']
['6', '5']
16:57:22-INFO: ***** Running evaluation *****
16:57:22-INFO:   Num examples = 408
16:57:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:29-INFO: ***** Eval results *****
16:57:29-INFO:   F-1 score = 0.89
16:57:29-INFO:   eval_accuracy = 0.8382352941176471
16:57:29-INFO:   eval_loss = 0.4280341405134935
16:57:29-INFO:   global_step = 0
16:57:29-INFO:   inference_time = 7.464793682098389
16:57:29-INFO:   loss = None
attention_head_mask ['6:6']
['6', '6']
16:57:29-INFO: ***** Running evaluation *****
16:57:29-INFO:   Num examples = 408
16:57:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:37-INFO: ***** Eval results *****
16:57:37-INFO:   F-1 score = 0.8911222780569515
16:57:37-INFO:   eval_accuracy = 0.8406862745098039
16:57:37-INFO:   eval_loss = 0.4109964049779452
16:57:37-INFO:   global_step = 0
16:57:37-INFO:   inference_time = 7.455461740493774
16:57:37-INFO:   loss = None
attention_head_mask ['6:7']
['6', '7']
16:57:37-INFO: ***** Running evaluation *****
16:57:37-INFO:   Num examples = 408
16:57:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.73it/s]
16:57:44-INFO: ***** Eval results *****
16:57:44-INFO:   F-1 score = 0.8911222780569515
16:57:44-INFO:   eval_accuracy = 0.8406862745098039
16:57:44-INFO:   eval_loss = 0.4046875421817486
16:57:44-INFO:   global_step = 0
16:57:44-INFO:   inference_time = 7.4808220863342285
16:57:44-INFO:   loss = None
attention_head_mask ['6:8']
['6', '8']
16:57:44-INFO: ***** Running evaluation *****
16:57:44-INFO:   Num examples = 408
16:57:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:52-INFO: ***** Eval results *****
16:57:52-INFO:   F-1 score = 0.8911222780569515
16:57:52-INFO:   eval_accuracy = 0.8406862745098039
16:57:52-INFO:   eval_loss = 0.41068978722278887
16:57:52-INFO:   global_step = 0
16:57:52-INFO:   inference_time = 7.461524486541748
16:57:52-INFO:   loss = None
attention_head_mask ['6:9']
['6', '9']
16:57:52-INFO: ***** Running evaluation *****
16:57:52-INFO:   Num examples = 408
16:57:52-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:57:59-INFO: ***** Eval results *****
16:57:59-INFO:   F-1 score = 0.8904593639575972
16:57:59-INFO:   eval_accuracy = 0.8480392156862745
16:57:59-INFO:   eval_loss = 0.3784128393118198
16:57:59-INFO:   global_step = 0
16:57:59-INFO:   inference_time = 7.469922065734863
16:57:59-INFO:   loss = None
attention_head_mask ['6:10']
['6', '10']
16:57:59-INFO: ***** Running evaluation *****
16:57:59-INFO:   Num examples = 408
16:57:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:07-INFO: ***** Eval results *****
16:58:07-INFO:   F-1 score = 0.895973154362416
16:58:07-INFO:   eval_accuracy = 0.8480392156862745
16:58:07-INFO:   eval_loss = 0.41179536626889157
16:58:07-INFO:   global_step = 0
16:58:07-INFO:   inference_time = 7.4629034996032715
16:58:07-INFO:   loss = None
attention_head_mask ['6:11']
['6', '11']
16:58:07-INFO: ***** Running evaluation *****
16:58:07-INFO:   Num examples = 408
16:58:07-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:14-INFO: ***** Eval results *****
16:58:14-INFO:   F-1 score = 0.8892617449664431
16:58:14-INFO:   eval_accuracy = 0.8382352941176471
16:58:14-INFO:   eval_loss = 0.40108049603608936
16:58:14-INFO:   global_step = 0
16:58:14-INFO:   inference_time = 7.454274654388428
16:58:14-INFO:   loss = None
attention_head_mask ['6:12']
['6', '12']
16:58:14-INFO: ***** Running evaluation *****
16:58:14-INFO:   Num examples = 408
16:58:14-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:22-INFO: ***** Eval results *****
16:58:22-INFO:   F-1 score = 0.8881469115191986
16:58:22-INFO:   eval_accuracy = 0.8357843137254902
16:58:22-INFO:   eval_loss = 0.41021141982995546
16:58:22-INFO:   global_step = 0
16:58:22-INFO:   inference_time = 7.465967893600464
16:58:22-INFO:   loss = None
attention_head_mask ['7:1']
['7', '1']
16:58:22-INFO: ***** Running evaluation *****
16:58:22-INFO:   Num examples = 408
16:58:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:29-INFO: ***** Eval results *****
16:58:29-INFO:   F-1 score = 0.8922558922558923
16:58:29-INFO:   eval_accuracy = 0.8431372549019608
16:58:29-INFO:   eval_loss = 0.3983493550465657
16:58:29-INFO:   global_step = 0
16:58:29-INFO:   inference_time = 7.462316989898682
16:58:29-INFO:   loss = None
attention_head_mask ['7:2']
['7', '2']
16:58:29-INFO: ***** Running evaluation *****
16:58:29-INFO:   Num examples = 408
16:58:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:37-INFO: ***** Eval results *****
16:58:37-INFO:   F-1 score = 0.8952702702702703
16:58:37-INFO:   eval_accuracy = 0.8480392156862745
16:58:37-INFO:   eval_loss = 0.40302380002461946
16:58:37-INFO:   global_step = 0
16:58:37-INFO:   inference_time = 7.468479633331299
16:58:37-INFO:   loss = None
attention_head_mask ['7:3']
['7', '3']
16:58:37-INFO: ***** Running evaluation *****
16:58:37-INFO:   Num examples = 408
16:58:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:44-INFO: ***** Eval results *****
16:58:44-INFO:   F-1 score = 0.8866666666666667
16:58:44-INFO:   eval_accuracy = 0.8333333333333334
16:58:44-INFO:   eval_loss = 0.4182684054741493
16:58:44-INFO:   global_step = 0
16:58:44-INFO:   inference_time = 7.466647148132324
16:58:44-INFO:   loss = None
attention_head_mask ['7:4']
['7', '4']
16:58:44-INFO: ***** Running evaluation *****
16:58:44-INFO:   Num examples = 408
16:58:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:58:52-INFO: ***** Eval results *****
16:58:52-INFO:   F-1 score = 0.8866666666666667
16:58:52-INFO:   eval_accuracy = 0.8333333333333334
16:58:52-INFO:   eval_loss = 0.4116125267285567
16:58:52-INFO:   global_step = 0
16:58:52-INFO:   inference_time = 7.465958833694458
16:58:52-INFO:   loss = None
attention_head_mask ['7:5']
['7', '5']
16:58:52-INFO: ***** Running evaluation *****
16:58:52-INFO:   Num examples = 408
16:58:52-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.73it/s]
16:58:59-INFO: ***** Eval results *****
16:58:59-INFO:   F-1 score = 0.891846921797005
16:58:59-INFO:   eval_accuracy = 0.8406862745098039
16:58:59-INFO:   eval_loss = 0.41074236654318297
16:58:59-INFO:   global_step = 0
16:58:59-INFO:   inference_time = 7.481914043426514
16:58:59-INFO:   loss = None
attention_head_mask ['7:6']
['7', '6']
16:58:59-INFO: ***** Running evaluation *****
16:58:59-INFO:   Num examples = 408
16:58:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:07-INFO: ***** Eval results *****
16:59:07-INFO:   F-1 score = 0.8896321070234114
16:59:07-INFO:   eval_accuracy = 0.8382352941176471
16:59:07-INFO:   eval_loss = 0.411605288202946
16:59:07-INFO:   global_step = 0
16:59:07-INFO:   inference_time = 7.467381954193115
16:59:07-INFO:   loss = None
attention_head_mask ['7:7']
['7', '7']
16:59:07-INFO: ***** Running evaluation *****
16:59:07-INFO:   Num examples = 408
16:59:07-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:14-INFO: ***** Eval results *****
16:59:14-INFO:   F-1 score = 0.8892617449664431
16:59:14-INFO:   eval_accuracy = 0.8382352941176471
16:59:14-INFO:   eval_loss = 0.40496429800987244
16:59:14-INFO:   global_step = 0
16:59:14-INFO:   inference_time = 7.466240167617798
16:59:14-INFO:   loss = None
attention_head_mask ['7:8']
['7', '8']
16:59:14-INFO: ***** Running evaluation *****
16:59:14-INFO:   Num examples = 408
16:59:14-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:22-INFO: ***** Eval results *****
16:59:22-INFO:   F-1 score = 0.8851913477537438
16:59:22-INFO:   eval_accuracy = 0.8308823529411765
16:59:22-INFO:   eval_loss = 0.41842763469769406
16:59:22-INFO:   global_step = 0
16:59:22-INFO:   inference_time = 7.462242603302002
16:59:22-INFO:   loss = None
attention_head_mask ['7:9']
['7', '9']
16:59:22-INFO: ***** Running evaluation *****
16:59:22-INFO:   Num examples = 408
16:59:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:29-INFO: ***** Eval results *****
16:59:29-INFO:   F-1 score = 0.8896321070234114
16:59:29-INFO:   eval_accuracy = 0.8382352941176471
16:59:29-INFO:   eval_loss = 0.40377918115028966
16:59:29-INFO:   global_step = 0
16:59:29-INFO:   inference_time = 7.458772420883179
16:59:29-INFO:   loss = None
attention_head_mask ['7:10']
['7', '10']
16:59:29-INFO: ***** Running evaluation *****
16:59:29-INFO:   Num examples = 408
16:59:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:37-INFO: ***** Eval results *****
16:59:37-INFO:   F-1 score = 0.8892617449664431
16:59:37-INFO:   eval_accuracy = 0.8382352941176471
16:59:37-INFO:   eval_loss = 0.40930200769351077
16:59:37-INFO:   global_step = 0
16:59:37-INFO:   inference_time = 7.448967456817627
16:59:37-INFO:   loss = None
attention_head_mask ['7:11']
['7', '11']
16:59:37-INFO: ***** Running evaluation *****
16:59:37-INFO:   Num examples = 408
16:59:37-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:44-INFO: ***** Eval results *****
16:59:44-INFO:   F-1 score = 0.8911222780569515
16:59:44-INFO:   eval_accuracy = 0.8406862745098039
16:59:44-INFO:   eval_loss = 0.4113424259882707
16:59:44-INFO:   global_step = 0
16:59:44-INFO:   inference_time = 7.448529005050659
16:59:44-INFO:   loss = None
attention_head_mask ['7:12']
['7', '12']
16:59:44-INFO: ***** Running evaluation *****
16:59:44-INFO:   Num examples = 408
16:59:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:52-INFO: ***** Eval results *****
16:59:52-INFO:   F-1 score = 0.8911222780569515
16:59:52-INFO:   eval_accuracy = 0.8406862745098039
16:59:52-INFO:   eval_loss = 0.40627253972567046
16:59:52-INFO:   global_step = 0
16:59:52-INFO:   inference_time = 7.459664344787598
16:59:52-INFO:   loss = None
attention_head_mask ['8:1']
['8', '1']
16:59:52-INFO: ***** Running evaluation *****
16:59:52-INFO:   Num examples = 408
16:59:52-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
16:59:59-INFO: ***** Eval results *****
16:59:59-INFO:   F-1 score = 0.8881469115191986
16:59:59-INFO:   eval_accuracy = 0.8357843137254902
16:59:59-INFO:   eval_loss = 0.40757411603744215
16:59:59-INFO:   global_step = 0
16:59:59-INFO:   inference_time = 7.453661680221558
16:59:59-INFO:   loss = None
attention_head_mask ['8:2']
['8', '2']
16:59:59-INFO: ***** Running evaluation *****
16:59:59-INFO:   Num examples = 408
16:59:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:07-INFO: ***** Eval results *****
17:00:07-INFO:   F-1 score = 0.8888888888888888
17:00:07-INFO:   eval_accuracy = 0.8382352941176471
17:00:07-INFO:   eval_loss = 0.40078540031726545
17:00:07-INFO:   global_step = 0
17:00:07-INFO:   inference_time = 7.4610817432403564
17:00:07-INFO:   loss = None
attention_head_mask ['8:3']
['8', '3']
17:00:07-INFO: ***** Running evaluation *****
17:00:07-INFO:   Num examples = 408
17:00:07-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:14-INFO: ***** Eval results *****
17:00:14-INFO:   F-1 score = 0.8888888888888888
17:00:14-INFO:   eval_accuracy = 0.8382352941176471
17:00:14-INFO:   eval_loss = 0.404904122535999
17:00:14-INFO:   global_step = 0
17:00:14-INFO:   inference_time = 7.463730335235596
17:00:14-INFO:   loss = None
attention_head_mask ['8:4']
['8', '4']
17:00:14-INFO: ***** Running evaluation *****
17:00:14-INFO:   Num examples = 408
17:00:14-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:22-INFO: ***** Eval results *****
17:00:22-INFO:   F-1 score = 0.8896321070234114
17:00:22-INFO:   eval_accuracy = 0.8382352941176471
17:00:22-INFO:   eval_loss = 0.40748370037629056
17:00:22-INFO:   global_step = 0
17:00:22-INFO:   inference_time = 7.454701662063599
17:00:22-INFO:   loss = None
attention_head_mask ['8:5']
['8', '5']
17:00:22-INFO: ***** Running evaluation *****
17:00:22-INFO:   Num examples = 408
17:00:22-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:29-INFO: ***** Eval results *****
17:00:29-INFO:   F-1 score = 0.8862876254180602
17:00:29-INFO:   eval_accuracy = 0.8333333333333334
17:00:29-INFO:   eval_loss = 0.41133350477768826
17:00:29-INFO:   global_step = 0
17:00:29-INFO:   inference_time = 7.451411962509155
17:00:29-INFO:   loss = None
attention_head_mask ['8:6']
['8', '6']
17:00:29-INFO: ***** Running evaluation *****
17:00:29-INFO:   Num examples = 408
17:00:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:36-INFO: ***** Eval results *****
17:00:36-INFO:   F-1 score = 0.8956228956228957
17:00:36-INFO:   eval_accuracy = 0.8480392156862745
17:00:36-INFO:   eval_loss = 0.3993884313565034
17:00:36-INFO:   global_step = 0
17:00:36-INFO:   inference_time = 7.457377195358276
17:00:36-INFO:   loss = None
attention_head_mask ['8:7']
['8', '7']
17:00:36-INFO: ***** Running evaluation *****
17:00:36-INFO:   Num examples = 408
17:00:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:44-INFO: ***** Eval results *****
17:00:44-INFO:   F-1 score = 0.8911222780569515
17:00:44-INFO:   eval_accuracy = 0.8406862745098039
17:00:44-INFO:   eval_loss = 0.4063950799978696
17:00:44-INFO:   global_step = 0
17:00:44-INFO:   inference_time = 7.460210800170898
17:00:44-INFO:   loss = None
attention_head_mask ['8:8']
['8', '8']
17:00:44-INFO: ***** Running evaluation *****
17:00:44-INFO:   Num examples = 408
17:00:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:51-INFO: ***** Eval results *****
17:00:51-INFO:   F-1 score = 0.8896321070234114
17:00:51-INFO:   eval_accuracy = 0.8382352941176471
17:00:51-INFO:   eval_loss = 0.4081048426719812
17:00:51-INFO:   global_step = 0
17:00:51-INFO:   inference_time = 7.454281568527222
17:00:51-INFO:   loss = None
attention_head_mask ['8:9']
['8', '9']
17:00:51-INFO: ***** Running evaluation *****
17:00:51-INFO:   Num examples = 408
17:00:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:00:59-INFO: ***** Eval results *****
17:00:59-INFO:   F-1 score = 0.8911222780569515
17:00:59-INFO:   eval_accuracy = 0.8406862745098039
17:00:59-INFO:   eval_loss = 0.4078265864115495
17:00:59-INFO:   global_step = 0
17:00:59-INFO:   inference_time = 7.445195913314819
17:00:59-INFO:   loss = None
attention_head_mask ['8:10']
['8', '10']
17:00:59-INFO: ***** Running evaluation *****
17:00:59-INFO:   Num examples = 408
17:00:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:06-INFO: ***** Eval results *****
17:01:06-INFO:   F-1 score = 0.8896321070234114
17:01:06-INFO:   eval_accuracy = 0.8382352941176471
17:01:06-INFO:   eval_loss = 0.40700597258714527
17:01:06-INFO:   global_step = 0
17:01:06-INFO:   inference_time = 7.442275524139404
17:01:06-INFO:   loss = None
attention_head_mask ['8:11']
['8', '11']
17:01:06-INFO: ***** Running evaluation *****
17:01:06-INFO:   Num examples = 408
17:01:06-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:14-INFO: ***** Eval results *****
17:01:14-INFO:   F-1 score = 0.8881469115191986
17:01:14-INFO:   eval_accuracy = 0.8357843137254902
17:01:14-INFO:   eval_loss = 0.40902151052768415
17:01:14-INFO:   global_step = 0
17:01:14-INFO:   inference_time = 7.46034049987793
17:01:14-INFO:   loss = None
attention_head_mask ['8:12']
['8', '12']
17:01:14-INFO: ***** Running evaluation *****
17:01:14-INFO:   Num examples = 408
17:01:14-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:21-INFO: ***** Eval results *****
17:01:21-INFO:   F-1 score = 0.8844221105527639
17:01:21-INFO:   eval_accuracy = 0.8308823529411765
17:01:21-INFO:   eval_loss = 0.40501659650069016
17:01:21-INFO:   global_step = 0
17:01:21-INFO:   inference_time = 7.451813459396362
17:01:21-INFO:   loss = None
attention_head_mask ['9:1']
['9', '1']
17:01:21-INFO: ***** Running evaluation *****
17:01:21-INFO:   Num examples = 408
17:01:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:29-INFO: ***** Eval results *****
17:01:29-INFO:   F-1 score = 0.8881469115191986
17:01:29-INFO:   eval_accuracy = 0.8357843137254902
17:01:29-INFO:   eval_loss = 0.4115541921212123
17:01:29-INFO:   global_step = 0
17:01:29-INFO:   inference_time = 7.450275421142578
17:01:29-INFO:   loss = None
attention_head_mask ['9:2']
['9', '2']
17:01:29-INFO: ***** Running evaluation *****
17:01:29-INFO:   Num examples = 408
17:01:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:36-INFO: ***** Eval results *****
17:01:36-INFO:   F-1 score = 0.8952702702702703
17:01:36-INFO:   eval_accuracy = 0.8480392156862745
17:01:36-INFO:   eval_loss = 0.4053825930907176
17:01:36-INFO:   global_step = 0
17:01:36-INFO:   inference_time = 7.452219486236572
17:01:36-INFO:   loss = None
attention_head_mask ['9:3']
['9', '3']
17:01:36-INFO: ***** Running evaluation *****
17:01:36-INFO:   Num examples = 408
17:01:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:44-INFO: ***** Eval results *****
17:01:44-INFO:   F-1 score = 0.8888888888888888
17:01:44-INFO:   eval_accuracy = 0.8382352941176471
17:01:44-INFO:   eval_loss = 0.39972146313924056
17:01:44-INFO:   global_step = 0
17:01:44-INFO:   inference_time = 7.456342697143555
17:01:44-INFO:   loss = None
attention_head_mask ['9:4']
['9', '4']
17:01:44-INFO: ***** Running evaluation *****
17:01:44-INFO:   Num examples = 408
17:01:44-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:51-INFO: ***** Eval results *****
17:01:51-INFO:   F-1 score = 0.8888888888888888
17:01:51-INFO:   eval_accuracy = 0.8382352941176471
17:01:51-INFO:   eval_loss = 0.4041993021965027
17:01:51-INFO:   global_step = 0
17:01:51-INFO:   inference_time = 7.462485313415527
17:01:51-INFO:   loss = None
attention_head_mask ['9:5']
['9', '5']
17:01:51-INFO: ***** Running evaluation *****
17:01:51-INFO:   Num examples = 408
17:01:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:01:59-INFO: ***** Eval results *****
17:01:59-INFO:   F-1 score = 0.8907563025210083
17:01:59-INFO:   eval_accuracy = 0.8406862745098039
17:01:59-INFO:   eval_loss = 0.4074158657055635
17:01:59-INFO:   global_step = 0
17:01:59-INFO:   inference_time = 7.448949575424194
17:01:59-INFO:   loss = None
attention_head_mask ['9:6']
['9', '6']
17:01:59-INFO: ***** Running evaluation *****
17:01:59-INFO:   Num examples = 408
17:01:59-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:06-INFO: ***** Eval results *****
17:02:06-INFO:   F-1 score = 0.8859060402684563
17:02:06-INFO:   eval_accuracy = 0.8333333333333334
17:02:06-INFO:   eval_loss = 0.40605912185632265
17:02:06-INFO:   global_step = 0
17:02:06-INFO:   inference_time = 7.439277172088623
17:02:06-INFO:   loss = None
attention_head_mask ['9:7']
['9', '7']
17:02:06-INFO: ***** Running evaluation *****
17:02:06-INFO:   Num examples = 408
17:02:06-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:14-INFO: ***** Eval results *****
17:02:14-INFO:   F-1 score = 0.8877721943048577
17:02:14-INFO:   eval_accuracy = 0.8357843137254902
17:02:14-INFO:   eval_loss = 0.4067857208160254
17:02:14-INFO:   global_step = 0
17:02:14-INFO:   inference_time = 7.45792031288147
17:02:14-INFO:   loss = None
attention_head_mask ['9:8']
['9', '8']
17:02:14-INFO: ***** Running evaluation *****
17:02:14-INFO:   Num examples = 408
17:02:14-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:21-INFO: ***** Eval results *****
17:02:21-INFO:   F-1 score = 0.893760539629005
17:02:21-INFO:   eval_accuracy = 0.8455882352941176
17:02:21-INFO:   eval_loss = 0.39427461532446056
17:02:21-INFO:   global_step = 0
17:02:21-INFO:   inference_time = 7.458654165267944
17:02:21-INFO:   loss = None
attention_head_mask ['9:9']
['9', '9']
17:02:21-INFO: ***** Running evaluation *****
17:02:21-INFO:   Num examples = 408
17:02:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:29-INFO: ***** Eval results *****
17:02:29-INFO:   F-1 score = 0.890728476821192
17:02:29-INFO:   eval_accuracy = 0.8382352941176471
17:02:29-INFO:   eval_loss = 0.4149378056709583
17:02:29-INFO:   global_step = 0
17:02:29-INFO:   inference_time = 7.467747449874878
17:02:29-INFO:   loss = None
attention_head_mask ['9:10']
['9', '10']
17:02:29-INFO: ***** Running evaluation *****
17:02:29-INFO:   Num examples = 408
17:02:29-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:36-INFO: ***** Eval results *****
17:02:36-INFO:   F-1 score = 0.8873949579831933
17:02:36-INFO:   eval_accuracy = 0.8357843137254902
17:02:36-INFO:   eval_loss = 0.40452158336456007
17:02:36-INFO:   global_step = 0
17:02:36-INFO:   inference_time = 7.450692176818848
17:02:36-INFO:   loss = None
attention_head_mask ['9:11']
['9', '11']
17:02:36-INFO: ***** Running evaluation *****
17:02:36-INFO:   Num examples = 408
17:02:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:43-INFO: ***** Eval results *****
17:02:43-INFO:   F-1 score = 0.8877721943048577
17:02:43-INFO:   eval_accuracy = 0.8357843137254902
17:02:43-INFO:   eval_loss = 0.40428030834748196
17:02:43-INFO:   global_step = 0
17:02:43-INFO:   inference_time = 7.455718994140625
17:02:43-INFO:   loss = None
attention_head_mask ['9:12']
['9', '12']
17:02:43-INFO: ***** Running evaluation *****
17:02:43-INFO:   Num examples = 408
17:02:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:51-INFO: ***** Eval results *****
17:02:51-INFO:   F-1 score = 0.8881469115191986
17:02:51-INFO:   eval_accuracy = 0.8357843137254902
17:02:51-INFO:   eval_loss = 0.40889080785788023
17:02:51-INFO:   global_step = 0
17:02:51-INFO:   inference_time = 7.45131254196167
17:02:51-INFO:   loss = None
attention_head_mask ['10:1']
['10', '1']
17:02:51-INFO: ***** Running evaluation *****
17:02:51-INFO:   Num examples = 408
17:02:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:02:58-INFO: ***** Eval results *****
17:02:58-INFO:   F-1 score = 0.8881469115191986
17:02:58-INFO:   eval_accuracy = 0.8357843137254902
17:02:58-INFO:   eval_loss = 0.4098083583208231
17:02:58-INFO:   global_step = 0
17:02:58-INFO:   inference_time = 7.451339244842529
17:02:58-INFO:   loss = None
attention_head_mask ['10:2']
['10', '2']
17:02:58-INFO: ***** Running evaluation *****
17:02:58-INFO:   Num examples = 408
17:02:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:06-INFO: ***** Eval results *****
17:03:06-INFO:   F-1 score = 0.8881469115191986
17:03:06-INFO:   eval_accuracy = 0.8357843137254902
17:03:06-INFO:   eval_loss = 0.40857253739467037
17:03:06-INFO:   global_step = 0
17:03:06-INFO:   inference_time = 7.457931756973267
17:03:06-INFO:   loss = None
attention_head_mask ['10:3']
['10', '3']
17:03:06-INFO: ***** Running evaluation *****
17:03:06-INFO:   Num examples = 408
17:03:06-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:13-INFO: ***** Eval results *****
17:03:13-INFO:   F-1 score = 0.8892617449664431
17:03:13-INFO:   eval_accuracy = 0.8382352941176471
17:03:13-INFO:   eval_loss = 0.398985899411715
17:03:13-INFO:   global_step = 0
17:03:13-INFO:   inference_time = 7.466426372528076
17:03:13-INFO:   loss = None
attention_head_mask ['10:4']
['10', '4']
17:03:13-INFO: ***** Running evaluation *****
17:03:13-INFO:   Num examples = 408
17:03:13-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:21-INFO: ***** Eval results *****
17:03:21-INFO:   F-1 score = 0.8881469115191986
17:03:21-INFO:   eval_accuracy = 0.8357843137254902
17:03:21-INFO:   eval_loss = 0.41271309554576874
17:03:21-INFO:   global_step = 0
17:03:21-INFO:   inference_time = 7.458253860473633
17:03:21-INFO:   loss = None
attention_head_mask ['10:5']
['10', '5']
17:03:21-INFO: ***** Running evaluation *****
17:03:21-INFO:   Num examples = 408
17:03:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:28-INFO: ***** Eval results *****
17:03:28-INFO:   F-1 score = 0.8881469115191986
17:03:28-INFO:   eval_accuracy = 0.8357843137254902
17:03:28-INFO:   eval_loss = 0.41366176077952754
17:03:28-INFO:   global_step = 0
17:03:28-INFO:   inference_time = 7.461497068405151
17:03:28-INFO:   loss = None
attention_head_mask ['10:6']
['10', '6']
17:03:28-INFO: ***** Running evaluation *****
17:03:28-INFO:   Num examples = 408
17:03:28-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:36-INFO: ***** Eval results *****
17:03:36-INFO:   F-1 score = 0.8930390492359932
17:03:36-INFO:   eval_accuracy = 0.8455882352941176
17:03:36-INFO:   eval_loss = 0.38723875696842486
17:03:36-INFO:   global_step = 0
17:03:36-INFO:   inference_time = 7.461439847946167
17:03:36-INFO:   loss = None
attention_head_mask ['10:7']
['10', '7']
17:03:36-INFO: ***** Running evaluation *****
17:03:36-INFO:   Num examples = 408
17:03:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:43-INFO: ***** Eval results *****
17:03:43-INFO:   F-1 score = 0.8881469115191986
17:03:43-INFO:   eval_accuracy = 0.8357843137254902
17:03:43-INFO:   eval_loss = 0.40876535039681655
17:03:43-INFO:   global_step = 0
17:03:43-INFO:   inference_time = 7.470152139663696
17:03:43-INFO:   loss = None
attention_head_mask ['10:8']
['10', '8']
17:03:43-INFO: ***** Running evaluation *****
17:03:43-INFO:   Num examples = 408
17:03:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:51-INFO: ***** Eval results *****
17:03:51-INFO:   F-1 score = 0.8881469115191986
17:03:51-INFO:   eval_accuracy = 0.8357843137254902
17:03:51-INFO:   eval_loss = 0.41457732824178845
17:03:51-INFO:   global_step = 0
17:03:51-INFO:   inference_time = 7.468860626220703
17:03:51-INFO:   loss = None
attention_head_mask ['10:9']
['10', '9']
17:03:51-INFO: ***** Running evaluation *****
17:03:51-INFO:   Num examples = 408
17:03:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:03:58-INFO: ***** Eval results *****
17:03:58-INFO:   F-1 score = 0.8881469115191986
17:03:58-INFO:   eval_accuracy = 0.8357843137254902
17:03:58-INFO:   eval_loss = 0.41135479968327743
17:03:58-INFO:   global_step = 0
17:03:58-INFO:   inference_time = 7.461071729660034
17:03:58-INFO:   loss = None
attention_head_mask ['10:10']
['10', '10']
17:03:58-INFO: ***** Running evaluation *****
17:03:58-INFO:   Num examples = 408
17:03:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:06-INFO: ***** Eval results *****
17:04:06-INFO:   F-1 score = 0.8881469115191986
17:04:06-INFO:   eval_accuracy = 0.8357843137254902
17:04:06-INFO:   eval_loss = 0.4128240461532886
17:04:06-INFO:   global_step = 0
17:04:06-INFO:   inference_time = 7.464878797531128
17:04:06-INFO:   loss = None
attention_head_mask ['10:11']
['10', '11']
17:04:06-INFO: ***** Running evaluation *****
17:04:06-INFO:   Num examples = 408
17:04:06-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:13-INFO: ***** Eval results *****
17:04:13-INFO:   F-1 score = 0.8862876254180602
17:04:13-INFO:   eval_accuracy = 0.8333333333333334
17:04:13-INFO:   eval_loss = 0.40824680832716137
17:04:13-INFO:   global_step = 0
17:04:13-INFO:   inference_time = 7.46794319152832
17:04:13-INFO:   loss = None
attention_head_mask ['10:12']
['10', '12']
17:04:13-INFO: ***** Running evaluation *****
17:04:13-INFO:   Num examples = 408
17:04:13-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:21-INFO: ***** Eval results *****
17:04:21-INFO:   F-1 score = 0.89
17:04:21-INFO:   eval_accuracy = 0.8382352941176471
17:04:21-INFO:   eval_loss = 0.4140990708882992
17:04:21-INFO:   global_step = 0
17:04:21-INFO:   inference_time = 7.449959993362427
17:04:21-INFO:   loss = None
attention_head_mask ['11:1']
['11', '1']
17:04:21-INFO: ***** Running evaluation *****
17:04:21-INFO:   Num examples = 408
17:04:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:28-INFO: ***** Eval results *****
17:04:28-INFO:   F-1 score = 0.89
17:04:28-INFO:   eval_accuracy = 0.8382352941176471
17:04:28-INFO:   eval_loss = 0.4110803008079529
17:04:28-INFO:   global_step = 0
17:04:28-INFO:   inference_time = 7.471030950546265
17:04:28-INFO:   loss = None
attention_head_mask ['11:2']
['11', '2']
17:04:28-INFO: ***** Running evaluation *****
17:04:28-INFO:   Num examples = 408
17:04:28-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:36-INFO: ***** Eval results *****
17:04:36-INFO:   F-1 score = 0.89
17:04:36-INFO:   eval_accuracy = 0.8382352941176471
17:04:36-INFO:   eval_loss = 0.41547318949149203
17:04:36-INFO:   global_step = 0
17:04:36-INFO:   inference_time = 7.469970464706421
17:04:36-INFO:   loss = None
attention_head_mask ['11:3']
['11', '3']
17:04:36-INFO: ***** Running evaluation *****
17:04:36-INFO:   Num examples = 408
17:04:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:43-INFO: ***** Eval results *****
17:04:43-INFO:   F-1 score = 0.8881469115191986
17:04:43-INFO:   eval_accuracy = 0.8357843137254902
17:04:43-INFO:   eval_loss = 0.41255392363438237
17:04:43-INFO:   global_step = 0
17:04:43-INFO:   inference_time = 7.4576263427734375
17:04:43-INFO:   loss = None
attention_head_mask ['11:4']
['11', '4']
17:04:43-INFO: ***** Running evaluation *****
17:04:43-INFO:   Num examples = 408
17:04:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:51-INFO: ***** Eval results *****
17:04:51-INFO:   F-1 score = 0.8881469115191986
17:04:51-INFO:   eval_accuracy = 0.8357843137254902
17:04:51-INFO:   eval_loss = 0.41100972776229566
17:04:51-INFO:   global_step = 0
17:04:51-INFO:   inference_time = 7.474099397659302
17:04:51-INFO:   loss = None
attention_head_mask ['11:5']
['11', '5']
17:04:51-INFO: ***** Running evaluation *****
17:04:51-INFO:   Num examples = 408
17:04:51-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:04:58-INFO: ***** Eval results *****
17:04:58-INFO:   F-1 score = 0.89
17:04:58-INFO:   eval_accuracy = 0.8382352941176471
17:04:58-INFO:   eval_loss = 0.41321993791140044
17:04:58-INFO:   global_step = 0
17:04:58-INFO:   inference_time = 7.457802057266235
17:04:58-INFO:   loss = None
attention_head_mask ['11:6']
['11', '6']
17:04:58-INFO: ***** Running evaluation *****
17:04:58-INFO:   Num examples = 408
17:04:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:06-INFO: ***** Eval results *****
17:05:06-INFO:   F-1 score = 0.8881469115191986
17:05:06-INFO:   eval_accuracy = 0.8357843137254902
17:05:06-INFO:   eval_loss = 0.41335667211275834
17:05:06-INFO:   global_step = 0
17:05:06-INFO:   inference_time = 7.452854633331299
17:05:06-INFO:   loss = None
attention_head_mask ['11:7']
['11', '7']
17:05:06-INFO: ***** Running evaluation *****
17:05:06-INFO:   Num examples = 408
17:05:06-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:13-INFO: ***** Eval results *****
17:05:13-INFO:   F-1 score = 0.89
17:05:13-INFO:   eval_accuracy = 0.8382352941176471
17:05:13-INFO:   eval_loss = 0.4138541737428078
17:05:13-INFO:   global_step = 0
17:05:13-INFO:   inference_time = 7.461626768112183
17:05:13-INFO:   loss = None
attention_head_mask ['11:8']
['11', '8']
17:05:13-INFO: ***** Running evaluation *****
17:05:13-INFO:   Num examples = 408
17:05:13-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:21-INFO: ***** Eval results *****
17:05:21-INFO:   F-1 score = 0.8859504132231406
17:05:21-INFO:   eval_accuracy = 0.8308823529411765
17:05:21-INFO:   eval_loss = 0.42801141853515917
17:05:21-INFO:   global_step = 0
17:05:21-INFO:   inference_time = 7.479613780975342
17:05:21-INFO:   loss = None
attention_head_mask ['11:9']
['11', '9']
17:05:21-INFO: ***** Running evaluation *****
17:05:21-INFO:   Num examples = 408
17:05:21-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:28-INFO: ***** Eval results *****
17:05:28-INFO:   F-1 score = 0.89
17:05:28-INFO:   eval_accuracy = 0.8382352941176471
17:05:28-INFO:   eval_loss = 0.4134289106497398
17:05:28-INFO:   global_step = 0
17:05:28-INFO:   inference_time = 7.473586559295654
17:05:28-INFO:   loss = None
attention_head_mask ['11:10']
['11', '10']
17:05:28-INFO: ***** Running evaluation *****
17:05:28-INFO:   Num examples = 408
17:05:28-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:36-INFO: ***** Eval results *****
17:05:36-INFO:   F-1 score = 0.89
17:05:36-INFO:   eval_accuracy = 0.8382352941176471
17:05:36-INFO:   eval_loss = 0.41579909508044904
17:05:36-INFO:   global_step = 0
17:05:36-INFO:   inference_time = 7.46440577507019
17:05:36-INFO:   loss = None
attention_head_mask ['11:11']
['11', '11']
17:05:36-INFO: ***** Running evaluation *****
17:05:36-INFO:   Num examples = 408
17:05:36-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:43-INFO: ***** Eval results *****
17:05:43-INFO:   F-1 score = 0.89
17:05:43-INFO:   eval_accuracy = 0.8382352941176471
17:05:43-INFO:   eval_loss = 0.41443624748633456
17:05:43-INFO:   global_step = 0
17:05:43-INFO:   inference_time = 7.460392475128174
17:05:43-INFO:   loss = None
attention_head_mask ['11:12']
['11', '12']
17:05:43-INFO: ***** Running evaluation *****
17:05:43-INFO:   Num examples = 408
17:05:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:50-INFO: ***** Eval results *****
17:05:50-INFO:   F-1 score = 0.8862876254180602
17:05:50-INFO:   eval_accuracy = 0.8333333333333334
17:05:50-INFO:   eval_loss = 0.4138290790411142
17:05:50-INFO:   global_step = 0
17:05:50-INFO:   inference_time = 7.454722881317139
17:05:50-INFO:   loss = None
attention_head_mask ['12:1']
['12', '1']
17:05:50-INFO: ***** Running evaluation *****
17:05:50-INFO:   Num examples = 408
17:05:50-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:05:58-INFO: ***** Eval results *****
17:05:58-INFO:   F-1 score = 0.8862876254180602
17:05:58-INFO:   eval_accuracy = 0.8333333333333334
17:05:58-INFO:   eval_loss = 0.4137845360315763
17:05:58-INFO:   global_step = 0
17:05:58-INFO:   inference_time = 7.468673944473267
17:05:58-INFO:   loss = None
attention_head_mask ['12:2']
['12', '2']
17:05:58-INFO: ***** Running evaluation *****
17:05:58-INFO:   Num examples = 408
17:05:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:05-INFO: ***** Eval results *****
17:06:05-INFO:   F-1 score = 0.8848080133555927
17:06:05-INFO:   eval_accuracy = 0.8308823529411765
17:06:05-INFO:   eval_loss = 0.4144814427082355
17:06:05-INFO:   global_step = 0
17:06:05-INFO:   inference_time = 7.476210832595825
17:06:05-INFO:   loss = None
attention_head_mask ['12:3']
['12', '3']
17:06:05-INFO: ***** Running evaluation *****
17:06:05-INFO:   Num examples = 408
17:06:05-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:13-INFO: ***** Eval results *****
17:06:13-INFO:   F-1 score = 0.8862876254180602
17:06:13-INFO:   eval_accuracy = 0.8333333333333334
17:06:13-INFO:   eval_loss = 0.41453606578019947
17:06:13-INFO:   global_step = 0
17:06:13-INFO:   inference_time = 7.463526725769043
17:06:13-INFO:   loss = None
attention_head_mask ['12:4']
['12', '4']
17:06:13-INFO: ***** Running evaluation *****
17:06:13-INFO:   Num examples = 408
17:06:13-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:20-INFO: ***** Eval results *****
17:06:20-INFO:   F-1 score = 0.8848080133555927
17:06:20-INFO:   eval_accuracy = 0.8308823529411765
17:06:20-INFO:   eval_loss = 0.4146161755690208
17:06:20-INFO:   global_step = 0
17:06:20-INFO:   inference_time = 7.457693099975586
17:06:20-INFO:   loss = None
attention_head_mask ['12:5']
['12', '5']
17:06:20-INFO: ***** Running evaluation *****
17:06:20-INFO:   Num examples = 408
17:06:20-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:28-INFO: ***** Eval results *****
17:06:28-INFO:   F-1 score = 0.8862876254180602
17:06:28-INFO:   eval_accuracy = 0.8333333333333334
17:06:28-INFO:   eval_loss = 0.41334100526112777
17:06:28-INFO:   global_step = 0
17:06:28-INFO:   inference_time = 7.467406272888184
17:06:28-INFO:   loss = None
attention_head_mask ['12:6']
['12', '6']
17:06:28-INFO: ***** Running evaluation *****
17:06:28-INFO:   Num examples = 408
17:06:28-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:35-INFO: ***** Eval results *****
17:06:35-INFO:   F-1 score = 0.8848080133555927
17:06:35-INFO:   eval_accuracy = 0.8308823529411765
17:06:35-INFO:   eval_loss = 0.41504532442643094
17:06:35-INFO:   global_step = 0
17:06:35-INFO:   inference_time = 7.476287126541138
17:06:35-INFO:   loss = None
attention_head_mask ['12:7']
['12', '7']
17:06:35-INFO: ***** Running evaluation *****
17:06:35-INFO:   Num examples = 408
17:06:35-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:43-INFO: ***** Eval results *****
17:06:43-INFO:   F-1 score = 0.8862876254180602
17:06:43-INFO:   eval_accuracy = 0.8333333333333334
17:06:43-INFO:   eval_loss = 0.41330504646668065
17:06:43-INFO:   global_step = 0
17:06:43-INFO:   inference_time = 7.4752442836761475
17:06:43-INFO:   loss = None
attention_head_mask ['12:8']
['12', '8']
17:06:43-INFO: ***** Running evaluation *****
17:06:43-INFO:   Num examples = 408
17:06:43-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.73it/s]
17:06:50-INFO: ***** Eval results *****
17:06:50-INFO:   F-1 score = 0.8848080133555927
17:06:50-INFO:   eval_accuracy = 0.8308823529411765
17:06:50-INFO:   eval_loss = 0.41441365961845106
17:06:50-INFO:   global_step = 0
17:06:50-INFO:   inference_time = 7.484836101531982
17:06:50-INFO:   loss = None
attention_head_mask ['12:9']
['12', '9']
17:06:50-INFO: ***** Running evaluation *****
17:06:50-INFO:   Num examples = 408
17:06:50-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:06:58-INFO: ***** Eval results *****
17:06:58-INFO:   F-1 score = 0.8848080133555927
17:06:58-INFO:   eval_accuracy = 0.8308823529411765
17:06:58-INFO:   eval_loss = 0.41486484041580785
17:06:58-INFO:   global_step = 0
17:06:58-INFO:   inference_time = 7.480312824249268
17:06:58-INFO:   loss = None
attention_head_mask ['12:10']
['12', '10']
17:06:58-INFO: ***** Running evaluation *****
17:06:58-INFO:   Num examples = 408
17:06:58-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:07:05-INFO: ***** Eval results *****
17:07:05-INFO:   F-1 score = 0.8862876254180602
17:07:05-INFO:   eval_accuracy = 0.8333333333333334
17:07:05-INFO:   eval_loss = 0.4136802634367576
17:07:05-INFO:   global_step = 0
17:07:05-INFO:   inference_time = 7.464564085006714
17:07:05-INFO:   loss = None
attention_head_mask ['12:11']
['12', '11']
17:07:05-INFO: ***** Running evaluation *****
17:07:05-INFO:   Num examples = 408
17:07:05-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:07:13-INFO: ***** Eval results *****
17:07:13-INFO:   F-1 score = 0.8848080133555927
17:07:13-INFO:   eval_accuracy = 0.8308823529411765
17:07:13-INFO:   eval_loss = 0.41399781749798703
17:07:13-INFO:   global_step = 0
17:07:13-INFO:   inference_time = 7.474645376205444
17:07:13-INFO:   loss = None
attention_head_mask ['12:12']
['12', '12']
17:07:13-INFO: ***** Running evaluation *****
17:07:13-INFO:   Num examples = 408
17:07:13-INFO:   Batch size = 32
Evaluating: 100% 13/13 [00:07<00:00,  1.74it/s]
17:07:20-INFO: ***** Eval results *****
17:07:20-INFO:   F-1 score = 0.8848080133555927
17:07:20-INFO:   eval_accuracy = 0.8308823529411765
17:07:20-INFO:   eval_loss = 0.4144256596381848
17:07:20-INFO:   global_step = 0
17:07:20-INFO:   inference_time = 7.464292049407959
17:07:20-INFO:   loss = None