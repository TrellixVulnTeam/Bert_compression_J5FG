{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8937c61-373b-4eb6-ab03-c7b57725644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e73f1b-8a00-4110-adab-1248e19e8f33",
   "metadata": {},
   "source": [
    "## Clean logs of attention head mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b16a2a6-fe52-48c0-8711-2bc96d668364",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = './logs'\n",
    "\n",
    "def get_start_idx(lines, substring):\n",
    "    return [line_idx for line_idx, line in enumerate(lines) if substring in line]\n",
    "\n",
    "def get_logs(lines):\n",
    "    starter_ides = get_start_idx(lines, 'attention_head_mask')\n",
    "    res = pd.DataFrame({'starter_ides': starter_ides})\n",
    "    res['next'] = res.apply(lambda x: x.shift(1))\n",
    "    res = res[1:]\n",
    "    log_len = int((res['starter_ides'] - res['next']).drop_duplicates().tolist()[0])\n",
    "    return [lines[starter_idx:(starter_idx+log_len)] for starter_idx in starter_ides]\n",
    "        \n",
    "def clean_log(logs):\n",
    "    '''\n",
    "    Clean the log of 1 experiment\n",
    "    '''\n",
    "    def clean_one_line(log_line):\n",
    "        '''\n",
    "        Clean 1 line of 1 log\n",
    "        Examples\n",
    "        --------\n",
    "        >>> clean_one_line(\"00:31:00-INFO:   Batch size = 8\")\n",
    "        ('Batch size', '8')\n",
    "        '''\n",
    "        if '-INFO:   ' in log_line:\n",
    "            result = log_line.split('-INFO:   ')\n",
    "\n",
    "            if result:\n",
    "                variable, value = result[1].split(' = ')\n",
    "                value = re.findall(r'[-+]?(?:\\d*\\.\\d+|\\d+)', value)\n",
    "                if value:\n",
    "                    value = value[0]\n",
    "                else:\n",
    "                    value = None\n",
    "                return variable, value\n",
    "    variables = []\n",
    "    values = []\n",
    "    for log_line in logs:\n",
    "        result = clean_one_line(log_line)\n",
    "        if result:\n",
    "            variable, value = result\n",
    "            variables.append(variable)\n",
    "            values.append(value)\n",
    "    return variables, values\n",
    "\n",
    "def get_experiment_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs(lines):\n",
    "        experiment = log[0].split(' ')[0]\n",
    "        parameter = log[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    return result\n",
    "\n",
    "def get_baseline_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    header_start = min(get_start_idx(lines, 'Running evaluation'))\n",
    "    header_end = min(get_start_idx(lines, 'attention_head_mask'))\n",
    "    variables, values = clean_log(lines[header_start:header_end])\n",
    "\n",
    "    df = pd.DataFrame({'task': task,\n",
    "                       'variables': variables,\n",
    "                       'values': values})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07a131b-8d4d-446c-95c5-68fcd7f5abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = []\n",
    "baseline_results = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/head_pruning') if '.ipynb_checkpoints' not in task]:\n",
    "    experiment_results.append(get_experiment_result(task))\n",
    "    baseline_results.append(get_baseline_result(task))\n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/head_pruning_experiment_results.csv', index=False)\n",
    "pd.concat(baseline_results, axis=0).to_csv('logs_cleaned/baseline_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499be002-6929-4af4-a819-c195a7cd4816",
   "metadata": {},
   "source": [
    "## Clean logs of layer pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ad81de-c908-4050-a4cd-fc3ae61b947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs_2(lines):\n",
    "    logs = []\n",
    "    start_ides = get_start_idx(lines, 'EXPERIMENT')\n",
    "    for log_idx, strat_idx in enumerate(start_ides):\n",
    "        if log_idx != len(start_ides) - 1:\n",
    "            end_idx = start_ides[log_idx+1]\n",
    "            log = lines[strat_idx:end_idx]\n",
    "            logs.append(log)\n",
    "    return logs\n",
    "\n",
    "def get_experiment_result_2(task):\n",
    "    with open(f'{LOGS_PATH}/layer_drop/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs_2(lines):\n",
    "        experiment = 'Remove Layers'\n",
    "        parameter = log[0].split(' remove layers ')[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    result.columns.name = None\n",
    "    return result\n",
    "\n",
    "experiment_results_2 = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/layer_drop') if '.ipynb_checkpoints' not in task]:\n",
    "    experiment_results_2.append(get_experiment_result_2(task))\n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/layer_drop_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
