{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8937c61-373b-4eb6-ab03-c7b57725644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e73f1b-8a00-4110-adab-1248e19e8f33",
   "metadata": {},
   "source": [
    "## Clean logs of attention head mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b16a2a6-fe52-48c0-8711-2bc96d668364",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS_PATH = './logs'\n",
    "\n",
    "def get_start_idx(lines, substring):\n",
    "    return [line_idx for line_idx, line in enumerate(lines) if substring in line]\n",
    "\n",
    "def get_logs(lines):\n",
    "    starter_ides = get_start_idx(lines, 'attention_head_mask')\n",
    "    res = pd.DataFrame({'starter_ides': starter_ides})\n",
    "    res['next'] = res.apply(lambda x: x.shift(1))\n",
    "    res = res[1:]\n",
    "    log_len = int((res['starter_ides'] - res['next']).drop_duplicates().tolist()[0])\n",
    "    return [lines[starter_idx:(starter_idx+log_len)] for starter_idx in starter_ides]\n",
    "        \n",
    "def clean_log(logs):\n",
    "    '''\n",
    "    Clean the log of 1 experiment\n",
    "    '''\n",
    "    def clean_one_line(log_line):\n",
    "        '''\n",
    "        Clean 1 line of 1 log\n",
    "        Examples\n",
    "        --------\n",
    "        >>> clean_one_line(\"00:31:00-INFO:   Batch size = 8\")\n",
    "        ('Batch size', '8')\n",
    "        '''\n",
    "        if '-INFO:   ' in log_line:\n",
    "            result = log_line.split('-INFO:   ')\n",
    "\n",
    "            if result:\n",
    "                #variable, value = result[0]\n",
    "                variable, value = result[1].split(' = ')\n",
    "                value = re.findall(r'[-+]?(?:\\d*\\.\\d+|\\d+)', value)\n",
    "        #                    print(result, value)\n",
    "                if value:\n",
    "                    value = value[0]\n",
    "                else:\n",
    "                    value = None\n",
    "                return variable, value\n",
    "    variables = []\n",
    "    values = []\n",
    "    for log_line in logs:\n",
    "        result = clean_one_line(log_line)\n",
    "        if result:\n",
    "            variable, value = result\n",
    "            variables.append(variable)\n",
    "            values.append(value)\n",
    "    return variables, values\n",
    "\n",
    "def get_experiment_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs(lines):\n",
    "        experiment = log[0].split(' ')[0]\n",
    "        parameter = log[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True) #\\\n",
    "               # .pivot(index = [\"experiments\", 'parameter'], \n",
    "               #        columns = 'variables', \n",
    "               #        values = 'values').reset_index()\n",
    "    result.columns.name = None\n",
    "    return result\n",
    "\n",
    "def get_baseline_result(task):\n",
    "    with open(f'{LOGS_PATH}/head_pruning/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    header_start = min(get_start_idx(lines, 'Running evaluation'))\n",
    "    header_end = min(get_start_idx(lines, 'attention_head_mask'))\n",
    "    variables, values = clean_log(lines[header_start:header_end])\n",
    "\n",
    "    df = pd.DataFrame({'task': task,\n",
    "                       'variables': variables,\n",
    "                       'values': values})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d07a131b-8d4d-446c-95c5-68fcd7f5abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task</th>\n",
       "      <th>experiments</th>\n",
       "      <th>parameter</th>\n",
       "      <th>variables</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>Num examples</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>Batch size</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.930045871559633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.930045871559633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sst-2</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.23572358821651765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>cola</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['12', '12']</td>\n",
       "      <td>eval_accuracy</td>\n",
       "      <td>0.8082454458293384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>cola</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['12', '12']</td>\n",
       "      <td>eval_loss</td>\n",
       "      <td>0.47653821923516015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>cola</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['12', '12']</td>\n",
       "      <td>global_step</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>cola</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['12', '12']</td>\n",
       "      <td>inference_time</td>\n",
       "      <td>9.440559148788452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>cola</td>\n",
       "      <td>attention_head_mask</td>\n",
       "      <td>['12', '12']</td>\n",
       "      <td>loss</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5037 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       task          experiments     parameter       variables  \\\n",
       "0     sst-2  attention_head_mask    ['1', '1']    Num examples   \n",
       "1     sst-2  attention_head_mask    ['1', '1']      Batch size   \n",
       "2     sst-2  attention_head_mask    ['1', '1']        Accuracy   \n",
       "3     sst-2  attention_head_mask    ['1', '1']   eval_accuracy   \n",
       "4     sst-2  attention_head_mask    ['1', '1']       eval_loss   \n",
       "...     ...                  ...           ...             ...   \n",
       "1147   cola  attention_head_mask  ['12', '12']   eval_accuracy   \n",
       "1148   cola  attention_head_mask  ['12', '12']       eval_loss   \n",
       "1149   cola  attention_head_mask  ['12', '12']     global_step   \n",
       "1150   cola  attention_head_mask  ['12', '12']  inference_time   \n",
       "1151   cola  attention_head_mask  ['12', '12']            loss   \n",
       "\n",
       "                   values  \n",
       "0                     872  \n",
       "1                      32  \n",
       "2       0.930045871559633  \n",
       "3       0.930045871559633  \n",
       "4     0.23572358821651765  \n",
       "...                   ...  \n",
       "1147   0.8082454458293384  \n",
       "1148  0.47653821923516015  \n",
       "1149                    0  \n",
       "1150    9.440559148788452  \n",
       "1151                 None  \n",
       "\n",
       "[5037 rows x 5 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_results = []\n",
    "baseline_results = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/head_pruning')]:\n",
    "    experiment_results.append(get_experiment_result(task))\n",
    "    baseline_results.append(get_baseline_result(task))\n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/head_pruning_experiment_results.csv', index=False)\n",
    "pd.concat(baseline_results, axis=0).to_csv('logs_cleaned/head_pruning_baseline_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499be002-6929-4af4-a819-c195a7cd4816",
   "metadata": {},
   "source": [
    "## Clean logs of layer pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "70ad81de-c908-4050-a4cd-fc3ae61b947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logs_2(lines):\n",
    "    logs = []\n",
    "    start_ides = get_start_idx(lines, 'EXPERIMENT')\n",
    "    for log_idx, strat_idx in enumerate(start_ides):\n",
    "        if log_idx != len(start_ides) - 1:\n",
    "            end_idx = start_ides[log_idx+1]\n",
    "            log = lines[strat_idx:end_idx]\n",
    "            logs.append(log)\n",
    "    return logs\n",
    "\n",
    "def get_experiment_result_2(task):\n",
    "    with open(f'{LOGS_PATH}/layer_drop/{task}.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    dfs = []\n",
    "    for log in get_logs_2(lines):\n",
    "        experiment = 'Remove Layers'\n",
    "        parameter = log[0].split(' remove layers ')[1].replace('\\n', '')\n",
    "        variables, values = clean_log(log[3:])\n",
    "        df = pd.DataFrame({'task': task.lower(),\n",
    "                           'experiments': experiment,\n",
    "                           'parameter': parameter,\n",
    "                           'variables': variables,\n",
    "                           'values': values})\n",
    "        dfs.append(df)\n",
    "    result = pd.concat(dfs, axis=0, ignore_index=True) #\\\n",
    "               # .pivot(index = [\"experiments\", 'parameter'], \n",
    "               #        columns = 'variables', \n",
    "               #        values = 'values').reset_index()\n",
    "    result.columns.name = None\n",
    "    return result\n",
    "\n",
    "experiment_results_2 = []\n",
    "#baseline_results = []\n",
    "for task in [task.replace('.txt', '') for task in os.listdir(LOGS_PATH + '/layer_drop')]:\n",
    "   \n",
    "    experiment_results_2.append(get_experiment_result_2(task))\n",
    "    #baseline_results.append(get_baseline_result(task))\n",
    "pd.concat(experiment_results, axis=0).to_csv('logs_cleaned/layer_drop_results.csv', index=False)\n",
    "#pd.concat(baseline_results, axis=0).to_csv('logs_cleaned/head_pruning_baseline_results.csv', index=False)\n",
    "\n",
    "\n",
    "#get_experiment_result_2('CoLA')\n",
    "# for line in log:\n",
    "#     print(line)\n",
    "#print(logs)\n",
    "# variables, values = clean_logs(log[3:])\n",
    "#     print(line)\n",
    "#LOGS_PATH = './logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86684c19-a1c6-4cca-bce2-7a469c70dfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
